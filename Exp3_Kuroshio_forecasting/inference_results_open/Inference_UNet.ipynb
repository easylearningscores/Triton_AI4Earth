{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9105d1dd-49b8-4e91-9b41-23406f05992a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/envs/haowu/lib/python3.10/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11000). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "2025-04-28 18:58:32,675 [INFO] Model loaded successfully.: Kuro_Unet_exp_128_20250324_best_model.pth\n",
      "2025-04-28 18:58:32,801 [INFO] Generated 73 initial dates, example: ['2021-01-01', '2021-01-06', '2021-01-11', '2021-01-16', '2021-01-21']...\n",
      "/tmp/ipykernel_52182/1335310592.py:101: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast():\n",
      "/miniconda3/envs/haowu/lib/python3.10/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "\n",
      "\u001b[Adiction progress.:   0%|                                                                                       | 0/12 [00:00<?, ?it/s]\n",
      "\u001b[Adiction progress.:   8%|██████▌                                                                        | 1/12 [00:00<00:03,  3.19it/s]\n",
      "\u001b[Adiction progress.:  17%|█████████████▏                                                                 | 2/12 [00:00<00:02,  3.82it/s]\n",
      "\u001b[Adiction progress.:  25%|███████████████████▊                                                           | 3/12 [00:00<00:02,  4.11it/s]\n",
      "\u001b[Adiction progress.:  33%|██████████████████████████▎                                                    | 4/12 [00:01<00:02,  3.93it/s]\n",
      "\u001b[Adiction progress.:  42%|████████████████████████████████▉                                              | 5/12 [00:01<00:01,  4.06it/s]\n",
      "\u001b[Adiction progress.:  50%|███████████████████████████████████████▌                                       | 6/12 [00:01<00:01,  3.82it/s]\n",
      "\u001b[Adiction progress.:  58%|██████████████████████████████████████████████                                 | 7/12 [00:01<00:01,  3.85it/s]\n",
      "\u001b[Adiction progress.:  67%|████████████████████████████████████████████████████▋                          | 8/12 [00:02<00:00,  4.00it/s]\n",
      "\u001b[Adiction progress.:  75%|███████████████████████████████████████████████████████████▎                   | 9/12 [00:02<00:00,  3.75it/s]\n",
      "\u001b[Adiction progress.:  83%|█████████████████████████████████████████████████████████████████             | 10/12 [00:02<00:00,  3.58it/s]\n",
      "\u001b[Adiction progress.:  92%|███████████████████████████████████████████████████████████████████████▌      | 11/12 [00:02<00:00,  3.55it/s]\n",
      "\u001b[Adiction progress.: 100%|██████████████████████████████████████████████████████████████████████████████| 12/12 [00:03<00:00,  3.62it/s]\n",
      "Process initial conditions.:   1%|▉                                                                       | 1/73 [00:03<04:32,  3.78s/it]\n",
      "\u001b[Adiction progress.:   0%|                                                                                       | 0/12 [00:00<?, ?it/s]\n",
      "\u001b[Adiction progress.:   8%|██████▌                                                                        | 1/12 [00:00<00:03,  3.37it/s]\n",
      "\u001b[Adiction progress.:  17%|█████████████▏                                                                 | 2/12 [00:00<00:02,  3.42it/s]\n",
      "\u001b[Adiction progress.:  25%|███████████████████▊                                                           | 3/12 [00:00<00:02,  3.30it/s]\n",
      "\u001b[Adiction progress.:  33%|██████████████████████████▎                                                    | 4/12 [00:01<00:02,  3.61it/s]\n",
      "\u001b[Adiction progress.:  42%|████████████████████████████████▉                                              | 5/12 [00:01<00:01,  3.69it/s]\n",
      "\u001b[Adiction progress.:  50%|███████████████████████████████████████▌                                       | 6/12 [00:01<00:01,  3.67it/s]\n",
      "\u001b[Adiction progress.:  58%|██████████████████████████████████████████████                                 | 7/12 [00:01<00:01,  3.55it/s]\n",
      "\u001b[Adiction progress.:  67%|████████████████████████████████████████████████████▋                          | 8/12 [00:02<00:01,  3.69it/s]\n",
      "\u001b[Adiction progress.:  75%|███████████████████████████████████████████████████████████▎                   | 9/12 [00:02<00:00,  3.53it/s]\n",
      "Process initial conditions.:   1%|▉                                                                       | 1/73 [00:06<08:10,  6.81s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 244\u001b[0m\n\u001b[1;32m    237\u001b[0m target_dates \u001b[38;5;241m=\u001b[39m data_loader\u001b[38;5;241m.\u001b[39mgenerate_target_dates(\n\u001b[1;32m    238\u001b[0m     start_date\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_range\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    239\u001b[0m     end_date\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_range\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    240\u001b[0m     interval_days\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_range\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterval\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    241\u001b[0m )\n\u001b[1;32m    242\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(target_dates)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m initial dates, example: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_dates[:\u001b[38;5;241m5\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 244\u001b[0m \u001b[43mprocess_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpred_days\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msave_dir\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m sample_dates \u001b[38;5;241m=\u001b[39m [target_dates[\u001b[38;5;241m0\u001b[39m], target_dates[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m sample_dates:\n",
      "Cell \u001b[0;32mIn[1], line 121\u001b[0m, in \u001b[0;36mprocess_batch\u001b[0;34m(model, data_loader, target_dates, pred_days, save_dir)\u001b[0m\n\u001b[1;32m    118\u001b[0m initial \u001b[38;5;241m=\u001b[39m initial[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, ::\u001b[38;5;241m2\u001b[39m, ::\u001b[38;5;241m2\u001b[39m] \n\u001b[1;32m    119\u001b[0m label \u001b[38;5;241m=\u001b[39m label[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, ::\u001b[38;5;241m2\u001b[39m, ::\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m--> 121\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_days\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforecast_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate_str\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    124\u001b[0m save_results(\n\u001b[1;32m    125\u001b[0m     initial\u001b[38;5;241m.\u001b[39mcpu(), \n\u001b[1;32m    126\u001b[0m     label\u001b[38;5;241m.\u001b[39mcpu(), \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m     save_path\n\u001b[1;32m    131\u001b[0m )\n",
      "Cell \u001b[0;32mIn[1], line 104\u001b[0m, in \u001b[0;36mpredict_single\u001b[0;34m(model, initial_input, pred_days)\u001b[0m\n\u001b[1;32m    102\u001b[0m total_steps \u001b[38;5;241m=\u001b[39m (pred_days \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m9\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(total_steps), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction progress.\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 104\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(output\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[1;32m    106\u001b[0m     current_input \u001b[38;5;241m=\u001b[39m output[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10\u001b[39m:]\n",
      "File \u001b[0;32m/miniconda3/envs/haowu/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/miniconda3/envs/haowu/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/jizhicfs/easyluwu/ocean_project/NPJ_baselines/Exp_2_Kuroshio/inference_results_open/model/U_net.py:86\u001b[0m, in \u001b[0;36mUNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     84\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup1(x4, x3)\n\u001b[1;32m     85\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup2(x, x2)\n\u001b[0;32m---> 86\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutc(x)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# 恢复原始维度（如果是5维输入）\u001b[39;00m\n",
      "File \u001b[0;32m/miniconda3/envs/haowu/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/miniconda3/envs/haowu/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/jizhicfs/easyluwu/ocean_project/NPJ_baselines/Exp_2_Kuroshio/inference_results_open/model/U_net.py:44\u001b[0m, in \u001b[0;36mUp.forward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m     41\u001b[0m x1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mpad(x1, [diffX \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, diffX \u001b[38;5;241m-\u001b[39m diffX \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     42\u001b[0m                             diffY \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, diffY \u001b[38;5;241m-\u001b[39m diffY \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m     43\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x2, x1], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/miniconda3/envs/haowu/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/miniconda3/envs/haowu/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/jizhicfs/easyluwu/ocean_project/NPJ_baselines/Exp_2_Kuroshio/inference_results_open/model/U_net.py:17\u001b[0m, in \u001b[0;36mDoubleConv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/miniconda3/envs/haowu/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/miniconda3/envs/haowu/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/miniconda3/envs/haowu/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/miniconda3/envs/haowu/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/miniconda3/envs/haowu/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/miniconda3/envs/haowu/lib/python3.10/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/miniconda3/envs/haowu/lib/python3.10/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import logging\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import xarray as xr\n",
    "from model.U_net import *\n",
    "\n",
    "\n",
    "# ============================== Initialization Configuration ==============================\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s [%(levelname)s] %(message)s')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "def load_single_model(model_path):\n",
    "    \"\"\"Load the best inference model\"\"\"\n",
    "    model = UNet(n_channels=2, n_classes=2).to(device)\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        if any(k.startswith('module.') for k in checkpoint.keys()):\n",
    "            checkpoint = {k.replace('module.', ''): v for k, v in checkpoint.items()}\n",
    "        model.load_state_dict(checkpoint)\n",
    "        logging.info(f\"Model loaded successfully.: {os.path.basename(model_path)}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Model file not found.: {model_path}\")\n",
    "    return model\n",
    "\n",
    "# ============================== Dataloader ==============================\n",
    "class OceanDataLoader:\n",
    "    def __init__(self, nc_path):\n",
    "        self.ds = xr.open_dataset(nc_path)\n",
    "        self.time_stamps = self.ds.time.values.astype('datetime64[s]').astype(datetime)\n",
    "    \n",
    "    def generate_target_dates(self, start_date, end_date, interval_days=1):\n",
    "        \"\"\"Generate a continuous initial date sequence.\"\"\"\n",
    "        all_dates = []\n",
    "        current_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "        end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "        \n",
    "        while current_date <= end_date:\n",
    "            if current_date in self.time_stamps:\n",
    "                all_dates.append(current_date.strftime(\"%Y-%m-%d\"))\n",
    "            current_date += timedelta(days=interval_days)\n",
    "        \n",
    "        if not all_dates:\n",
    "            raise ValueError(\"No valid dates found. Please check the date range and data files.\")\n",
    "        return all_dates\n",
    "    \n",
    "    def load_single_case(self, target_date, pred_days):\n",
    "        \"\"\"\n",
    "        Load a single initial condition \n",
    "        param target_date: The last date of the input sequence (format: 'YYYY-MM-%d') \n",
    "        param pred_days: The number of days to predict \n",
    "        return: (initial data, true labels, initial timestamp, label timestamp) \n",
    "        \"\"\"\n",
    "        try:\n",
    "            target_dt = datetime.strptime(target_date, \"%Y-%m-%d\")\n",
    "            end_idx = np.where(self.time_stamps == target_dt)[0][0]\n",
    "        except IndexError:\n",
    "            available_dates = [d.strftime(\"%Y-%m-%d\") for d in self.time_stamps[-10:]]\n",
    "            raise ValueError(f\"Invalid date {target_date}, the last 10 available dates: {available_dates}\")\n",
    "\n",
    "        if end_idx < 9:\n",
    "            raise ValueError(f\"At least 9 days of data are required, the earliest available date: {self.time_stamps[0].strftime('%Y-%m-%d')}\")\n",
    "        if end_idx + pred_days >= len(self.time_stamps):\n",
    "            raise ValueError(f\"Prediction exceeds data range, the data cutoff date is: {self.time_stamps[-1].strftime('%Y-%m-%d')}\")\n",
    "\n",
    "        initial_dates = self.time_stamps[end_idx-9 : end_idx+1]  \n",
    "        label_dates = self.time_stamps[end_idx+1 : end_idx+1+pred_days]\n",
    "\n",
    "        def load_var(var_name, start, end):\n",
    "            data = self.ds[var_name].isel(time=slice(start, end)).values\n",
    "            return torch.FloatTensor(np.nan_to_num(data, nan=0.0))\n",
    "\n",
    "        ugos_init = load_var('ugos', end_idx-9, end_idx+1)\n",
    "        vgos_init = load_var('vgos', end_idx-9, end_idx+1)\n",
    "        initial = torch.stack([ugos_init, vgos_init], dim=1).unsqueeze(0).to(device)\n",
    "\n",
    "        ugos_label = load_var('ugos', end_idx+1, end_idx+1+pred_days)\n",
    "        vgos_label = load_var('vgos', end_idx+1, end_idx+1+pred_days)\n",
    "        label = torch.stack([ugos_label, vgos_label], dim=1).unsqueeze(0).to(device)\n",
    "\n",
    "        return initial, label, initial_dates, label_dates\n",
    "\n",
    "# ============================== Inference engine ==============================\n",
    "def predict_single(model, initial_input, pred_days):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    current_input = initial_input.clone()\n",
    "    \n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        total_steps = (pred_days + 9) // 10\n",
    "        for _ in tqdm(range(total_steps), desc=f\"Prediction progress.\", leave=False):\n",
    "            output = model(current_input)\n",
    "            predictions.append(output.cpu())\n",
    "            current_input = output[:, -10:]\n",
    "    \n",
    "    return torch.cat(predictions, dim=1)[:, :pred_days].to(device)\n",
    "\n",
    "# ============================== Batch processing. ==============================\n",
    "def process_batch(model, data_loader, target_dates, pred_days, save_dir):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    success_count = 0\n",
    "    \n",
    "    for date_str in tqdm(target_dates, desc=\"Process initial conditions.\"):\n",
    "        try:\n",
    "            initial, label, init_dates, label_dates = data_loader.load_single_case(date_str, pred_days)\n",
    "            initial = initial[..., ::2, ::2] \n",
    "            label = label[..., ::2, ::2]\n",
    "            \n",
    "            prediction = predict_single(model, initial, pred_days)\n",
    "            \n",
    "            save_path = os.path.join(save_dir, f\"forecast_{date_str.replace('-','')}.h5\")\n",
    "            save_results(\n",
    "                initial.cpu(), \n",
    "                label.cpu(), \n",
    "                prediction.cpu(),\n",
    "                init_dates, \n",
    "                label_dates,\n",
    "                save_path\n",
    "            )\n",
    "            success_count += 1\n",
    "            \n",
    "            del initial, label, prediction\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Process {date_str} failed: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    logging.info(f\"Processing complete, successfully processed {success_count}/{len(target_dates)} initial conditions\")\n",
    "\n",
    "# ============================== Results saved ==============================\n",
    "def save_results(initial, label, prediction, init_dates, label_dates, save_path):\n",
    "    with h5py.File(save_path, 'w') as f:\n",
    "        f.create_dataset('initial', data=initial.numpy())\n",
    "        f.create_dataset('label', data=label.numpy())\n",
    "        f.create_dataset('prediction', data=prediction.numpy())\n",
    "        \n",
    "        def save_dates(dataset_name, dates):\n",
    "            str_dates = [d.strftime(\"%Y-%m-%d\") for d in dates]\n",
    "            dt = h5py.string_dtype(encoding='utf-8')\n",
    "            f.create_dataset(dataset_name, data=np.array(str_dates, dtype=dt))\n",
    "        \n",
    "        save_dates('initial_dates', init_dates)\n",
    "        save_dates('label_dates', label_dates)\n",
    "        \n",
    "        f.attrs['input_end_date'] = init_dates[-1].strftime(\"%Y-%m-%d\")\n",
    "        f.attrs['pred_start_date'] = label_dates[0].strftime(\"%Y-%m-%d\")\n",
    "        f.attrs['pred_end_date'] = label_dates[-1].strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def visualize_enhanced(h5_path, step=0, save_fig=True):\n",
    "    with h5py.File(h5_path, 'r') as f:\n",
    "        initial = f['initial'][0]\n",
    "        label = f['label'][0]\n",
    "        prediction = f['prediction'][0]\n",
    "        init_dates = [d.decode() for d in f['initial_dates'][:]]\n",
    "        label_dates = [d.decode() for d in f['label_dates'][:]]\n",
    "    \n",
    "    input_end_date = init_dates[-1]\n",
    "    pred_date = label_dates[min(step, len(label_dates)-1)]\n",
    "    \n",
    "    def get_speed(data, step):\n",
    "        return np.sqrt(data[step,0]**2 + data[step,1]**2)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(24, 6))\n",
    "    fig.suptitle(f\"Comparison of Ocean Surface Current Speed\\nInput End Date: {input_end_date} → Prediction Date: {pred_date}\", \n",
    "                y=1.05, fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plot_kwargs = {\n",
    "        'cmap': 'jet',\n",
    "        'extent': [123.1, 154.9, 10.06, 41.94],  \n",
    "        'origin': 'lower',\n",
    "        'vmin': 0,\n",
    "        'vmax': max(np.nanmax(label), np.nanmax(prediction))\n",
    "    }\n",
    "    \n",
    "    speed_initial = get_speed(initial, -1)\n",
    "    im0 = axes[0].imshow(speed_initial, **plot_kwargs)\n",
    "    axes[0].set_title(f\"Initial Field Last Day\\n{init_dates[-1]}\", fontsize=12)\n",
    "    axes[0].set_xlabel('Longitude', fontsize=10)\n",
    "    axes[0].set_ylabel('Latitude', fontsize=10)\n",
    "\n",
    "    \n",
    "    speed_label = get_speed(label, step)\n",
    "    im1 = axes[1].imshow(speed_label, **plot_kwargs)\n",
    "    axes[1].set_title(f\"True Values\\n{pred_date}\", fontsize=12)\n",
    "    axes[1].set_xlabel('Longitude', fontsize=10)\n",
    "\n",
    "    speed_pred = get_speed(prediction, step)\n",
    "    im2 = axes[2].imshow(speed_pred, **plot_kwargs)\n",
    "    axes[2].set_title(f\"Predicted Values\\n{pred_date}\", fontsize=12)\n",
    "    axes[2].set_xlabel('Longitude', fontsize=10)\n",
    "\n",
    "    cbar = fig.colorbar(im1, ax=axes, orientation='vertical', shrink=0.8, pad=0.03)\n",
    "    cbar.set_label('Current Speed (m/s)', fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_fig:\n",
    "        fig_name = f\"forecast_{input_end_date}_day{step+1}.png\"\n",
    "        plt.savefig(fig_name, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# ============================== Main ==============================\n",
    "if __name__ == \"__main__\":\n",
    "    backbone = 'Kuro_Unet_exp_128_20250324'\n",
    "    config = {\n",
    "        'model_path': f'/jizhicfs/easyluwu/ocean_project/NPJ_baselines/Exp_2_Kuroshio/checkpoints/{backbone}_best_model.pth',\n",
    "        'data_path': '/jizhicfs/easyluwu/ocean_project/kuro/KURO.nc',\n",
    "        'date_range': {  \n",
    "            'start': '2021-01-01',\n",
    "            'end': '2021-12-31',\n",
    "            'interval': 5  \n",
    "        },\n",
    "        'pred_days': 120,\n",
    "        'save_dir':f'./{backbone}_forecast_results'\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        model = load_single_model(config['model_path'])\n",
    "        data_loader = OceanDataLoader(config['data_path'])\n",
    "        \n",
    "        target_dates = data_loader.generate_target_dates(\n",
    "            start_date=config['date_range']['start'],\n",
    "            end_date=config['date_range']['end'],\n",
    "            interval_days=config['date_range']['interval']\n",
    "        )\n",
    "        logging.info(f\"Generated {len(target_dates)} initial dates, example: {target_dates[:5]}...\")\n",
    "        \n",
    "        process_batch(\n",
    "            model, \n",
    "            data_loader,\n",
    "            target_dates,\n",
    "            config['pred_days'],\n",
    "            config['save_dir']\n",
    "        )\n",
    "        \n",
    "        sample_dates = [target_dates[0], target_dates[-1]]\n",
    "        for date in sample_dates:\n",
    "            h5_file = os.path.join(config['save_dir'], f\"forecast_{date.replace('-','')}.h5\")\n",
    "            for step in [0, 60, 119]: \n",
    "                visualize_enhanced(h5_file, step=step)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Main process error: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eaa58f-6e63-4876-a558-dbe5d085ed6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322a4033-f4fa-495c-b095-f39099d18811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8346e2d-5eb7-4a04-bb6f-4a0831016f40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

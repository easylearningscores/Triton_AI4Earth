2025-02-18 14:15:03,208 Added key: store_based_barrier_key:1 to store for rank: 3
2025-02-18 14:15:03,302 Added key: store_based_barrier_key:1 to store for rank: 6
2025-02-18 14:15:03,311 Added key: store_based_barrier_key:1 to store for rank: 4
2025-02-18 14:15:03,389 Added key: store_based_barrier_key:1 to store for rank: 0
2025-02-18 14:15:03,415 Added key: store_based_barrier_key:1 to store for rank: 2
2025-02-18 14:15:03,437 Added key: store_based_barrier_key:1 to store for rank: 7
2025-02-18 14:15:03,444 Added key: store_based_barrier_key:1 to store for rank: 1
2025-02-18 14:15:03,461 Added key: store_based_barrier_key:1 to store for rank: 5
2025-02-18 14:15:25,625 Epoch 1/2000
2025-02-18 14:15:30,589 Reducer buckets have been rebuilt in this iteration.
2025-02-18 14:15:30,589 Reducer buckets have been rebuilt in this iteration.
2025-02-18 14:15:30,591 Reducer buckets have been rebuilt in this iteration.
2025-02-18 14:15:30,591 Reducer buckets have been rebuilt in this iteration.
2025-02-18 14:15:30,591 Reducer buckets have been rebuilt in this iteration.
2025-02-18 14:15:30,591 Reducer buckets have been rebuilt in this iteration.
2025-02-18 14:15:30,591 Reducer buckets have been rebuilt in this iteration.
2025-02-18 14:15:30,591 Reducer buckets have been rebuilt in this iteration.
2025-02-18 14:16:09,968 Current Learning Rate: 0.0099993832
2025-02-18 14:16:11,879 Train Loss: 1.3628420, Val Loss: 0.1698331
2025-02-18 14:16:11,879 Epoch 2/2000
2025-02-18 14:16:54,193 Current Learning Rate: 0.0099975328
2025-02-18 14:16:55,899 Train Loss: 0.0687663, Val Loss: 0.0357662
2025-02-18 14:16:55,900 Epoch 3/2000
2025-02-18 14:17:37,571 Current Learning Rate: 0.0099944494
2025-02-18 14:17:39,033 Train Loss: 0.0274687, Val Loss: 0.0195614
2025-02-18 14:17:39,036 Epoch 4/2000
2025-02-18 14:18:20,798 Current Learning Rate: 0.0099901336
2025-02-18 14:18:21,846 Train Loss: 0.0202074, Val Loss: 0.0180349
2025-02-18 14:18:21,849 Epoch 5/2000
2025-02-18 14:19:03,419 Current Learning Rate: 0.0099845867
2025-02-18 14:19:04,787 Train Loss: 0.0193941, Val Loss: 0.0177117
2025-02-18 14:19:04,788 Epoch 6/2000
2025-02-18 14:19:47,265 Current Learning Rate: 0.0099778098
2025-02-18 14:19:49,257 Train Loss: 0.0191047, Val Loss: 0.0175423
2025-02-18 14:19:49,257 Epoch 7/2000
2025-02-18 14:20:30,631 Current Learning Rate: 0.0099698048
2025-02-18 14:20:32,449 Train Loss: 0.0189317, Val Loss: 0.0174137
2025-02-18 14:20:32,449 Epoch 8/2000
2025-02-18 14:21:14,244 Current Learning Rate: 0.0099605735
2025-02-18 14:21:15,711 Train Loss: 0.0187991, Val Loss: 0.0173049
2025-02-18 14:21:15,711 Epoch 9/2000
2025-02-18 14:21:57,838 Current Learning Rate: 0.0099501183
2025-02-18 14:21:59,767 Train Loss: 0.0186761, Val Loss: 0.0172068
2025-02-18 14:21:59,767 Epoch 10/2000
2025-02-18 14:22:42,174 Current Learning Rate: 0.0099384417
2025-02-18 14:22:44,221 Train Loss: 0.0185759, Val Loss: 0.0171160
2025-02-18 14:22:44,222 Epoch 11/2000
2025-02-18 14:23:27,348 Current Learning Rate: 0.0099255466
2025-02-18 14:23:29,500 Train Loss: 0.0184690, Val Loss: 0.0170284
2025-02-18 14:23:29,501 Epoch 12/2000
2025-02-18 14:24:12,728 Current Learning Rate: 0.0099114363
2025-02-18 14:24:14,554 Train Loss: 0.0183741, Val Loss: 0.0169453
2025-02-18 14:24:14,555 Epoch 13/2000
2025-02-18 14:24:57,049 Current Learning Rate: 0.0098961141
2025-02-18 14:24:59,074 Train Loss: 0.0182787, Val Loss: 0.0168658
2025-02-18 14:24:59,075 Epoch 14/2000
2025-02-18 14:25:40,634 Current Learning Rate: 0.0098795838
2025-02-18 14:25:42,153 Train Loss: 0.0181902, Val Loss: 0.0167882
2025-02-18 14:25:42,154 Epoch 15/2000
2025-02-18 14:26:24,721 Current Learning Rate: 0.0098618496
2025-02-18 14:26:26,667 Train Loss: 0.0181102, Val Loss: 0.0167148
2025-02-18 14:26:26,668 Epoch 16/2000
2025-02-18 14:27:08,442 Current Learning Rate: 0.0098429158
2025-02-18 14:27:09,549 Train Loss: 0.0180223, Val Loss: 0.0166435
2025-02-18 14:27:09,562 Epoch 17/2000
2025-02-18 14:27:51,189 Current Learning Rate: 0.0098227871
2025-02-18 14:27:52,566 Train Loss: 0.0179441, Val Loss: 0.0165739
2025-02-18 14:27:52,567 Epoch 18/2000
2025-02-18 14:28:35,055 Current Learning Rate: 0.0098014684
2025-02-18 14:28:37,323 Train Loss: 0.0178550, Val Loss: 0.0164465
2025-02-18 14:28:37,323 Epoch 19/2000
2025-02-18 14:29:19,996 Current Learning Rate: 0.0097789651
2025-02-18 14:29:21,663 Train Loss: 0.0176387, Val Loss: 0.0162635
2025-02-18 14:29:21,663 Epoch 20/2000
2025-02-18 14:30:04,707 Current Learning Rate: 0.0097552826
2025-02-18 14:30:06,649 Train Loss: 0.0174251, Val Loss: 0.0161026
2025-02-18 14:30:06,650 Epoch 21/2000
2025-02-18 14:30:48,728 Current Learning Rate: 0.0097304268
2025-02-18 14:30:50,911 Train Loss: 0.0172205, Val Loss: 0.0159079
2025-02-18 14:30:50,911 Epoch 22/2000
2025-02-18 14:31:32,310 Current Learning Rate: 0.0097044038
2025-02-18 14:31:34,096 Train Loss: 0.0169694, Val Loss: 0.0156002
2025-02-18 14:31:34,096 Epoch 23/2000
2025-02-18 14:32:15,744 Current Learning Rate: 0.0096772202
2025-02-18 14:32:17,783 Train Loss: 0.0165015, Val Loss: 0.0151188
2025-02-18 14:32:17,784 Epoch 24/2000
2025-02-18 14:32:59,680 Current Learning Rate: 0.0096488824
2025-02-18 14:33:00,999 Train Loss: 0.0158210, Val Loss: 0.0143949
2025-02-18 14:33:00,999 Epoch 25/2000
2025-02-18 14:33:44,305 Current Learning Rate: 0.0096193977
2025-02-18 14:33:46,362 Train Loss: 0.0150978, Val Loss: 0.0137453
2025-02-18 14:33:46,362 Epoch 26/2000
2025-02-18 14:34:27,838 Current Learning Rate: 0.0095887731
2025-02-18 14:34:29,394 Train Loss: 0.0146063, Val Loss: 0.0133372
2025-02-18 14:34:29,395 Epoch 27/2000
2025-02-18 14:35:12,328 Current Learning Rate: 0.0095570164
2025-02-18 14:35:14,297 Train Loss: 0.0141579, Val Loss: 0.0129903
2025-02-18 14:35:14,297 Epoch 28/2000
2025-02-18 14:35:56,478 Current Learning Rate: 0.0095241353
2025-02-18 14:35:58,229 Train Loss: 0.0138481, Val Loss: 0.0127644
2025-02-18 14:35:58,230 Epoch 29/2000
2025-02-18 14:36:41,151 Current Learning Rate: 0.0094901379
2025-02-18 14:36:42,490 Train Loss: 0.0135901, Val Loss: 0.0124894
2025-02-18 14:36:42,490 Epoch 30/2000
2025-02-18 14:37:25,197 Current Learning Rate: 0.0094550326
2025-02-18 14:37:26,963 Train Loss: 0.0133189, Val Loss: 0.0121462
2025-02-18 14:37:26,964 Epoch 31/2000
2025-02-18 14:38:08,257 Current Learning Rate: 0.0094188282
2025-02-18 14:38:09,109 Train Loss: 0.0128272, Val Loss: 0.0116701
2025-02-18 14:38:09,110 Epoch 32/2000
2025-02-18 14:38:52,114 Current Learning Rate: 0.0093815334
2025-02-18 14:38:53,648 Train Loss: 0.0122802, Val Loss: 0.0112547
2025-02-18 14:38:53,655 Epoch 33/2000
2025-02-18 14:39:36,240 Current Learning Rate: 0.0093431576
2025-02-18 14:39:37,614 Train Loss: 0.0117762, Val Loss: 0.0106204
2025-02-18 14:39:37,614 Epoch 34/2000
2025-02-18 14:40:19,881 Current Learning Rate: 0.0093037101
2025-02-18 14:40:21,787 Train Loss: 0.0112313, Val Loss: 0.0101279
2025-02-18 14:40:21,787 Epoch 35/2000
2025-02-18 14:41:03,572 Current Learning Rate: 0.0092632008
2025-02-18 14:41:05,186 Train Loss: 0.0108187, Val Loss: 0.0096379
2025-02-18 14:41:05,187 Epoch 36/2000
2025-02-18 14:41:48,547 Current Learning Rate: 0.0092216396
2025-02-18 14:41:50,333 Train Loss: 0.0102309, Val Loss: 0.0092521
2025-02-18 14:41:50,333 Epoch 37/2000
2025-02-18 14:42:32,710 Current Learning Rate: 0.0091790368
2025-02-18 14:42:34,137 Train Loss: 0.0098315, Val Loss: 0.0088337
2025-02-18 14:42:34,137 Epoch 38/2000
2025-02-18 14:43:17,308 Current Learning Rate: 0.0091354029
2025-02-18 14:43:18,961 Train Loss: 0.0093248, Val Loss: 0.0083890
2025-02-18 14:43:18,961 Epoch 39/2000
2025-02-18 14:44:01,556 Current Learning Rate: 0.0090907486
2025-02-18 14:44:04,120 Train Loss: 0.0087695, Val Loss: 0.0080588
2025-02-18 14:44:04,120 Epoch 40/2000
2025-02-18 14:44:45,580 Current Learning Rate: 0.0090450850
2025-02-18 14:44:47,208 Train Loss: 0.0081769, Val Loss: 0.0073063
2025-02-18 14:44:47,210 Epoch 41/2000
2025-02-18 14:45:29,054 Current Learning Rate: 0.0089984233
2025-02-18 14:45:30,702 Train Loss: 0.0076267, Val Loss: 0.0069956
2025-02-18 14:45:30,703 Epoch 42/2000
2025-02-18 14:46:14,279 Current Learning Rate: 0.0089507751
2025-02-18 14:46:14,280 Train Loss: 0.0076356, Val Loss: 0.0090246
2025-02-18 14:46:14,281 Epoch 43/2000
2025-02-18 14:46:57,793 Current Learning Rate: 0.0089021520
2025-02-18 14:46:59,597 Train Loss: 0.0074178, Val Loss: 0.0064407
2025-02-18 14:46:59,598 Epoch 44/2000
2025-02-18 14:47:43,250 Current Learning Rate: 0.0088525662
2025-02-18 14:47:45,064 Train Loss: 0.0068171, Val Loss: 0.0060696
2025-02-18 14:47:45,064 Epoch 45/2000
2025-02-18 14:48:27,630 Current Learning Rate: 0.0088020298
2025-02-18 14:48:29,252 Train Loss: 0.0066029, Val Loss: 0.0059524
2025-02-18 14:48:29,252 Epoch 46/2000
2025-02-18 14:49:11,638 Current Learning Rate: 0.0087505553
2025-02-18 14:49:13,527 Train Loss: 0.0065815, Val Loss: 0.0057815
2025-02-18 14:49:13,528 Epoch 47/2000
2025-02-18 14:49:56,170 Current Learning Rate: 0.0086981555
2025-02-18 14:49:56,171 Train Loss: 0.0065231, Val Loss: 0.0061614
2025-02-18 14:49:56,171 Epoch 48/2000
2025-02-18 14:50:38,244 Current Learning Rate: 0.0086448431
2025-02-18 14:50:39,788 Train Loss: 0.0062545, Val Loss: 0.0056254
2025-02-18 14:50:39,788 Epoch 49/2000
2025-02-18 14:51:21,523 Current Learning Rate: 0.0085906315
2025-02-18 14:51:23,034 Train Loss: 0.0062356, Val Loss: 0.0054859
2025-02-18 14:51:23,034 Epoch 50/2000
2025-02-18 14:52:04,824 Current Learning Rate: 0.0085355339
2025-02-18 14:52:06,781 Train Loss: 0.0059626, Val Loss: 0.0053286
2025-02-18 14:52:06,781 Epoch 51/2000
2025-02-18 14:52:48,477 Current Learning Rate: 0.0084795640
2025-02-18 14:52:50,316 Train Loss: 0.0060748, Val Loss: 0.0053129
2025-02-18 14:52:50,316 Epoch 52/2000
2025-02-18 14:53:33,232 Current Learning Rate: 0.0084227355
2025-02-18 14:53:35,167 Train Loss: 0.0054856, Val Loss: 0.0050178
2025-02-18 14:53:35,167 Epoch 53/2000
2025-02-18 14:54:18,383 Current Learning Rate: 0.0083650626
2025-02-18 14:54:20,319 Train Loss: 0.0056379, Val Loss: 0.0049119
2025-02-18 14:54:20,319 Epoch 54/2000
2025-02-18 14:55:03,575 Current Learning Rate: 0.0083065593
2025-02-18 14:55:03,576 Train Loss: 0.0057683, Val Loss: 0.0053156
2025-02-18 14:55:03,577 Epoch 55/2000
2025-02-18 14:55:45,603 Current Learning Rate: 0.0082472402
2025-02-18 14:55:46,977 Train Loss: 0.0053413, Val Loss: 0.0048144
2025-02-18 14:55:46,978 Epoch 56/2000
2025-02-18 14:56:28,648 Current Learning Rate: 0.0081871199
2025-02-18 14:56:30,211 Train Loss: 0.0051032, Val Loss: 0.0047444
2025-02-18 14:56:30,211 Epoch 57/2000
2025-02-18 14:57:11,673 Current Learning Rate: 0.0081262133
2025-02-18 14:57:13,453 Train Loss: 0.0049701, Val Loss: 0.0045479
2025-02-18 14:57:13,453 Epoch 58/2000
2025-02-18 14:57:54,813 Current Learning Rate: 0.0080645353
2025-02-18 14:57:54,814 Train Loss: 0.0047992, Val Loss: 0.0050299
2025-02-18 14:57:54,814 Epoch 59/2000
2025-02-18 14:58:38,162 Current Learning Rate: 0.0080021011
2025-02-18 14:58:40,130 Train Loss: 0.0049871, Val Loss: 0.0042919
2025-02-18 14:58:40,131 Epoch 60/2000
2025-02-18 14:59:21,637 Current Learning Rate: 0.0079389263
2025-02-18 14:59:21,638 Train Loss: 0.0046179, Val Loss: 0.0044405
2025-02-18 14:59:21,638 Epoch 61/2000
2025-02-18 15:00:04,326 Current Learning Rate: 0.0078750263
2025-02-18 15:00:04,327 Train Loss: 0.0049569, Val Loss: 0.0044025
2025-02-18 15:00:04,327 Epoch 62/2000
2025-02-18 15:00:46,724 Current Learning Rate: 0.0078104169
2025-02-18 15:00:46,724 Train Loss: 0.0047013, Val Loss: 0.0046409
2025-02-18 15:00:46,724 Epoch 63/2000
2025-02-18 15:01:29,451 Current Learning Rate: 0.0077451141
2025-02-18 15:01:30,719 Train Loss: 0.0044193, Val Loss: 0.0039515
2025-02-18 15:01:30,719 Epoch 64/2000
2025-02-18 15:02:13,483 Current Learning Rate: 0.0076791340
2025-02-18 15:02:13,484 Train Loss: 0.0046267, Val Loss: 0.0039819
2025-02-18 15:02:13,485 Epoch 65/2000
2025-02-18 15:02:55,725 Current Learning Rate: 0.0076124928
2025-02-18 15:02:56,885 Train Loss: 0.0042735, Val Loss: 0.0039007
2025-02-18 15:02:56,886 Epoch 66/2000
2025-02-18 15:03:38,702 Current Learning Rate: 0.0075452071
2025-02-18 15:03:40,434 Train Loss: 0.0040702, Val Loss: 0.0036998
2025-02-18 15:03:40,435 Epoch 67/2000
2025-02-18 15:04:21,978 Current Learning Rate: 0.0074772933
2025-02-18 15:04:21,979 Train Loss: 0.0041402, Val Loss: 0.0043896
2025-02-18 15:04:21,979 Epoch 68/2000
2025-02-18 15:05:05,501 Current Learning Rate: 0.0074087684
2025-02-18 15:05:05,502 Train Loss: 0.0040681, Val Loss: 0.0037126
2025-02-18 15:05:05,502 Epoch 69/2000
2025-02-18 15:05:47,627 Current Learning Rate: 0.0073396491
2025-02-18 15:05:49,693 Train Loss: 0.0041826, Val Loss: 0.0035981
2025-02-18 15:05:49,697 Epoch 70/2000
2025-02-18 15:06:31,219 Current Learning Rate: 0.0072699525
2025-02-18 15:06:33,095 Train Loss: 0.0039610, Val Loss: 0.0035859
2025-02-18 15:06:33,096 Epoch 71/2000
2025-02-18 15:07:16,333 Current Learning Rate: 0.0071996958
2025-02-18 15:07:16,334 Train Loss: 0.0040461, Val Loss: 0.0038279
2025-02-18 15:07:16,334 Epoch 72/2000
2025-02-18 15:07:59,643 Current Learning Rate: 0.0071288965
2025-02-18 15:08:01,314 Train Loss: 0.0038196, Val Loss: 0.0034883
2025-02-18 15:08:01,314 Epoch 73/2000
2025-02-18 15:08:44,217 Current Learning Rate: 0.0070575718
2025-02-18 15:08:44,218 Train Loss: 0.0037394, Val Loss: 0.0035490
2025-02-18 15:08:44,219 Epoch 74/2000
2025-02-18 15:09:26,810 Current Learning Rate: 0.0069857395
2025-02-18 15:09:26,811 Train Loss: 0.0039330, Val Loss: 0.0036724
2025-02-18 15:09:26,821 Epoch 75/2000
2025-02-18 15:10:09,949 Current Learning Rate: 0.0069134172
2025-02-18 15:10:09,950 Train Loss: 0.0036523, Val Loss: 0.0037484
2025-02-18 15:10:09,950 Epoch 76/2000
2025-02-18 15:10:52,358 Current Learning Rate: 0.0068406228
2025-02-18 15:10:53,681 Train Loss: 0.0038443, Val Loss: 0.0034668
2025-02-18 15:10:53,690 Epoch 77/2000
2025-02-18 15:11:36,386 Current Learning Rate: 0.0067673742
2025-02-18 15:11:38,111 Train Loss: 0.0038872, Val Loss: 0.0033315
2025-02-18 15:11:38,111 Epoch 78/2000
2025-02-18 15:12:20,782 Current Learning Rate: 0.0066936896
2025-02-18 15:12:22,756 Train Loss: 0.0038132, Val Loss: 0.0032982
2025-02-18 15:12:22,756 Epoch 79/2000
2025-02-18 15:13:05,301 Current Learning Rate: 0.0066195871
2025-02-18 15:13:07,177 Train Loss: 0.0035646, Val Loss: 0.0031638
2025-02-18 15:13:07,178 Epoch 80/2000
2025-02-18 15:13:50,518 Current Learning Rate: 0.0065450850
2025-02-18 15:13:50,519 Train Loss: 0.0034006, Val Loss: 0.0031946
2025-02-18 15:13:50,519 Epoch 81/2000
2025-02-18 15:14:33,180 Current Learning Rate: 0.0064702016
2025-02-18 15:14:34,976 Train Loss: 0.0033588, Val Loss: 0.0030893
2025-02-18 15:14:34,977 Epoch 82/2000
2025-02-18 15:15:17,469 Current Learning Rate: 0.0063949555
2025-02-18 15:15:19,359 Train Loss: 0.0033879, Val Loss: 0.0030405
2025-02-18 15:15:19,359 Epoch 83/2000
2025-02-18 15:16:01,120 Current Learning Rate: 0.0063193652
2025-02-18 15:16:03,834 Train Loss: 0.0031879, Val Loss: 0.0029718
2025-02-18 15:16:03,835 Epoch 84/2000
2025-02-18 15:16:45,422 Current Learning Rate: 0.0062434494
2025-02-18 15:16:45,423 Train Loss: 0.0032266, Val Loss: 0.0031460
2025-02-18 15:16:45,423 Epoch 85/2000
2025-02-18 15:17:28,969 Current Learning Rate: 0.0061672268
2025-02-18 15:17:30,500 Train Loss: 0.0034299, Val Loss: 0.0029372
2025-02-18 15:17:30,501 Epoch 86/2000
2025-02-18 15:18:13,226 Current Learning Rate: 0.0060907162
2025-02-18 15:18:13,227 Train Loss: 0.0031645, Val Loss: 0.0029600
2025-02-18 15:18:13,228 Epoch 87/2000
2025-02-18 15:18:55,920 Current Learning Rate: 0.0060139365
2025-02-18 15:18:55,921 Train Loss: 0.0034704, Val Loss: 0.0032086
2025-02-18 15:18:55,921 Epoch 88/2000
2025-02-18 15:19:38,466 Current Learning Rate: 0.0059369066
2025-02-18 15:19:40,324 Train Loss: 0.0032061, Val Loss: 0.0029067
2025-02-18 15:19:40,325 Epoch 89/2000
2025-02-18 15:20:22,570 Current Learning Rate: 0.0058596455
2025-02-18 15:20:24,452 Train Loss: 0.0030000, Val Loss: 0.0028417
2025-02-18 15:20:24,452 Epoch 90/2000
2025-02-18 15:21:05,591 Current Learning Rate: 0.0057821723
2025-02-18 15:21:06,909 Train Loss: 0.0029832, Val Loss: 0.0028316
2025-02-18 15:21:06,909 Epoch 91/2000
2025-02-18 15:21:48,842 Current Learning Rate: 0.0057045062
2025-02-18 15:21:48,843 Train Loss: 0.0031305, Val Loss: 0.0028579
2025-02-18 15:21:48,843 Epoch 92/2000
2025-02-18 15:22:32,087 Current Learning Rate: 0.0056266662
2025-02-18 15:22:32,088 Train Loss: 0.0030638, Val Loss: 0.0029005
2025-02-18 15:22:32,088 Epoch 93/2000
2025-02-18 15:23:15,526 Current Learning Rate: 0.0055486716
2025-02-18 15:23:17,138 Train Loss: 0.0031297, Val Loss: 0.0028207
2025-02-18 15:23:17,138 Epoch 94/2000
2025-02-18 15:23:59,840 Current Learning Rate: 0.0054705416
2025-02-18 15:23:59,841 Train Loss: 0.0031764, Val Loss: 0.0029541
2025-02-18 15:23:59,841 Epoch 95/2000
2025-02-18 15:24:42,563 Current Learning Rate: 0.0053922955
2025-02-18 15:24:42,564 Train Loss: 0.0028410, Val Loss: 0.0028266
2025-02-18 15:24:42,564 Epoch 96/2000
2025-02-18 15:25:25,665 Current Learning Rate: 0.0053139526
2025-02-18 15:25:25,666 Train Loss: 0.0031975, Val Loss: 0.0028658
2025-02-18 15:25:25,666 Epoch 97/2000
2025-02-18 15:26:08,886 Current Learning Rate: 0.0052355323
2025-02-18 15:26:10,570 Train Loss: 0.0029171, Val Loss: 0.0027451
2025-02-18 15:26:10,581 Epoch 98/2000
2025-02-18 15:26:53,594 Current Learning Rate: 0.0051570538
2025-02-18 15:26:55,286 Train Loss: 0.0030150, Val Loss: 0.0027333
2025-02-18 15:26:55,286 Epoch 99/2000
2025-02-18 15:27:37,802 Current Learning Rate: 0.0050785366
2025-02-18 15:27:39,704 Train Loss: 0.0029330, Val Loss: 0.0027265
2025-02-18 15:27:39,705 Epoch 100/2000
2025-02-18 15:28:21,599 Current Learning Rate: 0.0050000000
2025-02-18 15:28:23,311 Train Loss: 0.0028290, Val Loss: 0.0026971
2025-02-18 15:28:23,311 Epoch 101/2000
2025-02-18 15:29:05,828 Current Learning Rate: 0.0049214634
2025-02-18 15:29:07,674 Train Loss: 0.0028858, Val Loss: 0.0026960
2025-02-18 15:29:07,674 Epoch 102/2000
2025-02-18 15:29:49,923 Current Learning Rate: 0.0048429462
2025-02-18 15:29:51,663 Train Loss: 0.0029532, Val Loss: 0.0026186
2025-02-18 15:29:51,663 Epoch 103/2000
2025-02-18 15:30:33,303 Current Learning Rate: 0.0047644677
2025-02-18 15:30:33,304 Train Loss: 0.0027671, Val Loss: 0.0026594
2025-02-18 15:30:33,305 Epoch 104/2000
2025-02-18 15:31:16,313 Current Learning Rate: 0.0046860474
2025-02-18 15:31:16,316 Train Loss: 0.0029455, Val Loss: 0.0027470
2025-02-18 15:31:16,317 Epoch 105/2000
2025-02-18 15:31:58,554 Current Learning Rate: 0.0046077045
2025-02-18 15:31:58,555 Train Loss: 0.0029949, Val Loss: 0.0027208
2025-02-18 15:31:58,555 Epoch 106/2000
2025-02-18 15:32:41,495 Current Learning Rate: 0.0045294584
2025-02-18 15:32:41,496 Train Loss: 0.0031252, Val Loss: 0.0027911
2025-02-18 15:32:41,496 Epoch 107/2000
2025-02-18 15:33:23,791 Current Learning Rate: 0.0044513284
2025-02-18 15:33:25,313 Train Loss: 0.0027322, Val Loss: 0.0025305
2025-02-18 15:33:25,314 Epoch 108/2000
2025-02-18 15:34:07,154 Current Learning Rate: 0.0043733338
2025-02-18 15:34:07,155 Train Loss: 0.0027422, Val Loss: 0.0025760
2025-02-18 15:34:07,155 Epoch 109/2000
2025-02-18 15:34:51,055 Current Learning Rate: 0.0042954938
2025-02-18 15:34:51,056 Train Loss: 0.0030014, Val Loss: 0.0025514
2025-02-18 15:34:51,056 Epoch 110/2000
2025-02-18 15:35:34,206 Current Learning Rate: 0.0042178277
2025-02-18 15:35:34,207 Train Loss: 0.0030148, Val Loss: 0.0026140
2025-02-18 15:35:34,207 Epoch 111/2000
2025-02-18 15:36:16,790 Current Learning Rate: 0.0041403545
2025-02-18 15:36:18,205 Train Loss: 0.0026457, Val Loss: 0.0025104
2025-02-18 15:36:18,205 Epoch 112/2000
2025-02-18 15:37:01,153 Current Learning Rate: 0.0040630934
2025-02-18 15:37:03,763 Train Loss: 0.0026000, Val Loss: 0.0024824
2025-02-18 15:37:03,763 Epoch 113/2000
2025-02-18 15:37:45,215 Current Learning Rate: 0.0039860635
2025-02-18 15:37:46,673 Train Loss: 0.0027027, Val Loss: 0.0024382
2025-02-18 15:37:46,674 Epoch 114/2000
2025-02-18 15:38:28,234 Current Learning Rate: 0.0039092838
2025-02-18 15:38:28,235 Train Loss: 0.0026419, Val Loss: 0.0024624
2025-02-18 15:38:28,235 Epoch 115/2000
2025-02-18 15:39:11,099 Current Learning Rate: 0.0038327732
2025-02-18 15:39:11,100 Train Loss: 0.0031512, Val Loss: 0.0024630
2025-02-18 15:39:11,100 Epoch 116/2000
2025-02-18 15:39:53,683 Current Learning Rate: 0.0037565506
2025-02-18 15:39:53,684 Train Loss: 0.0027621, Val Loss: 0.0024817
2025-02-18 15:39:53,684 Epoch 117/2000
2025-02-18 15:40:37,852 Current Learning Rate: 0.0036806348
2025-02-18 15:40:37,853 Train Loss: 0.0027294, Val Loss: 0.0025535
2025-02-18 15:40:37,853 Epoch 118/2000
2025-02-18 15:41:20,361 Current Learning Rate: 0.0036050445
2025-02-18 15:41:20,362 Train Loss: 0.0025651, Val Loss: 0.0025561
2025-02-18 15:41:20,362 Epoch 119/2000
2025-02-18 15:42:02,818 Current Learning Rate: 0.0035297984
2025-02-18 15:42:02,818 Train Loss: 0.0031162, Val Loss: 0.0025939
2025-02-18 15:42:02,819 Epoch 120/2000
2025-02-18 15:42:45,830 Current Learning Rate: 0.0034549150
2025-02-18 15:42:45,831 Train Loss: 0.0027383, Val Loss: 0.0025477
2025-02-18 15:42:45,831 Epoch 121/2000
2025-02-18 15:43:28,082 Current Learning Rate: 0.0033804129
2025-02-18 15:43:29,869 Train Loss: 0.0027425, Val Loss: 0.0023956
2025-02-18 15:43:29,869 Epoch 122/2000
2025-02-18 15:44:12,125 Current Learning Rate: 0.0033063104
2025-02-18 15:44:12,126 Train Loss: 0.0026657, Val Loss: 0.0024754
2025-02-18 15:44:12,127 Epoch 123/2000
2025-02-18 15:44:55,260 Current Learning Rate: 0.0032326258
2025-02-18 15:44:57,403 Train Loss: 0.0024242, Val Loss: 0.0023507
2025-02-18 15:44:57,403 Epoch 124/2000
2025-02-18 15:45:40,537 Current Learning Rate: 0.0031593772
2025-02-18 15:45:40,537 Train Loss: 0.0025713, Val Loss: 0.0023812
2025-02-18 15:45:40,538 Epoch 125/2000
2025-02-18 15:46:23,441 Current Learning Rate: 0.0030865828
2025-02-18 15:46:25,521 Train Loss: 0.0025928, Val Loss: 0.0023480
2025-02-18 15:46:25,521 Epoch 126/2000
2025-02-18 15:47:07,296 Current Learning Rate: 0.0030142605
2025-02-18 15:47:08,912 Train Loss: 0.0024050, Val Loss: 0.0023392
2025-02-18 15:47:08,914 Epoch 127/2000
2025-02-18 15:47:50,737 Current Learning Rate: 0.0029424282
2025-02-18 15:47:52,171 Train Loss: 0.0025779, Val Loss: 0.0023248
2025-02-18 15:47:52,171 Epoch 128/2000
2025-02-18 15:48:34,452 Current Learning Rate: 0.0028711035
2025-02-18 15:48:34,453 Train Loss: 0.0025542, Val Loss: 0.0024302
2025-02-18 15:48:34,453 Epoch 129/2000
2025-02-18 15:49:17,368 Current Learning Rate: 0.0028003042
2025-02-18 15:49:17,369 Train Loss: 0.0027851, Val Loss: 0.0023806
2025-02-18 15:49:17,369 Epoch 130/2000
2025-02-18 15:49:59,989 Current Learning Rate: 0.0027300475
2025-02-18 15:49:59,990 Train Loss: 0.0024214, Val Loss: 0.0023312
2025-02-18 15:49:59,991 Epoch 131/2000
2025-02-18 15:50:43,407 Current Learning Rate: 0.0026603509
2025-02-18 15:50:45,584 Train Loss: 0.0025682, Val Loss: 0.0022957
2025-02-18 15:50:45,584 Epoch 132/2000
2025-02-18 15:51:28,546 Current Learning Rate: 0.0025912316
2025-02-18 15:51:30,558 Train Loss: 0.0023948, Val Loss: 0.0022712
2025-02-18 15:51:30,559 Epoch 133/2000
2025-02-18 15:52:13,160 Current Learning Rate: 0.0025227067
2025-02-18 15:52:13,161 Train Loss: 0.0026540, Val Loss: 0.0023643
2025-02-18 15:52:13,161 Epoch 134/2000
2025-02-18 15:52:55,851 Current Learning Rate: 0.0024547929
2025-02-18 15:52:55,852 Train Loss: 0.0026912, Val Loss: 0.0022917
2025-02-18 15:52:55,853 Epoch 135/2000
2025-02-18 15:53:38,329 Current Learning Rate: 0.0023875072
2025-02-18 15:53:39,791 Train Loss: 0.0023403, Val Loss: 0.0022606
2025-02-18 15:53:39,791 Epoch 136/2000
2025-02-18 15:54:21,966 Current Learning Rate: 0.0023208660
2025-02-18 15:54:21,967 Train Loss: 0.0025837, Val Loss: 0.0022768
2025-02-18 15:54:21,967 Epoch 137/2000
2025-02-18 15:55:04,893 Current Learning Rate: 0.0022548859
2025-02-18 15:55:06,420 Train Loss: 0.0022579, Val Loss: 0.0022366
2025-02-18 15:55:06,420 Epoch 138/2000
2025-02-18 15:55:49,472 Current Learning Rate: 0.0021895831
2025-02-18 15:55:51,165 Train Loss: 0.0023904, Val Loss: 0.0022284
2025-02-18 15:55:51,165 Epoch 139/2000
2025-02-18 15:56:33,771 Current Learning Rate: 0.0021249737
2025-02-18 15:56:33,772 Train Loss: 0.0024008, Val Loss: 0.0022358
2025-02-18 15:56:33,772 Epoch 140/2000
2025-02-18 15:57:16,026 Current Learning Rate: 0.0020610737
2025-02-18 15:57:17,931 Train Loss: 0.0022246, Val Loss: 0.0022110
2025-02-18 15:57:17,932 Epoch 141/2000
2025-02-18 15:57:59,378 Current Learning Rate: 0.0019978989
2025-02-18 15:57:59,378 Train Loss: 0.0023086, Val Loss: 0.0022171
2025-02-18 15:57:59,379 Epoch 142/2000
2025-02-18 15:58:41,749 Current Learning Rate: 0.0019354647
2025-02-18 15:58:42,831 Train Loss: 0.0022637, Val Loss: 0.0021975
2025-02-18 15:58:42,831 Epoch 143/2000
2025-02-18 15:59:24,774 Current Learning Rate: 0.0018737867
2025-02-18 15:59:24,776 Train Loss: 0.0024424, Val Loss: 0.0022221
2025-02-18 15:59:24,776 Epoch 144/2000
2025-02-18 16:00:08,319 Current Learning Rate: 0.0018128801
2025-02-18 16:00:08,319 Train Loss: 0.0022830, Val Loss: 0.0022219
2025-02-18 16:00:08,320 Epoch 145/2000
2025-02-18 16:00:50,699 Current Learning Rate: 0.0017527598
2025-02-18 16:00:50,700 Train Loss: 0.0025422, Val Loss: 0.0022204
2025-02-18 16:00:50,701 Epoch 146/2000
2025-02-18 16:01:33,665 Current Learning Rate: 0.0016934407
2025-02-18 16:01:35,648 Train Loss: 0.0022766, Val Loss: 0.0021824
2025-02-18 16:01:35,648 Epoch 147/2000
2025-02-18 16:02:18,678 Current Learning Rate: 0.0016349374
2025-02-18 16:02:18,679 Train Loss: 0.0023299, Val Loss: 0.0022020
2025-02-18 16:02:18,679 Epoch 148/2000
2025-02-18 16:03:01,210 Current Learning Rate: 0.0015772645
2025-02-18 16:03:01,210 Train Loss: 0.0023008, Val Loss: 0.0022081
2025-02-18 16:03:01,211 Epoch 149/2000
2025-02-18 16:03:44,894 Current Learning Rate: 0.0015204360
2025-02-18 16:03:46,886 Train Loss: 0.0022495, Val Loss: 0.0021472
2025-02-18 16:03:46,886 Epoch 150/2000
2025-02-18 16:04:28,626 Current Learning Rate: 0.0014644661
2025-02-18 16:04:29,826 Train Loss: 0.0022816, Val Loss: 0.0021302
2025-02-18 16:04:29,827 Epoch 151/2000
2025-02-18 16:05:13,144 Current Learning Rate: 0.0014093685
2025-02-18 16:05:13,145 Train Loss: 0.0025645, Val Loss: 0.0021428
2025-02-18 16:05:13,145 Epoch 152/2000
2025-02-18 16:05:55,306 Current Learning Rate: 0.0013551569
2025-02-18 16:05:55,307 Train Loss: 0.0024435, Val Loss: 0.0021654
2025-02-18 16:05:55,307 Epoch 153/2000
2025-02-18 16:06:37,669 Current Learning Rate: 0.0013018445
2025-02-18 16:06:39,081 Train Loss: 0.0025198, Val Loss: 0.0021174
2025-02-18 16:06:39,088 Epoch 154/2000
2025-02-18 16:07:22,351 Current Learning Rate: 0.0012494447
2025-02-18 16:07:24,243 Train Loss: 0.0021932, Val Loss: 0.0020996
2025-02-18 16:07:24,244 Epoch 155/2000
2025-02-18 16:08:07,232 Current Learning Rate: 0.0011979702
2025-02-18 16:08:07,233 Train Loss: 0.0021102, Val Loss: 0.0021050
2025-02-18 16:08:07,234 Epoch 156/2000
2025-02-18 16:08:50,923 Current Learning Rate: 0.0011474338
2025-02-18 16:08:52,954 Train Loss: 0.0021750, Val Loss: 0.0020915
2025-02-18 16:08:52,954 Epoch 157/2000
2025-02-18 16:09:35,087 Current Learning Rate: 0.0010978480
2025-02-18 16:09:35,088 Train Loss: 0.0021748, Val Loss: 0.0021046
2025-02-18 16:09:35,088 Epoch 158/2000
2025-02-18 16:10:18,820 Current Learning Rate: 0.0010492249
2025-02-18 16:10:18,821 Train Loss: 0.0022929, Val Loss: 0.0020975
2025-02-18 16:10:18,821 Epoch 159/2000
2025-02-18 16:11:02,377 Current Learning Rate: 0.0010015767
2025-02-18 16:11:02,377 Train Loss: 0.0022445, Val Loss: 0.0020939
2025-02-18 16:11:02,378 Epoch 160/2000
2025-02-18 16:11:45,112 Current Learning Rate: 0.0009549150
2025-02-18 16:11:47,072 Train Loss: 0.0023150, Val Loss: 0.0020744
2025-02-18 16:11:47,072 Epoch 161/2000
2025-02-18 16:12:28,392 Current Learning Rate: 0.0009092514
2025-02-18 16:12:29,439 Train Loss: 0.0023384, Val Loss: 0.0020734
2025-02-18 16:12:29,442 Epoch 162/2000
2025-02-18 16:13:11,385 Current Learning Rate: 0.0008645971
2025-02-18 16:13:11,386 Train Loss: 0.0024140, Val Loss: 0.0020823
2025-02-18 16:13:11,386 Epoch 163/2000
2025-02-18 16:13:53,692 Current Learning Rate: 0.0008209632
2025-02-18 16:13:53,693 Train Loss: 0.0024373, Val Loss: 0.0020741
2025-02-18 16:13:53,693 Epoch 164/2000
2025-02-18 16:14:36,506 Current Learning Rate: 0.0007783604
2025-02-18 16:14:38,472 Train Loss: 0.0022746, Val Loss: 0.0020577
2025-02-18 16:14:38,473 Epoch 165/2000
2025-02-18 16:15:21,574 Current Learning Rate: 0.0007367992
2025-02-18 16:15:21,575 Train Loss: 0.0022988, Val Loss: 0.0020613
2025-02-18 16:15:21,575 Epoch 166/2000
2025-02-18 16:16:04,434 Current Learning Rate: 0.0006962899
2025-02-18 16:16:05,795 Train Loss: 0.0023153, Val Loss: 0.0020529
2025-02-18 16:16:05,796 Epoch 167/2000
2025-02-18 16:16:47,301 Current Learning Rate: 0.0006568424
2025-02-18 16:16:48,693 Train Loss: 0.0021537, Val Loss: 0.0020437
2025-02-18 16:16:48,694 Epoch 168/2000
2025-02-18 16:17:32,178 Current Learning Rate: 0.0006184666
2025-02-18 16:17:34,047 Train Loss: 0.0020853, Val Loss: 0.0020344
2025-02-18 16:17:34,047 Epoch 169/2000
2025-02-18 16:18:16,768 Current Learning Rate: 0.0005811718
2025-02-18 16:18:18,900 Train Loss: 0.0022062, Val Loss: 0.0020296
2025-02-18 16:18:18,900 Epoch 170/2000
2025-02-18 16:19:01,729 Current Learning Rate: 0.0005449674
2025-02-18 16:19:03,786 Train Loss: 0.0020276, Val Loss: 0.0020274
2025-02-18 16:19:03,786 Epoch 171/2000
2025-02-18 16:19:45,107 Current Learning Rate: 0.0005098621
2025-02-18 16:19:46,453 Train Loss: 0.0022592, Val Loss: 0.0020274
2025-02-18 16:19:46,454 Epoch 172/2000
2025-02-18 16:20:28,147 Current Learning Rate: 0.0004758647
2025-02-18 16:20:28,148 Train Loss: 0.0022123, Val Loss: 0.0020308
2025-02-18 16:20:28,148 Epoch 173/2000
2025-02-18 16:21:11,787 Current Learning Rate: 0.0004429836
2025-02-18 16:21:13,859 Train Loss: 0.0021227, Val Loss: 0.0020174
2025-02-18 16:21:13,860 Epoch 174/2000
2025-02-18 16:21:55,363 Current Learning Rate: 0.0004112269
2025-02-18 16:21:57,456 Train Loss: 0.0021057, Val Loss: 0.0020160
2025-02-18 16:21:57,457 Epoch 175/2000
2025-02-18 16:22:39,165 Current Learning Rate: 0.0003806023
2025-02-18 16:22:39,166 Train Loss: 0.0022247, Val Loss: 0.0020161
2025-02-18 16:22:39,166 Epoch 176/2000
2025-02-18 16:23:22,391 Current Learning Rate: 0.0003511176
2025-02-18 16:23:24,313 Train Loss: 0.0020290, Val Loss: 0.0020113
2025-02-18 16:23:24,313 Epoch 177/2000
2025-02-18 16:24:07,311 Current Learning Rate: 0.0003227798
2025-02-18 16:24:08,888 Train Loss: 0.0020590, Val Loss: 0.0020087
2025-02-18 16:24:08,889 Epoch 178/2000
2025-02-18 16:24:51,745 Current Learning Rate: 0.0002955962
2025-02-18 16:24:51,746 Train Loss: 0.0021380, Val Loss: 0.0020131
2025-02-18 16:24:51,746 Epoch 179/2000
2025-02-18 16:25:33,992 Current Learning Rate: 0.0002695732
2025-02-18 16:25:35,918 Train Loss: 0.0021452, Val Loss: 0.0020065
2025-02-18 16:25:35,918 Epoch 180/2000
2025-02-18 16:26:18,046 Current Learning Rate: 0.0002447174
2025-02-18 16:26:18,048 Train Loss: 0.0022274, Val Loss: 0.0020067
2025-02-18 16:26:18,048 Epoch 181/2000
2025-02-18 16:27:01,311 Current Learning Rate: 0.0002210349
2025-02-18 16:27:04,017 Train Loss: 0.0021063, Val Loss: 0.0020031
2025-02-18 16:27:04,018 Epoch 182/2000
2025-02-18 16:27:46,352 Current Learning Rate: 0.0001985316
2025-02-18 16:27:46,353 Train Loss: 0.0021554, Val Loss: 0.0020034
2025-02-18 16:27:46,353 Epoch 183/2000
2025-02-18 16:28:29,309 Current Learning Rate: 0.0001772129
2025-02-18 16:28:30,795 Train Loss: 0.0024092, Val Loss: 0.0020027
2025-02-18 16:28:30,795 Epoch 184/2000
2025-02-18 16:29:12,078 Current Learning Rate: 0.0001570842
2025-02-18 16:29:13,558 Train Loss: 0.0020361, Val Loss: 0.0019969
2025-02-18 16:29:13,559 Epoch 185/2000
2025-02-18 16:29:56,010 Current Learning Rate: 0.0001381504
2025-02-18 16:29:57,610 Train Loss: 0.0021787, Val Loss: 0.0019946
2025-02-18 16:29:57,626 Epoch 186/2000
2025-02-18 16:30:39,171 Current Learning Rate: 0.0001204162
2025-02-18 16:30:40,913 Train Loss: 0.0019766, Val Loss: 0.0019902
2025-02-18 16:30:40,913 Epoch 187/2000
2025-02-18 16:31:23,907 Current Learning Rate: 0.0001038859
2025-02-18 16:31:25,253 Train Loss: 0.0022846, Val Loss: 0.0019884
2025-02-18 16:31:25,254 Epoch 188/2000
2025-02-18 16:32:08,068 Current Learning Rate: 0.0000885637
2025-02-18 16:32:09,313 Train Loss: 0.0020690, Val Loss: 0.0019866
2025-02-18 16:32:09,313 Epoch 189/2000
2025-02-18 16:32:51,798 Current Learning Rate: 0.0000744534
2025-02-18 16:32:53,347 Train Loss: 0.0021456, Val Loss: 0.0019859
2025-02-18 16:32:53,347 Epoch 190/2000
2025-02-18 16:33:35,036 Current Learning Rate: 0.0000615583
2025-02-18 16:33:35,037 Train Loss: 0.0020096, Val Loss: 0.0019868
2025-02-18 16:33:35,037 Epoch 191/2000
2025-02-18 16:34:17,951 Current Learning Rate: 0.0000498817
2025-02-18 16:34:17,951 Train Loss: 0.0021014, Val Loss: 0.0019870
2025-02-18 16:34:17,952 Epoch 192/2000
2025-02-18 16:35:00,377 Current Learning Rate: 0.0000394265
2025-02-18 16:35:01,751 Train Loss: 0.0021133, Val Loss: 0.0019855
2025-02-18 16:35:01,751 Epoch 193/2000
2025-02-18 16:35:43,333 Current Learning Rate: 0.0000301952
2025-02-18 16:35:43,337 Train Loss: 0.0020557, Val Loss: 0.0019860
2025-02-18 16:35:43,338 Epoch 194/2000
2025-02-18 16:36:26,163 Current Learning Rate: 0.0000221902
2025-02-18 16:36:27,830 Train Loss: 0.0020902, Val Loss: 0.0019851
2025-02-18 16:36:27,831 Epoch 195/2000
2025-02-18 16:37:09,739 Current Learning Rate: 0.0000154133
2025-02-18 16:37:11,376 Train Loss: 0.0020577, Val Loss: 0.0019844
2025-02-18 16:37:11,376 Epoch 196/2000
2025-02-18 16:37:52,870 Current Learning Rate: 0.0000098664
2025-02-18 16:37:54,391 Train Loss: 0.0021702, Val Loss: 0.0019841
2025-02-18 16:37:54,392 Epoch 197/2000
2025-02-18 16:38:36,351 Current Learning Rate: 0.0000055506
2025-02-18 16:38:38,011 Train Loss: 0.0021440, Val Loss: 0.0019836
2025-02-18 16:38:38,012 Epoch 198/2000
2025-02-18 16:39:19,730 Current Learning Rate: 0.0000024672
2025-02-18 16:39:21,329 Train Loss: 0.0022741, Val Loss: 0.0019835
2025-02-18 16:39:21,330 Epoch 199/2000
2025-02-18 16:40:04,695 Current Learning Rate: 0.0000006168
2025-02-18 16:40:06,773 Train Loss: 0.0020641, Val Loss: 0.0019835
2025-02-18 16:40:06,774 Epoch 200/2000
2025-02-18 16:40:49,032 Current Learning Rate: 0.0000000000
2025-02-18 16:40:51,054 Train Loss: 0.0020595, Val Loss: 0.0019833
2025-02-18 16:40:51,055 Epoch 201/2000
2025-02-18 16:41:34,126 Current Learning Rate: 0.0000006168
2025-02-18 16:41:34,126 Train Loss: 0.0020695, Val Loss: 0.0019834
2025-02-18 16:41:34,126 Epoch 202/2000
2025-02-18 16:42:16,596 Current Learning Rate: 0.0000024672
2025-02-18 16:42:16,596 Train Loss: 0.0020921, Val Loss: 0.0019834
2025-02-18 16:42:16,596 Epoch 203/2000
2025-02-18 16:42:59,368 Current Learning Rate: 0.0000055506
2025-02-18 16:42:59,369 Train Loss: 0.0021943, Val Loss: 0.0019834
2025-02-18 16:42:59,369 Epoch 204/2000
2025-02-18 16:43:42,953 Current Learning Rate: 0.0000098664
2025-02-18 16:43:42,954 Train Loss: 0.0020710, Val Loss: 0.0019834
2025-02-18 16:43:42,955 Epoch 205/2000
2025-02-18 16:44:26,379 Current Learning Rate: 0.0000154133
2025-02-18 16:44:26,380 Train Loss: 0.0020787, Val Loss: 0.0019834
2025-02-18 16:44:26,380 Epoch 206/2000
2025-02-18 16:45:08,473 Current Learning Rate: 0.0000221902
2025-02-18 16:45:08,474 Train Loss: 0.0021324, Val Loss: 0.0019837
2025-02-18 16:45:08,474 Epoch 207/2000
2025-02-18 16:45:51,237 Current Learning Rate: 0.0000301952
2025-02-18 16:45:51,237 Train Loss: 0.0020701, Val Loss: 0.0019840
2025-02-18 16:45:51,237 Epoch 208/2000
2025-02-18 16:46:34,893 Current Learning Rate: 0.0000394265
2025-02-18 16:46:34,893 Train Loss: 0.0023016, Val Loss: 0.0019862
2025-02-18 16:46:34,894 Epoch 209/2000
2025-02-18 16:47:17,151 Current Learning Rate: 0.0000498817
2025-02-18 16:47:17,151 Train Loss: 0.0021189, Val Loss: 0.0019850
2025-02-18 16:47:17,151 Epoch 210/2000
2025-02-18 16:48:00,254 Current Learning Rate: 0.0000615583
2025-02-18 16:48:00,255 Train Loss: 0.0020372, Val Loss: 0.0019842
2025-02-18 16:48:00,255 Epoch 211/2000
2025-02-18 16:48:42,868 Current Learning Rate: 0.0000744534
2025-02-18 16:48:44,324 Train Loss: 0.0020863, Val Loss: 0.0019831
2025-02-18 16:48:44,324 Epoch 212/2000
2025-02-18 16:49:25,874 Current Learning Rate: 0.0000885637
2025-02-18 16:49:27,615 Train Loss: 0.0020293, Val Loss: 0.0019824
2025-02-18 16:49:27,616 Epoch 213/2000
2025-02-18 16:50:10,728 Current Learning Rate: 0.0001038859
2025-02-18 16:50:10,728 Train Loss: 0.0020420, Val Loss: 0.0019828
2025-02-18 16:50:10,728 Epoch 214/2000
2025-02-18 16:50:53,667 Current Learning Rate: 0.0001204162
2025-02-18 16:50:54,850 Train Loss: 0.0021052, Val Loss: 0.0019823
2025-02-18 16:50:54,850 Epoch 215/2000
2025-02-18 16:51:37,062 Current Learning Rate: 0.0001381504
2025-02-18 16:51:37,063 Train Loss: 0.0024028, Val Loss: 0.0019872
2025-02-18 16:51:37,064 Epoch 216/2000
2025-02-18 16:52:19,490 Current Learning Rate: 0.0001570842
2025-02-18 16:52:19,490 Train Loss: 0.0022716, Val Loss: 0.0019895
2025-02-18 16:52:19,491 Epoch 217/2000
2025-02-18 16:53:02,683 Current Learning Rate: 0.0001772129
2025-02-18 16:53:02,684 Train Loss: 0.0022299, Val Loss: 0.0019912
2025-02-18 16:53:02,684 Epoch 218/2000
2025-02-18 16:53:46,070 Current Learning Rate: 0.0001985316
2025-02-18 16:53:46,070 Train Loss: 0.0021929, Val Loss: 0.0019872
2025-02-18 16:53:46,070 Epoch 219/2000
2025-02-18 16:54:28,333 Current Learning Rate: 0.0002210349
2025-02-18 16:54:28,334 Train Loss: 0.0026620, Val Loss: 0.0019922
2025-02-18 16:54:28,334 Epoch 220/2000
2025-02-18 16:55:11,390 Current Learning Rate: 0.0002447174
2025-02-18 16:55:11,391 Train Loss: 0.0025068, Val Loss: 0.0020201
2025-02-18 16:55:11,401 Epoch 221/2000
2025-02-18 16:55:54,526 Current Learning Rate: 0.0002695732
2025-02-18 16:55:54,527 Train Loss: 0.0021727, Val Loss: 0.0019875
2025-02-18 16:55:54,527 Epoch 222/2000
2025-02-18 16:56:37,924 Current Learning Rate: 0.0002955962
2025-02-18 16:56:37,924 Train Loss: 0.0019936, Val Loss: 0.0019841
2025-02-18 16:56:37,925 Epoch 223/2000
2025-02-18 16:57:19,772 Current Learning Rate: 0.0003227798
2025-02-18 16:57:19,772 Train Loss: 0.0022919, Val Loss: 0.0019945
2025-02-18 16:57:19,773 Epoch 224/2000
2025-02-18 16:58:03,506 Current Learning Rate: 0.0003511176
2025-02-18 16:58:05,072 Train Loss: 0.0021292, Val Loss: 0.0019816
2025-02-18 16:58:05,073 Epoch 225/2000
2025-02-18 16:58:46,452 Current Learning Rate: 0.0003806023
2025-02-18 16:58:46,454 Train Loss: 0.0020398, Val Loss: 0.0019823
2025-02-18 16:58:46,454 Epoch 226/2000
2025-02-18 16:59:29,473 Current Learning Rate: 0.0004112269
2025-02-18 16:59:30,824 Train Loss: 0.0020794, Val Loss: 0.0019798
2025-02-18 16:59:30,824 Epoch 227/2000
2025-02-18 17:00:13,891 Current Learning Rate: 0.0004429836
2025-02-18 17:00:13,892 Train Loss: 0.0023814, Val Loss: 0.0019832
2025-02-18 17:00:13,892 Epoch 228/2000
2025-02-18 17:00:57,227 Current Learning Rate: 0.0004758647
2025-02-18 17:00:57,228 Train Loss: 0.0021208, Val Loss: 0.0019859
2025-02-18 17:00:57,228 Epoch 229/2000
2025-02-18 17:01:40,463 Current Learning Rate: 0.0005098621
2025-02-18 17:01:40,464 Train Loss: 0.0020718, Val Loss: 0.0019910
2025-02-18 17:01:40,464 Epoch 230/2000
2025-02-18 17:02:23,731 Current Learning Rate: 0.0005449674
2025-02-18 17:02:23,732 Train Loss: 0.0022761, Val Loss: 0.0019842
2025-02-18 17:02:23,732 Epoch 231/2000
2025-02-18 17:03:06,218 Current Learning Rate: 0.0005811718
2025-02-18 17:03:07,966 Train Loss: 0.0021898, Val Loss: 0.0019768
2025-02-18 17:03:07,967 Epoch 232/2000
2025-02-18 17:03:50,246 Current Learning Rate: 0.0006184666
2025-02-18 17:03:51,275 Train Loss: 0.0020886, Val Loss: 0.0019726
2025-02-18 17:03:51,276 Epoch 233/2000
2025-02-18 17:04:33,764 Current Learning Rate: 0.0006568424
2025-02-18 17:04:33,765 Train Loss: 0.0021526, Val Loss: 0.0020102
2025-02-18 17:04:33,765 Epoch 234/2000
2025-02-18 17:05:17,002 Current Learning Rate: 0.0006962899
2025-02-18 17:05:17,002 Train Loss: 0.0021231, Val Loss: 0.0019973
2025-02-18 17:05:17,003 Epoch 235/2000
2025-02-18 17:05:59,511 Current Learning Rate: 0.0007367992
2025-02-18 17:05:59,511 Train Loss: 0.0021176, Val Loss: 0.0019983
2025-02-18 17:05:59,512 Epoch 236/2000
2025-02-18 17:06:43,512 Current Learning Rate: 0.0007783604
2025-02-18 17:06:43,512 Train Loss: 0.0020430, Val Loss: 0.0019853
2025-02-18 17:06:43,513 Epoch 237/2000
2025-02-18 17:07:26,475 Current Learning Rate: 0.0008209632
2025-02-18 17:07:26,476 Train Loss: 0.0023675, Val Loss: 0.0020038
2025-02-18 17:07:26,476 Epoch 238/2000
2025-02-18 17:08:08,690 Current Learning Rate: 0.0008645971
2025-02-18 17:08:08,691 Train Loss: 0.0023511, Val Loss: 0.0019897
2025-02-18 17:08:08,692 Epoch 239/2000
2025-02-18 17:08:51,622 Current Learning Rate: 0.0009092514
2025-02-18 17:08:53,349 Train Loss: 0.0019571, Val Loss: 0.0019558
2025-02-18 17:08:53,349 Epoch 240/2000
2025-02-18 17:09:36,112 Current Learning Rate: 0.0009549150
2025-02-18 17:09:36,113 Train Loss: 0.0021965, Val Loss: 0.0019822
2025-02-18 17:09:36,114 Epoch 241/2000
2025-02-18 17:10:18,236 Current Learning Rate: 0.0010015767
2025-02-18 17:10:18,236 Train Loss: 0.0022462, Val Loss: 0.0019775
2025-02-18 17:10:18,237 Epoch 242/2000
2025-02-18 17:11:01,233 Current Learning Rate: 0.0010492249
2025-02-18 17:11:01,234 Train Loss: 0.0021528, Val Loss: 0.0019719
2025-02-18 17:11:01,235 Epoch 243/2000
2025-02-18 17:11:44,787 Current Learning Rate: 0.0010978480
2025-02-18 17:11:44,787 Train Loss: 0.0021179, Val Loss: 0.0019795
2025-02-18 17:11:44,788 Epoch 244/2000
2025-02-18 17:12:28,071 Current Learning Rate: 0.0011474338
2025-02-18 17:12:28,072 Train Loss: 0.0020616, Val Loss: 0.0019595
2025-02-18 17:12:28,072 Epoch 245/2000
2025-02-18 17:13:10,758 Current Learning Rate: 0.0011979702
2025-02-18 17:13:10,759 Train Loss: 0.0022047, Val Loss: 0.0019963
2025-02-18 17:13:10,759 Epoch 246/2000
2025-02-18 17:13:53,165 Current Learning Rate: 0.0012494447
2025-02-18 17:13:53,166 Train Loss: 0.0022352, Val Loss: 0.0020700
2025-02-18 17:13:53,166 Epoch 247/2000
2025-02-18 17:14:36,330 Current Learning Rate: 0.0013018445
2025-02-18 17:14:36,331 Train Loss: 0.0020563, Val Loss: 0.0019558
2025-02-18 17:14:36,331 Epoch 248/2000
2025-02-18 17:15:18,763 Current Learning Rate: 0.0013551569
2025-02-18 17:15:18,763 Train Loss: 0.0024619, Val Loss: 0.0021336
2025-02-18 17:15:18,764 Epoch 249/2000
2025-02-18 17:16:01,508 Current Learning Rate: 0.0014093685
2025-02-18 17:16:01,509 Train Loss: 0.0022092, Val Loss: 0.0022978
2025-02-18 17:16:01,509 Epoch 250/2000
2025-02-18 17:16:44,431 Current Learning Rate: 0.0014644661
2025-02-18 17:16:44,431 Train Loss: 0.0021759, Val Loss: 0.0020078
2025-02-18 17:16:44,432 Epoch 251/2000
2025-02-18 17:17:27,816 Current Learning Rate: 0.0015204360
2025-02-18 17:17:27,817 Train Loss: 0.0023476, Val Loss: 0.0021104
2025-02-18 17:17:27,818 Epoch 252/2000
2025-02-18 17:18:11,339 Current Learning Rate: 0.0015772645
2025-02-18 17:18:11,340 Train Loss: 0.0024153, Val Loss: 0.0021297
2025-02-18 17:18:11,340 Epoch 253/2000
2025-02-18 17:18:54,453 Current Learning Rate: 0.0016349374
2025-02-18 17:18:54,454 Train Loss: 0.0020383, Val Loss: 0.0019624
2025-02-18 17:18:54,454 Epoch 254/2000
2025-02-18 17:19:37,857 Current Learning Rate: 0.0016934407
2025-02-18 17:19:37,857 Train Loss: 0.0025406, Val Loss: 0.0020266
2025-02-18 17:19:37,857 Epoch 255/2000
2025-02-18 17:20:21,308 Current Learning Rate: 0.0017527598
2025-02-18 17:20:23,471 Train Loss: 0.0022011, Val Loss: 0.0019523
2025-02-18 17:20:23,472 Epoch 256/2000
2025-02-18 17:21:06,460 Current Learning Rate: 0.0018128801
2025-02-18 17:21:06,461 Train Loss: 0.0022263, Val Loss: 0.0019919
2025-02-18 17:21:06,462 Epoch 257/2000
2025-02-18 17:21:49,862 Current Learning Rate: 0.0018737867
2025-02-18 17:21:49,863 Train Loss: 0.0020372, Val Loss: 0.0020744
2025-02-18 17:21:49,863 Epoch 258/2000
2025-02-18 17:22:33,125 Current Learning Rate: 0.0019354647
2025-02-18 17:22:33,125 Train Loss: 0.0021006, Val Loss: 0.0020085
2025-02-18 17:22:33,126 Epoch 259/2000
2025-02-18 17:23:14,896 Current Learning Rate: 0.0019978989
2025-02-18 17:23:16,324 Train Loss: 0.0022565, Val Loss: 0.0019517
2025-02-18 17:23:16,340 Epoch 260/2000
2025-02-18 17:23:58,569 Current Learning Rate: 0.0020610737
2025-02-18 17:23:58,569 Train Loss: 0.0021173, Val Loss: 0.0020114
2025-02-18 17:23:58,570 Epoch 261/2000
2025-02-18 17:24:42,252 Current Learning Rate: 0.0021249737
2025-02-18 17:24:44,287 Train Loss: 0.0020451, Val Loss: 0.0019251
2025-02-18 17:24:44,287 Epoch 262/2000
2025-02-18 17:25:27,305 Current Learning Rate: 0.0021895831
2025-02-18 17:25:27,307 Train Loss: 0.0028658, Val Loss: 0.0025279
2025-02-18 17:25:27,309 Epoch 263/2000
2025-02-18 17:26:09,671 Current Learning Rate: 0.0022548859
2025-02-18 17:26:09,671 Train Loss: 0.0022533, Val Loss: 0.0020600
2025-02-18 17:26:09,672 Epoch 264/2000
2025-02-18 17:26:52,712 Current Learning Rate: 0.0023208660
2025-02-18 17:26:52,713 Train Loss: 0.0021905, Val Loss: 0.0020418
2025-02-18 17:26:52,713 Epoch 265/2000
2025-02-18 17:27:35,513 Current Learning Rate: 0.0023875072
2025-02-18 17:27:35,514 Train Loss: 0.0024926, Val Loss: 0.0022231
2025-02-18 17:27:35,514 Epoch 266/2000
2025-02-18 17:28:18,201 Current Learning Rate: 0.0024547929
2025-02-18 17:28:18,202 Train Loss: 0.0023036, Val Loss: 0.0020216
2025-02-18 17:28:18,202 Epoch 267/2000
2025-02-18 17:29:00,649 Current Learning Rate: 0.0025227067
2025-02-18 17:29:00,650 Train Loss: 0.0027150, Val Loss: 0.0021037
2025-02-18 17:29:00,650 Epoch 268/2000
2025-02-18 17:29:44,410 Current Learning Rate: 0.0025912316
2025-02-18 17:29:44,411 Train Loss: 0.0029222, Val Loss: 0.0020365
2025-02-18 17:29:44,411 Epoch 269/2000
2025-02-18 17:30:27,360 Current Learning Rate: 0.0026603509
2025-02-18 17:30:27,361 Train Loss: 0.0022119, Val Loss: 0.0020850
2025-02-18 17:30:27,361 Epoch 270/2000
2025-02-18 17:31:09,717 Current Learning Rate: 0.0027300475
2025-02-18 17:31:09,718 Train Loss: 0.0022681, Val Loss: 0.0020540
2025-02-18 17:31:09,718 Epoch 271/2000
2025-02-18 17:31:52,295 Current Learning Rate: 0.0028003042
2025-02-18 17:31:52,296 Train Loss: 0.0024327, Val Loss: 0.0021627
2025-02-18 17:31:52,296 Epoch 272/2000
2025-02-18 17:32:35,620 Current Learning Rate: 0.0028711035
2025-02-18 17:32:35,621 Train Loss: 0.0022867, Val Loss: 0.0021199
2025-02-18 17:32:35,621 Epoch 273/2000
2025-02-18 17:33:17,806 Current Learning Rate: 0.0029424282
2025-02-18 17:33:17,807 Train Loss: 0.0034277, Val Loss: 0.0022840
2025-02-18 17:33:17,807 Epoch 274/2000
2025-02-18 17:34:00,432 Current Learning Rate: 0.0030142605
2025-02-18 17:34:00,433 Train Loss: 0.0019804, Val Loss: 0.0019544
2025-02-18 17:34:00,453 Epoch 275/2000
2025-02-18 17:34:43,828 Current Learning Rate: 0.0030865828
2025-02-18 17:34:45,879 Train Loss: 0.0022005, Val Loss: 0.0018912
2025-02-18 17:34:45,879 Epoch 276/2000
2025-02-18 17:35:28,669 Current Learning Rate: 0.0031593772
2025-02-18 17:35:28,670 Train Loss: 0.0022289, Val Loss: 0.0020203
2025-02-18 17:35:28,671 Epoch 277/2000
2025-02-18 17:36:11,497 Current Learning Rate: 0.0032326258
2025-02-18 17:36:11,498 Train Loss: 0.0023485, Val Loss: 0.0022531
2025-02-18 17:36:11,498 Epoch 278/2000
2025-02-18 17:36:54,326 Current Learning Rate: 0.0033063104
2025-02-18 17:36:54,326 Train Loss: 0.0020823, Val Loss: 0.0019360
2025-02-18 17:36:54,327 Epoch 279/2000
2025-02-18 17:37:37,229 Current Learning Rate: 0.0033804129
2025-02-18 17:37:37,230 Train Loss: 0.0036312, Val Loss: 0.0023923
2025-02-18 17:37:37,230 Epoch 280/2000
2025-02-18 17:38:20,275 Current Learning Rate: 0.0034549150
2025-02-18 17:38:20,276 Train Loss: 0.0022580, Val Loss: 0.0020475
2025-02-18 17:38:20,276 Epoch 281/2000
2025-02-18 17:39:02,899 Current Learning Rate: 0.0035297984
2025-02-18 17:39:04,322 Train Loss: 0.0018580, Val Loss: 0.0018449
2025-02-18 17:39:04,322 Epoch 282/2000
2025-02-18 17:39:46,966 Current Learning Rate: 0.0036050445
2025-02-18 17:39:46,967 Train Loss: 0.0035762, Val Loss: 0.0023837
2025-02-18 17:39:46,967 Epoch 283/2000
2025-02-18 17:40:29,857 Current Learning Rate: 0.0036806348
2025-02-18 17:40:29,857 Train Loss: 0.0020949, Val Loss: 0.0019122
2025-02-18 17:40:29,858 Epoch 284/2000
2025-02-18 17:41:12,868 Current Learning Rate: 0.0037565506
2025-02-18 17:41:12,869 Train Loss: 0.0020912, Val Loss: 0.0018673
2025-02-18 17:41:12,869 Epoch 285/2000
2025-02-18 17:41:56,081 Current Learning Rate: 0.0038327732
2025-02-18 17:41:57,701 Train Loss: 0.0020819, Val Loss: 0.0018445
2025-02-18 17:41:57,701 Epoch 286/2000
2025-02-18 17:42:40,442 Current Learning Rate: 0.0039092838
2025-02-18 17:42:40,443 Train Loss: 0.0022515, Val Loss: 0.0021071
2025-02-18 17:42:40,443 Epoch 287/2000
2025-02-18 17:43:23,583 Current Learning Rate: 0.0039860635
2025-02-18 17:43:23,584 Train Loss: 0.0024569, Val Loss: 0.0025974
2025-02-18 17:43:23,584 Epoch 288/2000
2025-02-18 17:44:06,549 Current Learning Rate: 0.0040630934
2025-02-18 17:44:06,550 Train Loss: 0.0021944, Val Loss: 0.0020369
2025-02-18 17:44:06,550 Epoch 289/2000
2025-02-18 17:44:49,814 Current Learning Rate: 0.0041403545
2025-02-18 17:44:49,815 Train Loss: 0.0029261, Val Loss: 0.0023501
2025-02-18 17:44:49,815 Epoch 290/2000
2025-02-18 17:45:33,030 Current Learning Rate: 0.0042178277
2025-02-18 17:45:33,031 Train Loss: 0.0022571, Val Loss: 0.0018816
2025-02-18 17:45:33,031 Epoch 291/2000
2025-02-18 17:46:15,380 Current Learning Rate: 0.0042954938
2025-02-18 17:46:15,380 Train Loss: 0.0027410, Val Loss: 0.0026028
2025-02-18 17:46:15,380 Epoch 292/2000
2025-02-18 17:46:59,168 Current Learning Rate: 0.0043733338
2025-02-18 17:46:59,169 Train Loss: 0.0023064, Val Loss: 0.0020107
2025-02-18 17:46:59,169 Epoch 293/2000
2025-02-18 17:47:42,336 Current Learning Rate: 0.0044513284
2025-02-18 17:47:42,336 Train Loss: 0.0022670, Val Loss: 0.0019972
2025-02-18 17:47:42,337 Epoch 294/2000
2025-02-18 17:48:25,761 Current Learning Rate: 0.0045294584
2025-02-18 17:48:25,761 Train Loss: 0.0025803, Val Loss: 0.0021324
2025-02-18 17:48:25,762 Epoch 295/2000
2025-02-18 17:49:08,391 Current Learning Rate: 0.0046077045
2025-02-18 17:49:08,392 Train Loss: 0.0018848, Val Loss: 0.0019026
2025-02-18 17:49:08,392 Epoch 296/2000
2025-02-18 17:49:51,576 Current Learning Rate: 0.0046860474
2025-02-18 17:49:51,576 Train Loss: 0.0027394, Val Loss: 0.0030746
2025-02-18 17:49:51,576 Epoch 297/2000
2025-02-18 17:50:33,927 Current Learning Rate: 0.0047644677
2025-02-18 17:50:33,928 Train Loss: 0.0026139, Val Loss: 0.0021545
2025-02-18 17:50:33,928 Epoch 298/2000
2025-02-18 17:51:17,310 Current Learning Rate: 0.0048429462
2025-02-18 17:51:17,310 Train Loss: 0.0020331, Val Loss: 0.0018768
2025-02-18 17:51:17,310 Epoch 299/2000
2025-02-18 17:52:00,259 Current Learning Rate: 0.0049214634
2025-02-18 17:52:00,259 Train Loss: 0.0029920, Val Loss: 0.0021373
2025-02-18 17:52:00,261 Epoch 300/2000
2025-02-18 17:52:42,781 Current Learning Rate: 0.0050000000
2025-02-18 17:52:44,146 Train Loss: 0.0018674, Val Loss: 0.0018172
2025-02-18 17:52:44,152 Epoch 301/2000
2025-02-18 17:53:25,902 Current Learning Rate: 0.0050785366
2025-02-18 17:53:25,903 Train Loss: 0.0026097, Val Loss: 0.0023666
2025-02-18 17:53:25,903 Epoch 302/2000
2025-02-18 17:54:08,415 Current Learning Rate: 0.0051570538
2025-02-18 17:54:08,415 Train Loss: 0.0020608, Val Loss: 0.0020070
2025-02-18 17:54:08,416 Epoch 303/2000
2025-02-18 17:54:51,147 Current Learning Rate: 0.0052355323
2025-02-18 17:54:52,736 Train Loss: 0.0018909, Val Loss: 0.0017573
2025-02-18 17:54:52,736 Epoch 304/2000
2025-02-18 17:55:34,551 Current Learning Rate: 0.0053139526
2025-02-18 17:55:36,133 Train Loss: 0.0018080, Val Loss: 0.0017460
2025-02-18 17:55:36,133 Epoch 305/2000
2025-02-18 17:56:18,434 Current Learning Rate: 0.0053922955
2025-02-18 17:56:18,435 Train Loss: 0.0035959, Val Loss: 0.0024591
2025-02-18 17:56:18,436 Epoch 306/2000
2025-02-18 17:57:01,706 Current Learning Rate: 0.0054705416
2025-02-18 17:57:01,706 Train Loss: 0.0021499, Val Loss: 0.0018718
2025-02-18 17:57:01,707 Epoch 307/2000
2025-02-18 17:57:45,246 Current Learning Rate: 0.0055486716
2025-02-18 17:57:45,256 Train Loss: 0.0019959, Val Loss: 0.0017491
2025-02-18 17:57:45,257 Epoch 308/2000
2025-02-18 17:58:28,821 Current Learning Rate: 0.0056266662
2025-02-18 17:58:28,821 Train Loss: 0.0017812, Val Loss: 0.0019117
2025-02-18 17:58:28,822 Epoch 309/2000
2025-02-18 17:59:12,171 Current Learning Rate: 0.0057045062
2025-02-18 17:59:12,172 Train Loss: 0.0023382, Val Loss: 0.0019419
2025-02-18 17:59:12,172 Epoch 310/2000
2025-02-18 17:59:55,710 Current Learning Rate: 0.0057821723
2025-02-18 17:59:55,711 Train Loss: 0.0018849, Val Loss: 0.0018889
2025-02-18 17:59:55,711 Epoch 311/2000
2025-02-18 18:00:38,906 Current Learning Rate: 0.0058596455
2025-02-18 18:00:38,906 Train Loss: 0.0019797, Val Loss: 0.0018297
2025-02-18 18:00:38,907 Epoch 312/2000
2025-02-18 18:01:21,390 Current Learning Rate: 0.0059369066
2025-02-18 18:01:21,390 Train Loss: 0.0018032, Val Loss: 0.0018692
2025-02-18 18:01:21,391 Epoch 313/2000
2025-02-18 18:02:04,183 Current Learning Rate: 0.0060139365
2025-02-18 18:02:04,184 Train Loss: 0.0020518, Val Loss: 0.0020126
2025-02-18 18:02:04,184 Epoch 314/2000
2025-02-18 18:02:47,470 Current Learning Rate: 0.0060907162
2025-02-18 18:02:48,999 Train Loss: 0.0019250, Val Loss: 0.0017355
2025-02-18 18:02:48,999 Epoch 315/2000
2025-02-18 18:03:30,653 Current Learning Rate: 0.0061672268
2025-02-18 18:03:30,654 Train Loss: 0.0018704, Val Loss: 0.0018669
2025-02-18 18:03:30,655 Epoch 316/2000
2025-02-18 18:04:14,478 Current Learning Rate: 0.0062434494
2025-02-18 18:04:14,479 Train Loss: 0.0025219, Val Loss: 0.0022951
2025-02-18 18:04:14,479 Epoch 317/2000
2025-02-18 18:04:57,930 Current Learning Rate: 0.0063193652
2025-02-18 18:04:57,930 Train Loss: 0.0018168, Val Loss: 0.0017720
2025-02-18 18:04:57,930 Epoch 318/2000
2025-02-18 18:05:41,091 Current Learning Rate: 0.0063949555
2025-02-18 18:05:41,092 Train Loss: 0.0017140, Val Loss: 0.0017393
2025-02-18 18:05:41,092 Epoch 319/2000
2025-02-18 18:06:23,492 Current Learning Rate: 0.0064702016
2025-02-18 18:06:23,492 Train Loss: 0.0024777, Val Loss: 0.0019097
2025-02-18 18:06:23,493 Epoch 320/2000
2025-02-18 18:07:06,845 Current Learning Rate: 0.0065450850
2025-02-18 18:07:06,846 Train Loss: 0.0021007, Val Loss: 0.0019510
2025-02-18 18:07:06,846 Epoch 321/2000
2025-02-18 18:07:49,549 Current Learning Rate: 0.0066195871
2025-02-18 18:07:49,549 Train Loss: 0.0019580, Val Loss: 0.0018938
2025-02-18 18:07:49,550 Epoch 322/2000
2025-02-18 18:08:32,763 Current Learning Rate: 0.0066936896
2025-02-18 18:08:32,763 Train Loss: 0.0020908, Val Loss: 0.0024106
2025-02-18 18:08:32,764 Epoch 323/2000
2025-02-18 18:09:15,017 Current Learning Rate: 0.0067673742
2025-02-18 18:09:16,660 Train Loss: 0.0017726, Val Loss: 0.0016919
2025-02-18 18:09:16,660 Epoch 324/2000
2025-02-18 18:09:59,860 Current Learning Rate: 0.0068406228
2025-02-18 18:09:59,861 Train Loss: 0.0022114, Val Loss: 0.0018984
2025-02-18 18:09:59,861 Epoch 325/2000
2025-02-18 18:10:41,735 Current Learning Rate: 0.0069134172
2025-02-18 18:10:41,736 Train Loss: 0.0022210, Val Loss: 0.0017853
2025-02-18 18:10:41,736 Epoch 326/2000
2025-02-18 18:11:24,252 Current Learning Rate: 0.0069857395
2025-02-18 18:11:24,253 Train Loss: 0.0019125, Val Loss: 0.0018118
2025-02-18 18:11:24,257 Epoch 327/2000
2025-02-18 18:12:07,319 Current Learning Rate: 0.0070575718
2025-02-18 18:12:07,320 Train Loss: 0.0017428, Val Loss: 0.0017612
2025-02-18 18:12:07,320 Epoch 328/2000
2025-02-18 18:12:50,182 Current Learning Rate: 0.0071288965
2025-02-18 18:12:51,888 Train Loss: 0.0017766, Val Loss: 0.0015894
2025-02-18 18:12:51,889 Epoch 329/2000
2025-02-18 18:13:34,386 Current Learning Rate: 0.0071996958
2025-02-18 18:13:34,386 Train Loss: 0.0019559, Val Loss: 0.0020721
2025-02-18 18:13:34,387 Epoch 330/2000
2025-02-18 18:14:16,352 Current Learning Rate: 0.0072699525
2025-02-18 18:14:16,353 Train Loss: 0.0018707, Val Loss: 0.0018036
2025-02-18 18:14:16,353 Epoch 331/2000
2025-02-18 18:14:59,831 Current Learning Rate: 0.0073396491
2025-02-18 18:14:59,832 Train Loss: 0.0016481, Val Loss: 0.0015985
2025-02-18 18:14:59,832 Epoch 332/2000
2025-02-18 18:15:43,156 Current Learning Rate: 0.0074087684
2025-02-18 18:15:43,156 Train Loss: 0.0018216, Val Loss: 0.0016206
2025-02-18 18:15:43,157 Epoch 333/2000
2025-02-18 18:16:26,066 Current Learning Rate: 0.0074772933
2025-02-18 18:16:26,067 Train Loss: 0.0019091, Val Loss: 0.0017353
2025-02-18 18:16:26,067 Epoch 334/2000
2025-02-18 18:17:08,244 Current Learning Rate: 0.0075452071
2025-02-18 18:17:08,245 Train Loss: 0.0018253, Val Loss: 0.0016177
2025-02-18 18:17:08,245 Epoch 335/2000
2025-02-18 18:17:50,613 Current Learning Rate: 0.0076124928
2025-02-18 18:17:50,613 Train Loss: 0.0020595, Val Loss: 0.0016002
2025-02-18 18:17:50,613 Epoch 336/2000
2025-02-18 18:18:33,309 Current Learning Rate: 0.0076791340
2025-02-18 18:18:33,310 Train Loss: 0.0015516, Val Loss: 0.0016030
2025-02-18 18:18:33,310 Epoch 337/2000
2025-02-18 18:19:16,693 Current Learning Rate: 0.0077451141
2025-02-18 18:19:16,694 Train Loss: 0.0017143, Val Loss: 0.0017131
2025-02-18 18:19:16,694 Epoch 338/2000
2025-02-18 18:19:59,626 Current Learning Rate: 0.0078104169
2025-02-18 18:19:59,627 Train Loss: 0.0019217, Val Loss: 0.0020587
2025-02-18 18:19:59,627 Epoch 339/2000
2025-02-18 18:20:43,199 Current Learning Rate: 0.0078750263
2025-02-18 18:20:43,200 Train Loss: 0.0016958, Val Loss: 0.0016010
2025-02-18 18:20:43,200 Epoch 340/2000
2025-02-18 18:21:26,017 Current Learning Rate: 0.0079389263
2025-02-18 18:21:27,238 Train Loss: 0.0014670, Val Loss: 0.0015100
2025-02-18 18:21:27,238 Epoch 341/2000
2025-02-18 18:22:10,548 Current Learning Rate: 0.0080021011
2025-02-18 18:22:10,548 Train Loss: 0.0019157, Val Loss: 0.0018127
2025-02-18 18:22:10,548 Epoch 342/2000
2025-02-18 18:22:53,166 Current Learning Rate: 0.0080645353
2025-02-18 18:22:53,167 Train Loss: 0.0018622, Val Loss: 0.0016093
2025-02-18 18:22:53,167 Epoch 343/2000
2025-02-18 18:23:35,993 Current Learning Rate: 0.0081262133
2025-02-18 18:23:35,994 Train Loss: 0.0018541, Val Loss: 0.0016999
2025-02-18 18:23:35,994 Epoch 344/2000
2025-02-18 18:24:19,508 Current Learning Rate: 0.0081871199
2025-02-18 18:24:19,509 Train Loss: 0.0016666, Val Loss: 0.0016238
2025-02-18 18:24:19,509 Epoch 345/2000
2025-02-18 18:25:01,663 Current Learning Rate: 0.0082472402
2025-02-18 18:25:01,664 Train Loss: 0.0017156, Val Loss: 0.0016722
2025-02-18 18:25:01,664 Epoch 346/2000
2025-02-18 18:25:45,420 Current Learning Rate: 0.0083065593
2025-02-18 18:25:45,421 Train Loss: 0.0017596, Val Loss: 0.0016487
2025-02-18 18:25:45,421 Epoch 347/2000
2025-02-18 18:26:28,790 Current Learning Rate: 0.0083650626
2025-02-18 18:26:28,790 Train Loss: 0.0017325, Val Loss: 0.0017112
2025-02-18 18:26:28,790 Epoch 348/2000
2025-02-18 18:27:11,358 Current Learning Rate: 0.0084227355
2025-02-18 18:27:11,361 Train Loss: 0.0015121, Val Loss: 0.0015322
2025-02-18 18:27:11,362 Epoch 349/2000
2025-02-18 18:27:53,969 Current Learning Rate: 0.0084795640
2025-02-18 18:27:53,970 Train Loss: 0.0017999, Val Loss: 0.0017936
2025-02-18 18:27:53,971 Epoch 350/2000
2025-02-18 18:28:36,639 Current Learning Rate: 0.0085355339
2025-02-18 18:28:36,639 Train Loss: 0.0016998, Val Loss: 0.0015861
2025-02-18 18:28:36,639 Epoch 351/2000
2025-02-18 18:29:20,073 Current Learning Rate: 0.0085906315
2025-02-18 18:29:20,073 Train Loss: 0.0019386, Val Loss: 0.0018972
2025-02-18 18:29:20,074 Epoch 352/2000
2025-02-18 18:30:02,899 Current Learning Rate: 0.0086448431
2025-02-18 18:30:02,900 Train Loss: 0.0015820, Val Loss: 0.0017853
2025-02-18 18:30:02,900 Epoch 353/2000
2025-02-18 18:30:45,903 Current Learning Rate: 0.0086981555
2025-02-18 18:30:45,904 Train Loss: 0.0017570, Val Loss: 0.0017251
2025-02-18 18:30:45,904 Epoch 354/2000
2025-02-18 18:31:28,902 Current Learning Rate: 0.0087505553
2025-02-18 18:31:28,903 Train Loss: 0.0015964, Val Loss: 0.0016704
2025-02-18 18:31:28,903 Epoch 355/2000
2025-02-18 18:32:12,132 Current Learning Rate: 0.0088020298
2025-02-18 18:32:12,132 Train Loss: 0.0015286, Val Loss: 0.0016506
2025-02-18 18:32:12,133 Epoch 356/2000
2025-02-18 18:32:54,634 Current Learning Rate: 0.0088525662
2025-02-18 18:32:54,637 Train Loss: 0.0015187, Val Loss: 0.0015421
2025-02-18 18:32:54,639 Epoch 357/2000
2025-02-18 18:33:38,046 Current Learning Rate: 0.0089021520
2025-02-18 18:33:38,047 Train Loss: 0.0021062, Val Loss: 0.0032683
2025-02-18 18:33:38,047 Epoch 358/2000
2025-02-18 18:34:21,470 Current Learning Rate: 0.0089507751
2025-02-18 18:34:21,471 Train Loss: 0.0021825, Val Loss: 0.0015852
2025-02-18 18:34:21,471 Epoch 359/2000
2025-02-18 18:35:04,446 Current Learning Rate: 0.0089984233
2025-02-18 18:35:05,800 Train Loss: 0.0018197, Val Loss: 0.0014681
2025-02-18 18:35:05,800 Epoch 360/2000
2025-02-18 18:35:48,574 Current Learning Rate: 0.0090450850
2025-02-18 18:35:48,575 Train Loss: 0.0016813, Val Loss: 0.0021415
2025-02-18 18:35:48,575 Epoch 361/2000
2025-02-18 18:36:31,883 Current Learning Rate: 0.0090907486
2025-02-18 18:36:34,074 Train Loss: 0.0015965, Val Loss: 0.0014384
2025-02-18 18:36:34,075 Epoch 362/2000
2025-02-18 18:37:17,082 Current Learning Rate: 0.0091354029
2025-02-18 18:37:18,832 Train Loss: 0.0013874, Val Loss: 0.0014136
2025-02-18 18:37:18,832 Epoch 363/2000
2025-02-18 18:38:01,391 Current Learning Rate: 0.0091790368
2025-02-18 18:38:01,392 Train Loss: 0.0014922, Val Loss: 0.0016143
2025-02-18 18:38:01,392 Epoch 364/2000
2025-02-18 18:38:44,307 Current Learning Rate: 0.0092216396
2025-02-18 18:38:45,517 Train Loss: 0.0013926, Val Loss: 0.0013412
2025-02-18 18:38:45,517 Epoch 365/2000
2025-02-18 18:39:28,642 Current Learning Rate: 0.0092632008
2025-02-18 18:39:28,643 Train Loss: 0.0016428, Val Loss: 0.0016724
2025-02-18 18:39:28,643 Epoch 366/2000
2025-02-18 18:40:12,059 Current Learning Rate: 0.0093037101
2025-02-18 18:40:12,059 Train Loss: 0.0013429, Val Loss: 0.0015838
2025-02-18 18:40:12,059 Epoch 367/2000
2025-02-18 18:40:55,793 Current Learning Rate: 0.0093431576
2025-02-18 18:40:55,794 Train Loss: 0.0012813, Val Loss: 0.0013530
2025-02-18 18:40:55,794 Epoch 368/2000
2025-02-18 18:41:38,495 Current Learning Rate: 0.0093815334
2025-02-18 18:41:38,496 Train Loss: 0.0014401, Val Loss: 0.0013843
2025-02-18 18:41:38,496 Epoch 369/2000
2025-02-18 18:42:21,662 Current Learning Rate: 0.0094188282
2025-02-18 18:42:21,663 Train Loss: 0.0012297, Val Loss: 0.0014001
2025-02-18 18:42:21,663 Epoch 370/2000
2025-02-18 18:43:05,064 Current Learning Rate: 0.0094550326
2025-02-18 18:43:05,064 Train Loss: 0.0012705, Val Loss: 0.0018555
2025-02-18 18:43:05,064 Epoch 371/2000
2025-02-18 18:43:48,083 Current Learning Rate: 0.0094901379
2025-02-18 18:43:48,084 Train Loss: 0.0017594, Val Loss: 0.0017246
2025-02-18 18:43:48,084 Epoch 372/2000
2025-02-18 18:44:30,913 Current Learning Rate: 0.0095241353
2025-02-18 18:44:30,913 Train Loss: 0.0016862, Val Loss: 0.0015140
2025-02-18 18:44:30,913 Epoch 373/2000
2025-02-18 18:45:14,029 Current Learning Rate: 0.0095570164
2025-02-18 18:45:14,029 Train Loss: 0.0014067, Val Loss: 0.0013510
2025-02-18 18:45:14,029 Epoch 374/2000
2025-02-18 18:45:56,673 Current Learning Rate: 0.0095887731
2025-02-18 18:45:57,729 Train Loss: 0.0013898, Val Loss: 0.0013164
2025-02-18 18:45:57,732 Epoch 375/2000
2025-02-18 18:46:39,493 Current Learning Rate: 0.0096193977
2025-02-18 18:46:39,494 Train Loss: 0.0013693, Val Loss: 0.0013573
2025-02-18 18:46:39,494 Epoch 376/2000
2025-02-18 18:47:22,583 Current Learning Rate: 0.0096488824
2025-02-18 18:47:22,583 Train Loss: 0.0013377, Val Loss: 0.0013611
2025-02-18 18:47:22,584 Epoch 377/2000
2025-02-18 18:48:05,544 Current Learning Rate: 0.0096772202
2025-02-18 18:48:06,887 Train Loss: 0.0011529, Val Loss: 0.0012729
2025-02-18 18:48:06,887 Epoch 378/2000
2025-02-18 18:48:48,128 Current Learning Rate: 0.0097044038
2025-02-18 18:48:49,263 Train Loss: 0.0012668, Val Loss: 0.0012526
2025-02-18 18:48:49,264 Epoch 379/2000
2025-02-18 18:49:31,857 Current Learning Rate: 0.0097304268
2025-02-18 18:49:31,858 Train Loss: 0.0015333, Val Loss: 0.0013690
2025-02-18 18:49:31,858 Epoch 380/2000
2025-02-18 18:50:14,927 Current Learning Rate: 0.0097552826
2025-02-18 18:50:14,928 Train Loss: 0.0012782, Val Loss: 0.0012590
2025-02-18 18:50:14,928 Epoch 381/2000
2025-02-18 18:50:57,867 Current Learning Rate: 0.0097789651
2025-02-18 18:50:57,868 Train Loss: 0.0015421, Val Loss: 0.0014658
2025-02-18 18:50:57,868 Epoch 382/2000
2025-02-18 18:51:40,749 Current Learning Rate: 0.0098014684
2025-02-18 18:51:42,337 Train Loss: 0.0012468, Val Loss: 0.0012293
2025-02-18 18:51:42,337 Epoch 383/2000
2025-02-18 18:52:25,160 Current Learning Rate: 0.0098227871
2025-02-18 18:52:25,161 Train Loss: 0.0012961, Val Loss: 0.0012819
2025-02-18 18:52:25,161 Epoch 384/2000
2025-02-18 18:53:07,355 Current Learning Rate: 0.0098429158
2025-02-18 18:53:07,355 Train Loss: 0.0013461, Val Loss: 0.0013925
2025-02-18 18:53:07,356 Epoch 385/2000
2025-02-18 18:53:50,623 Current Learning Rate: 0.0098618496
2025-02-18 18:53:50,624 Train Loss: 0.0014020, Val Loss: 0.0013148
2025-02-18 18:53:50,624 Epoch 386/2000
2025-02-18 18:54:33,782 Current Learning Rate: 0.0098795838
2025-02-18 18:54:33,782 Train Loss: 0.0017544, Val Loss: 0.0015577
2025-02-18 18:54:33,782 Epoch 387/2000
2025-02-18 18:55:16,293 Current Learning Rate: 0.0098961141
2025-02-18 18:55:16,294 Train Loss: 0.0015864, Val Loss: 0.0017547
2025-02-18 18:55:16,294 Epoch 388/2000
2025-02-18 18:55:59,068 Current Learning Rate: 0.0099114363
2025-02-18 18:55:59,068 Train Loss: 0.0012810, Val Loss: 0.0013886
2025-02-18 18:55:59,069 Epoch 389/2000
2025-02-18 18:56:42,192 Current Learning Rate: 0.0099255466
2025-02-18 18:56:42,192 Train Loss: 0.0012414, Val Loss: 0.0014214
2025-02-18 18:56:42,193 Epoch 390/2000
2025-02-18 18:57:25,765 Current Learning Rate: 0.0099384417
2025-02-18 18:57:25,766 Train Loss: 0.0013963, Val Loss: 0.0012380
2025-02-18 18:57:25,766 Epoch 391/2000
2025-02-18 18:58:09,021 Current Learning Rate: 0.0099501183
2025-02-18 18:58:09,021 Train Loss: 0.0010892, Val Loss: 0.0012810
2025-02-18 18:58:09,021 Epoch 392/2000
2025-02-18 18:58:52,156 Current Learning Rate: 0.0099605735
2025-02-18 18:58:52,156 Train Loss: 0.0014638, Val Loss: 0.0013840
2025-02-18 18:58:52,156 Epoch 393/2000
2025-02-18 18:59:35,203 Current Learning Rate: 0.0099698048
2025-02-18 18:59:37,270 Train Loss: 0.0012113, Val Loss: 0.0012240
2025-02-18 18:59:37,270 Epoch 394/2000
2025-02-18 19:00:20,559 Current Learning Rate: 0.0099778098
2025-02-18 19:00:20,561 Train Loss: 0.0011264, Val Loss: 0.0013557
2025-02-18 19:00:20,569 Epoch 395/2000
2025-02-18 19:01:03,777 Current Learning Rate: 0.0099845867
2025-02-18 19:01:05,631 Train Loss: 0.0010732, Val Loss: 0.0012006
2025-02-18 19:01:05,632 Epoch 396/2000
2025-02-18 19:01:47,097 Current Learning Rate: 0.0099901336
2025-02-18 19:01:48,929 Train Loss: 0.0011134, Val Loss: 0.0011634
2025-02-18 19:01:48,930 Epoch 397/2000
2025-02-18 19:02:31,762 Current Learning Rate: 0.0099944494
2025-02-18 19:02:31,763 Train Loss: 0.0012579, Val Loss: 0.0014505
2025-02-18 19:02:31,764 Epoch 398/2000
2025-02-18 19:03:14,594 Current Learning Rate: 0.0099975328
2025-02-18 19:03:15,966 Train Loss: 0.0010476, Val Loss: 0.0011492
2025-02-18 19:03:15,966 Epoch 399/2000
2025-02-18 19:03:57,921 Current Learning Rate: 0.0099993832
2025-02-18 19:03:57,921 Train Loss: 0.0014083, Val Loss: 0.0016155
2025-02-18 19:03:57,922 Epoch 400/2000
2025-02-18 19:04:41,030 Current Learning Rate: 0.0100000000
2025-02-18 19:04:41,030 Train Loss: 0.0012435, Val Loss: 0.0012054
2025-02-18 19:04:41,031 Epoch 401/2000
2025-02-18 19:05:23,639 Current Learning Rate: 0.0099993832
2025-02-18 19:05:23,640 Train Loss: 0.0011665, Val Loss: 0.0013673
2025-02-18 19:05:23,640 Epoch 402/2000
2025-02-18 19:06:06,146 Current Learning Rate: 0.0099975328
2025-02-18 19:06:07,553 Train Loss: 0.0010835, Val Loss: 0.0011264
2025-02-18 19:06:07,553 Epoch 403/2000
2025-02-18 19:06:49,124 Current Learning Rate: 0.0099944494
2025-02-18 19:06:50,602 Train Loss: 0.0009434, Val Loss: 0.0011085
2025-02-18 19:06:50,602 Epoch 404/2000
2025-02-18 19:07:32,088 Current Learning Rate: 0.0099901336
2025-02-18 19:07:33,261 Train Loss: 0.0008888, Val Loss: 0.0010331
2025-02-18 19:07:33,261 Epoch 405/2000
2025-02-18 19:08:15,585 Current Learning Rate: 0.0099845867
2025-02-18 19:08:15,586 Train Loss: 0.0011416, Val Loss: 0.0010873
2025-02-18 19:08:15,586 Epoch 406/2000
2025-02-18 19:08:57,840 Current Learning Rate: 0.0099778098
2025-02-18 19:08:57,840 Train Loss: 0.0010608, Val Loss: 0.0010907
2025-02-18 19:08:57,840 Epoch 407/2000
2025-02-18 19:09:41,177 Current Learning Rate: 0.0099698048
2025-02-18 19:09:41,177 Train Loss: 0.0009946, Val Loss: 0.0011131
2025-02-18 19:09:41,178 Epoch 408/2000
2025-02-18 19:10:24,325 Current Learning Rate: 0.0099605735
2025-02-18 19:10:24,326 Train Loss: 0.0010914, Val Loss: 0.0011571
2025-02-18 19:10:24,326 Epoch 409/2000
2025-02-18 19:11:07,432 Current Learning Rate: 0.0099501183
2025-02-18 19:11:07,433 Train Loss: 0.0011023, Val Loss: 0.0010870
2025-02-18 19:11:07,433 Epoch 410/2000
2025-02-18 19:11:50,514 Current Learning Rate: 0.0099384417
2025-02-18 19:11:52,535 Train Loss: 0.0010144, Val Loss: 0.0010130
2025-02-18 19:11:52,535 Epoch 411/2000
2025-02-18 19:12:34,603 Current Learning Rate: 0.0099255466
2025-02-18 19:12:34,605 Train Loss: 0.0010780, Val Loss: 0.0010758
2025-02-18 19:12:34,605 Epoch 412/2000
2025-02-18 19:13:16,926 Current Learning Rate: 0.0099114363
2025-02-18 19:13:16,927 Train Loss: 0.0011290, Val Loss: 0.0010530
2025-02-18 19:13:16,927 Epoch 413/2000
2025-02-18 19:13:59,534 Current Learning Rate: 0.0098961141
2025-02-18 19:13:59,536 Train Loss: 0.0009785, Val Loss: 0.0010945
2025-02-18 19:13:59,536 Epoch 414/2000
2025-02-18 19:14:42,628 Current Learning Rate: 0.0098795838
2025-02-18 19:14:44,484 Train Loss: 0.0008982, Val Loss: 0.0009911
2025-02-18 19:14:44,484 Epoch 415/2000
2025-02-18 19:15:27,525 Current Learning Rate: 0.0098618496
2025-02-18 19:15:27,525 Train Loss: 0.0008983, Val Loss: 0.0010050
2025-02-18 19:15:27,526 Epoch 416/2000
2025-02-18 19:16:09,864 Current Learning Rate: 0.0098429158
2025-02-18 19:16:09,866 Train Loss: 0.0012341, Val Loss: 0.0012834
2025-02-18 19:16:09,866 Epoch 417/2000
2025-02-18 19:16:52,899 Current Learning Rate: 0.0098227871
2025-02-18 19:16:52,899 Train Loss: 0.0009907, Val Loss: 0.0010211
2025-02-18 19:16:52,900 Epoch 418/2000
2025-02-18 19:17:35,712 Current Learning Rate: 0.0098014684
2025-02-18 19:17:37,443 Train Loss: 0.0009190, Val Loss: 0.0009890
2025-02-18 19:17:37,443 Epoch 419/2000
2025-02-18 19:18:20,260 Current Learning Rate: 0.0097789651
2025-02-18 19:18:20,261 Train Loss: 0.0009876, Val Loss: 0.0010098
2025-02-18 19:18:20,261 Epoch 420/2000
2025-02-18 19:19:03,520 Current Learning Rate: 0.0097552826
2025-02-18 19:19:03,520 Train Loss: 0.0009777, Val Loss: 0.0010709
2025-02-18 19:19:03,521 Epoch 421/2000
2025-02-18 19:19:46,973 Current Learning Rate: 0.0097304268
2025-02-18 19:19:46,973 Train Loss: 0.0010375, Val Loss: 0.0010619
2025-02-18 19:19:46,973 Epoch 422/2000
2025-02-18 19:20:30,281 Current Learning Rate: 0.0097044038
2025-02-18 19:20:30,282 Train Loss: 0.0011694, Val Loss: 0.0010593
2025-02-18 19:20:30,282 Epoch 423/2000
2025-02-18 19:21:13,502 Current Learning Rate: 0.0096772202
2025-02-18 19:21:13,503 Train Loss: 0.0010318, Val Loss: 0.0011026
2025-02-18 19:21:13,503 Epoch 424/2000
2025-02-18 19:21:57,125 Current Learning Rate: 0.0096488824
2025-02-18 19:21:58,853 Train Loss: 0.0009790, Val Loss: 0.0008923
2025-02-18 19:21:58,853 Epoch 425/2000
2025-02-18 19:22:40,909 Current Learning Rate: 0.0096193977
2025-02-18 19:22:40,910 Train Loss: 0.0010028, Val Loss: 0.0010390
2025-02-18 19:22:40,910 Epoch 426/2000
2025-02-18 19:23:24,187 Current Learning Rate: 0.0095887731
2025-02-18 19:23:24,188 Train Loss: 0.0012474, Val Loss: 0.0010552
2025-02-18 19:23:24,188 Epoch 427/2000
2025-02-18 19:24:06,971 Current Learning Rate: 0.0095570164
2025-02-18 19:24:06,971 Train Loss: 0.0009328, Val Loss: 0.0008956
2025-02-18 19:24:06,971 Epoch 428/2000
2025-02-18 19:24:49,573 Current Learning Rate: 0.0095241353
2025-02-18 19:24:49,574 Train Loss: 0.0010250, Val Loss: 0.0009040
2025-02-18 19:24:49,574 Epoch 429/2000
2025-02-18 19:25:33,175 Current Learning Rate: 0.0094901379
2025-02-18 19:25:33,175 Train Loss: 0.0008876, Val Loss: 0.0009556
2025-02-18 19:25:33,176 Epoch 430/2000
2025-02-18 19:26:16,275 Current Learning Rate: 0.0094550326
2025-02-18 19:26:17,573 Train Loss: 0.0008340, Val Loss: 0.0008763
2025-02-18 19:26:17,573 Epoch 431/2000
2025-02-18 19:27:00,468 Current Learning Rate: 0.0094188282
2025-02-18 19:27:00,469 Train Loss: 0.0008833, Val Loss: 0.0009338
2025-02-18 19:27:00,469 Epoch 432/2000
2025-02-18 19:27:42,605 Current Learning Rate: 0.0093815334
2025-02-18 19:27:44,514 Train Loss: 0.0009102, Val Loss: 0.0008535
2025-02-18 19:27:44,515 Epoch 433/2000
2025-02-18 19:28:27,554 Current Learning Rate: 0.0093431576
2025-02-18 19:28:29,593 Train Loss: 0.0007994, Val Loss: 0.0008042
2025-02-18 19:28:29,593 Epoch 434/2000
2025-02-18 19:29:12,397 Current Learning Rate: 0.0093037101
2025-02-18 19:29:14,361 Train Loss: 0.0007456, Val Loss: 0.0008031
2025-02-18 19:29:14,362 Epoch 435/2000
2025-02-18 19:29:56,702 Current Learning Rate: 0.0092632008
2025-02-18 19:29:58,165 Train Loss: 0.0007755, Val Loss: 0.0008031
2025-02-18 19:29:58,166 Epoch 436/2000
2025-02-18 19:30:41,345 Current Learning Rate: 0.0092216396
2025-02-18 19:30:43,344 Train Loss: 0.0007013, Val Loss: 0.0007970
2025-02-18 19:30:43,345 Epoch 437/2000
2025-02-18 19:31:25,150 Current Learning Rate: 0.0091790368
2025-02-18 19:31:25,151 Train Loss: 0.0006960, Val Loss: 0.0007992
2025-02-18 19:31:25,151 Epoch 438/2000
2025-02-18 19:32:08,564 Current Learning Rate: 0.0091354029
2025-02-18 19:32:08,565 Train Loss: 0.0007976, Val Loss: 0.0008266
2025-02-18 19:32:08,565 Epoch 439/2000
2025-02-18 19:32:52,143 Current Learning Rate: 0.0090907486
2025-02-18 19:32:52,143 Train Loss: 0.0008247, Val Loss: 0.0008597
2025-02-18 19:32:52,144 Epoch 440/2000
2025-02-18 19:33:34,864 Current Learning Rate: 0.0090450850
2025-02-18 19:33:34,865 Train Loss: 0.0009173, Val Loss: 0.0009132
2025-02-18 19:33:34,865 Epoch 441/2000
2025-02-18 19:34:18,025 Current Learning Rate: 0.0089984233
2025-02-18 19:34:18,026 Train Loss: 0.0006895, Val Loss: 0.0008034
2025-02-18 19:34:18,026 Epoch 442/2000
2025-02-18 19:35:00,925 Current Learning Rate: 0.0089507751
2025-02-18 19:35:00,925 Train Loss: 0.0007486, Val Loss: 0.0008509
2025-02-18 19:35:00,926 Epoch 443/2000
2025-02-18 19:35:43,106 Current Learning Rate: 0.0089021520
2025-02-18 19:35:43,106 Train Loss: 0.0011021, Val Loss: 0.0008607
2025-02-18 19:35:43,107 Epoch 444/2000
2025-02-18 19:36:26,033 Current Learning Rate: 0.0088525662
2025-02-18 19:36:26,034 Train Loss: 0.0008986, Val Loss: 0.0009608
2025-02-18 19:36:26,035 Epoch 445/2000
2025-02-18 19:37:08,657 Current Learning Rate: 0.0088020298
2025-02-18 19:37:08,658 Train Loss: 0.0008676, Val Loss: 0.0009627
2025-02-18 19:37:08,658 Epoch 446/2000
2025-02-18 19:37:52,301 Current Learning Rate: 0.0087505553
2025-02-18 19:37:52,302 Train Loss: 0.0007821, Val Loss: 0.0008340
2025-02-18 19:37:52,303 Epoch 447/2000
2025-02-18 19:38:35,869 Current Learning Rate: 0.0086981555
2025-02-18 19:38:35,870 Train Loss: 0.0009361, Val Loss: 0.0008472
2025-02-18 19:38:35,870 Epoch 448/2000
2025-02-18 19:39:19,117 Current Learning Rate: 0.0086448431
2025-02-18 19:39:21,257 Train Loss: 0.0007113, Val Loss: 0.0007563
2025-02-18 19:39:21,257 Epoch 449/2000
2025-02-18 19:40:04,305 Current Learning Rate: 0.0085906315
2025-02-18 19:40:04,306 Train Loss: 0.0007372, Val Loss: 0.0007889
2025-02-18 19:40:04,306 Epoch 450/2000
2025-02-18 19:40:47,432 Current Learning Rate: 0.0085355339
2025-02-18 19:40:47,432 Train Loss: 0.0008533, Val Loss: 0.0008757
2025-02-18 19:40:47,432 Epoch 451/2000
2025-02-18 19:41:29,680 Current Learning Rate: 0.0084795640
2025-02-18 19:41:31,265 Train Loss: 0.0007861, Val Loss: 0.0007555
2025-02-18 19:41:31,266 Epoch 452/2000
2025-02-18 19:42:12,721 Current Learning Rate: 0.0084227355
2025-02-18 19:42:12,723 Train Loss: 0.0006757, Val Loss: 0.0007673
2025-02-18 19:42:12,723 Epoch 453/2000
2025-02-18 19:42:55,405 Current Learning Rate: 0.0083650626
2025-02-18 19:42:55,406 Train Loss: 0.0008313, Val Loss: 0.0007784
2025-02-18 19:42:55,406 Epoch 454/2000
2025-02-18 19:43:38,638 Current Learning Rate: 0.0083065593
2025-02-18 19:43:38,638 Train Loss: 0.0007668, Val Loss: 0.0007979
2025-02-18 19:43:38,638 Epoch 455/2000
2025-02-18 19:44:20,814 Current Learning Rate: 0.0082472402
2025-02-18 19:44:20,815 Train Loss: 0.0008555, Val Loss: 0.0010283
2025-02-18 19:44:20,815 Epoch 456/2000
2025-02-18 19:45:03,393 Current Learning Rate: 0.0081871199
2025-02-18 19:45:05,072 Train Loss: 0.0007266, Val Loss: 0.0007519
2025-02-18 19:45:05,072 Epoch 457/2000
2025-02-18 19:45:46,775 Current Learning Rate: 0.0081262133
2025-02-18 19:45:46,777 Train Loss: 0.0007581, Val Loss: 0.0007625
2025-02-18 19:45:46,777 Epoch 458/2000
2025-02-18 19:46:29,572 Current Learning Rate: 0.0080645353
2025-02-18 19:46:29,573 Train Loss: 0.0008003, Val Loss: 0.0007955
2025-02-18 19:46:29,573 Epoch 459/2000
2025-02-18 19:47:12,594 Current Learning Rate: 0.0080021011
2025-02-18 19:47:14,438 Train Loss: 0.0008082, Val Loss: 0.0007480
2025-02-18 19:47:14,439 Epoch 460/2000
2025-02-18 19:47:55,877 Current Learning Rate: 0.0079389263
2025-02-18 19:47:56,988 Train Loss: 0.0006230, Val Loss: 0.0007110
2025-02-18 19:47:56,988 Epoch 461/2000
2025-02-18 19:48:38,381 Current Learning Rate: 0.0078750263
2025-02-18 19:48:38,381 Train Loss: 0.0007029, Val Loss: 0.0007509
2025-02-18 19:48:38,382 Epoch 462/2000
2025-02-18 19:49:21,463 Current Learning Rate: 0.0078104169
2025-02-18 19:49:21,464 Train Loss: 0.0007934, Val Loss: 0.0007817
2025-02-18 19:49:21,464 Epoch 463/2000
2025-02-18 19:50:04,408 Current Learning Rate: 0.0077451141
2025-02-18 19:50:04,408 Train Loss: 0.0006062, Val Loss: 0.0007356
2025-02-18 19:50:04,409 Epoch 464/2000
2025-02-18 19:50:47,602 Current Learning Rate: 0.0076791340
2025-02-18 19:50:47,602 Train Loss: 0.0006761, Val Loss: 0.0007192
2025-02-18 19:50:47,602 Epoch 465/2000
2025-02-18 19:51:31,126 Current Learning Rate: 0.0076124928
2025-02-18 19:51:31,126 Train Loss: 0.0007075, Val Loss: 0.0007434
2025-02-18 19:51:31,126 Epoch 466/2000
2025-02-18 19:52:13,159 Current Learning Rate: 0.0075452071
2025-02-18 19:52:13,160 Train Loss: 0.0006940, Val Loss: 0.0007113
2025-02-18 19:52:13,160 Epoch 467/2000
2025-02-18 19:52:55,713 Current Learning Rate: 0.0074772933
2025-02-18 19:52:55,713 Train Loss: 0.0006135, Val Loss: 0.0007139
2025-02-18 19:52:55,713 Epoch 468/2000
2025-02-18 19:53:38,999 Current Learning Rate: 0.0074087684
2025-02-18 19:53:39,000 Train Loss: 0.0007084, Val Loss: 0.0007598
2025-02-18 19:53:39,000 Epoch 469/2000
2025-02-18 19:54:21,461 Current Learning Rate: 0.0073396491
2025-02-18 19:54:23,305 Train Loss: 0.0007285, Val Loss: 0.0006965
2025-02-18 19:54:23,305 Epoch 470/2000
2025-02-18 19:55:05,022 Current Learning Rate: 0.0072699525
2025-02-18 19:55:05,025 Train Loss: 0.0007479, Val Loss: 0.0007113
2025-02-18 19:55:05,033 Epoch 471/2000
2025-02-18 19:55:48,334 Current Learning Rate: 0.0071996958
2025-02-18 19:55:48,335 Train Loss: 0.0008276, Val Loss: 0.0007131
2025-02-18 19:55:48,335 Epoch 472/2000
2025-02-18 19:56:30,130 Current Learning Rate: 0.0071288965
2025-02-18 19:56:30,131 Train Loss: 0.0007012, Val Loss: 0.0007755
2025-02-18 19:56:30,131 Epoch 473/2000
2025-02-18 19:57:13,513 Current Learning Rate: 0.0070575718
2025-02-18 19:57:13,513 Train Loss: 0.0006384, Val Loss: 0.0007046
2025-02-18 19:57:13,514 Epoch 474/2000
2025-02-18 19:57:55,389 Current Learning Rate: 0.0069857395
2025-02-18 19:57:56,698 Train Loss: 0.0006106, Val Loss: 0.0006879
2025-02-18 19:57:56,706 Epoch 475/2000
2025-02-18 19:58:39,630 Current Learning Rate: 0.0069134172
2025-02-18 19:58:41,550 Train Loss: 0.0005941, Val Loss: 0.0006362
2025-02-18 19:58:41,551 Epoch 476/2000
2025-02-18 19:59:23,669 Current Learning Rate: 0.0068406228
2025-02-18 19:59:25,357 Train Loss: 0.0005749, Val Loss: 0.0006203
2025-02-18 19:59:25,357 Epoch 477/2000
2025-02-18 20:00:08,471 Current Learning Rate: 0.0067673742
2025-02-18 20:00:08,472 Train Loss: 0.0005808, Val Loss: 0.0006563
2025-02-18 20:00:08,473 Epoch 478/2000
2025-02-18 20:00:50,511 Current Learning Rate: 0.0066936896
2025-02-18 20:00:50,512 Train Loss: 0.0007293, Val Loss: 0.0007316
2025-02-18 20:00:50,512 Epoch 479/2000
2025-02-18 20:01:32,700 Current Learning Rate: 0.0066195871
2025-02-18 20:01:32,700 Train Loss: 0.0006753, Val Loss: 0.0006559
2025-02-18 20:01:32,701 Epoch 480/2000
2025-02-18 20:02:16,248 Current Learning Rate: 0.0065450850
2025-02-18 20:02:16,249 Train Loss: 0.0006014, Val Loss: 0.0006347
2025-02-18 20:02:16,249 Epoch 481/2000
2025-02-18 20:02:59,534 Current Learning Rate: 0.0064702016
2025-02-18 20:02:59,535 Train Loss: 0.0005768, Val Loss: 0.0006270
2025-02-18 20:02:59,535 Epoch 482/2000
2025-02-18 20:03:41,788 Current Learning Rate: 0.0063949555
2025-02-18 20:03:41,788 Train Loss: 0.0004969, Val Loss: 0.0006244
2025-02-18 20:03:41,789 Epoch 483/2000
2025-02-18 20:04:25,008 Current Learning Rate: 0.0063193652
2025-02-18 20:04:25,009 Train Loss: 0.0006966, Val Loss: 0.0007884
2025-02-18 20:04:25,009 Epoch 484/2000
2025-02-18 20:05:08,598 Current Learning Rate: 0.0062434494
2025-02-18 20:05:08,598 Train Loss: 0.0005425, Val Loss: 0.0006594
2025-02-18 20:05:08,598 Epoch 485/2000
2025-02-18 20:05:50,586 Current Learning Rate: 0.0061672268
2025-02-18 20:05:50,587 Train Loss: 0.0005567, Val Loss: 0.0006676
2025-02-18 20:05:50,587 Epoch 486/2000
2025-02-18 20:06:33,881 Current Learning Rate: 0.0060907162
2025-02-18 20:06:33,882 Train Loss: 0.0007032, Val Loss: 0.0006918
2025-02-18 20:06:33,882 Epoch 487/2000
2025-02-18 20:07:16,328 Current Learning Rate: 0.0060139365
2025-02-18 20:07:16,329 Train Loss: 0.0005944, Val Loss: 0.0006368
2025-02-18 20:07:16,329 Epoch 488/2000
2025-02-18 20:08:00,116 Current Learning Rate: 0.0059369066
2025-02-18 20:08:00,116 Train Loss: 0.0007418, Val Loss: 0.0008033
2025-02-18 20:08:00,117 Epoch 489/2000
2025-02-18 20:08:42,409 Current Learning Rate: 0.0058596455
2025-02-18 20:08:42,410 Train Loss: 0.0006701, Val Loss: 0.0007014
2025-02-18 20:08:42,411 Epoch 490/2000
2025-02-18 20:09:25,832 Current Learning Rate: 0.0057821723
2025-02-18 20:09:25,833 Train Loss: 0.0006095, Val Loss: 0.0007286
2025-02-18 20:09:25,834 Epoch 491/2000
2025-02-18 20:10:09,101 Current Learning Rate: 0.0057045062
2025-02-18 20:10:09,102 Train Loss: 0.0006757, Val Loss: 0.0006271
2025-02-18 20:10:09,102 Epoch 492/2000
2025-02-18 20:10:51,410 Current Learning Rate: 0.0056266662
2025-02-18 20:10:51,411 Train Loss: 0.0007621, Val Loss: 0.0006948
2025-02-18 20:10:51,411 Epoch 493/2000
2025-02-18 20:11:34,226 Current Learning Rate: 0.0055486716
2025-02-18 20:11:34,226 Train Loss: 0.0006900, Val Loss: 0.0010454
2025-02-18 20:11:34,227 Epoch 494/2000
2025-02-18 20:12:17,643 Current Learning Rate: 0.0054705416
2025-02-18 20:12:17,644 Train Loss: 0.0008437, Val Loss: 0.0007571
2025-02-18 20:12:17,644 Epoch 495/2000
2025-02-18 20:13:01,049 Current Learning Rate: 0.0053922955
2025-02-18 20:13:03,367 Train Loss: 0.0006913, Val Loss: 0.0006169
2025-02-18 20:13:03,367 Epoch 496/2000
2025-02-18 20:13:46,033 Current Learning Rate: 0.0053139526
2025-02-18 20:13:47,886 Train Loss: 0.0004793, Val Loss: 0.0005901
2025-02-18 20:13:47,886 Epoch 497/2000
2025-02-18 20:14:29,636 Current Learning Rate: 0.0052355323
2025-02-18 20:14:29,637 Train Loss: 0.0005662, Val Loss: 0.0006020
2025-02-18 20:14:29,638 Epoch 498/2000
2025-02-18 20:15:13,105 Current Learning Rate: 0.0051570538
2025-02-18 20:15:14,866 Train Loss: 0.0005533, Val Loss: 0.0005840
2025-02-18 20:15:14,866 Epoch 499/2000
2025-02-18 20:15:56,324 Current Learning Rate: 0.0050785366
2025-02-18 20:15:57,918 Train Loss: 0.0005304, Val Loss: 0.0005641
2025-02-18 20:15:57,918 Epoch 500/2000
2025-02-18 20:16:40,881 Current Learning Rate: 0.0050000000
2025-02-18 20:16:40,882 Train Loss: 0.0004447, Val Loss: 0.0005674
2025-02-18 20:16:40,883 Epoch 501/2000
2025-02-18 20:17:23,002 Current Learning Rate: 0.0049214634
2025-02-18 20:17:23,003 Train Loss: 0.0004908, Val Loss: 0.0005810
2025-02-18 20:17:23,003 Epoch 502/2000
2025-02-18 20:18:06,050 Current Learning Rate: 0.0048429462
2025-02-18 20:18:06,050 Train Loss: 0.0004975, Val Loss: 0.0005829
2025-02-18 20:18:06,051 Epoch 503/2000
2025-02-18 20:18:48,804 Current Learning Rate: 0.0047644677
2025-02-18 20:18:50,634 Train Loss: 0.0005299, Val Loss: 0.0005455
2025-02-18 20:18:50,634 Epoch 504/2000
2025-02-18 20:19:32,043 Current Learning Rate: 0.0046860474
2025-02-18 20:19:32,043 Train Loss: 0.0004964, Val Loss: 0.0005700
2025-02-18 20:19:32,044 Epoch 505/2000
2025-02-18 20:20:15,400 Current Learning Rate: 0.0046077045
2025-02-18 20:20:15,401 Train Loss: 0.0004832, Val Loss: 0.0005934
2025-02-18 20:20:15,401 Epoch 506/2000
2025-02-18 20:20:58,350 Current Learning Rate: 0.0045294584
2025-02-18 20:20:58,350 Train Loss: 0.0005651, Val Loss: 0.0005681
2025-02-18 20:20:58,376 Epoch 507/2000
2025-02-18 20:21:41,711 Current Learning Rate: 0.0044513284
2025-02-18 20:21:41,712 Train Loss: 0.0004447, Val Loss: 0.0005573
2025-02-18 20:21:41,712 Epoch 508/2000
2025-02-18 20:22:25,072 Current Learning Rate: 0.0043733338
2025-02-18 20:22:27,092 Train Loss: 0.0005681, Val Loss: 0.0005372
2025-02-18 20:22:27,092 Epoch 509/2000
2025-02-18 20:23:10,305 Current Learning Rate: 0.0042954938
2025-02-18 20:23:10,306 Train Loss: 0.0004749, Val Loss: 0.0005407
2025-02-18 20:23:10,306 Epoch 510/2000
2025-02-18 20:23:53,486 Current Learning Rate: 0.0042178277
2025-02-18 20:23:55,236 Train Loss: 0.0005136, Val Loss: 0.0005314
2025-02-18 20:23:55,236 Epoch 511/2000
2025-02-18 20:24:36,729 Current Learning Rate: 0.0041403545
2025-02-18 20:24:38,347 Train Loss: 0.0004961, Val Loss: 0.0005310
2025-02-18 20:24:38,348 Epoch 512/2000
2025-02-18 20:25:20,861 Current Learning Rate: 0.0040630934
2025-02-18 20:25:23,044 Train Loss: 0.0005754, Val Loss: 0.0005265
2025-02-18 20:25:23,044 Epoch 513/2000
2025-02-18 20:26:06,165 Current Learning Rate: 0.0039860635
2025-02-18 20:26:08,224 Train Loss: 0.0004098, Val Loss: 0.0005233
2025-02-18 20:26:08,224 Epoch 514/2000
2025-02-18 20:26:51,562 Current Learning Rate: 0.0039092838
2025-02-18 20:26:51,563 Train Loss: 0.0005606, Val Loss: 0.0005408
2025-02-18 20:26:51,563 Epoch 515/2000
2025-02-18 20:27:35,053 Current Learning Rate: 0.0038327732
2025-02-18 20:27:35,053 Train Loss: 0.0005602, Val Loss: 0.0005325
2025-02-18 20:27:35,054 Epoch 516/2000
2025-02-18 20:28:18,209 Current Learning Rate: 0.0037565506
2025-02-18 20:28:18,210 Train Loss: 0.0004406, Val Loss: 0.0005445
2025-02-18 20:28:18,210 Epoch 517/2000
2025-02-18 20:29:01,143 Current Learning Rate: 0.0036806348
2025-02-18 20:29:01,144 Train Loss: 0.0004557, Val Loss: 0.0005442
2025-02-18 20:29:01,144 Epoch 518/2000
2025-02-18 20:29:44,007 Current Learning Rate: 0.0036050445
2025-02-18 20:29:44,007 Train Loss: 0.0004850, Val Loss: 0.0005578
2025-02-18 20:29:44,007 Epoch 519/2000
2025-02-18 20:30:26,371 Current Learning Rate: 0.0035297984
2025-02-18 20:30:26,372 Train Loss: 0.0004421, Val Loss: 0.0005278
2025-02-18 20:30:26,372 Epoch 520/2000
2025-02-18 20:31:10,020 Current Learning Rate: 0.0034549150
2025-02-18 20:31:10,021 Train Loss: 0.0005167, Val Loss: 0.0005400
2025-02-18 20:31:10,021 Epoch 521/2000
2025-02-18 20:31:53,457 Current Learning Rate: 0.0033804129
2025-02-18 20:31:55,345 Train Loss: 0.0004615, Val Loss: 0.0005043
2025-02-18 20:31:55,345 Epoch 522/2000
2025-02-18 20:32:36,845 Current Learning Rate: 0.0033063104
2025-02-18 20:32:38,361 Train Loss: 0.0004535, Val Loss: 0.0004982
2025-02-18 20:32:38,361 Epoch 523/2000
2025-02-18 20:33:20,891 Current Learning Rate: 0.0032326258
2025-02-18 20:33:20,891 Train Loss: 0.0004284, Val Loss: 0.0004999
2025-02-18 20:33:20,892 Epoch 524/2000
2025-02-18 20:34:04,011 Current Learning Rate: 0.0031593772
2025-02-18 20:34:05,653 Train Loss: 0.0004283, Val Loss: 0.0004947
2025-02-18 20:34:05,653 Epoch 525/2000
2025-02-18 20:34:47,174 Current Learning Rate: 0.0030865828
2025-02-18 20:34:47,176 Train Loss: 0.0005067, Val Loss: 0.0005016
2025-02-18 20:34:47,176 Epoch 526/2000
2025-02-18 20:35:30,445 Current Learning Rate: 0.0030142605
2025-02-18 20:35:30,446 Train Loss: 0.0004307, Val Loss: 0.0005006
2025-02-18 20:35:30,446 Epoch 527/2000
2025-02-18 20:36:12,391 Current Learning Rate: 0.0029424282
2025-02-18 20:36:12,392 Train Loss: 0.0004258, Val Loss: 0.0004951
2025-02-18 20:36:12,392 Epoch 528/2000
2025-02-18 20:36:55,051 Current Learning Rate: 0.0028711035
2025-02-18 20:36:55,052 Train Loss: 0.0005415, Val Loss: 0.0005146
2025-02-18 20:36:55,052 Epoch 529/2000
2025-02-18 20:37:38,487 Current Learning Rate: 0.0028003042
2025-02-18 20:37:40,731 Train Loss: 0.0004089, Val Loss: 0.0004895
2025-02-18 20:37:40,732 Epoch 530/2000
2025-02-18 20:38:22,034 Current Learning Rate: 0.0027300475
2025-02-18 20:38:23,590 Train Loss: 0.0004597, Val Loss: 0.0004862
2025-02-18 20:38:23,590 Epoch 531/2000
2025-02-18 20:39:05,008 Current Learning Rate: 0.0026603509
2025-02-18 20:39:05,009 Train Loss: 0.0003936, Val Loss: 0.0004920
2025-02-18 20:39:05,009 Epoch 532/2000
2025-02-18 20:39:47,966 Current Learning Rate: 0.0025912316
2025-02-18 20:39:47,967 Train Loss: 0.0004479, Val Loss: 0.0004926
2025-02-18 20:39:47,967 Epoch 533/2000
2025-02-18 20:40:30,548 Current Learning Rate: 0.0025227067
2025-02-18 20:40:31,948 Train Loss: 0.0004063, Val Loss: 0.0004787
2025-02-18 20:40:31,948 Epoch 534/2000
2025-02-18 20:41:13,657 Current Learning Rate: 0.0024547929
2025-02-18 20:41:13,658 Train Loss: 0.0004758, Val Loss: 0.0004793
2025-02-18 20:41:13,658 Epoch 535/2000
2025-02-18 20:41:56,761 Current Learning Rate: 0.0023875072
2025-02-18 20:41:58,702 Train Loss: 0.0004320, Val Loss: 0.0004662
2025-02-18 20:41:58,702 Epoch 536/2000
2025-02-18 20:42:41,168 Current Learning Rate: 0.0023208660
2025-02-18 20:42:43,309 Train Loss: 0.0003620, Val Loss: 0.0004593
2025-02-18 20:42:43,310 Epoch 537/2000
2025-02-18 20:43:26,235 Current Learning Rate: 0.0022548859
2025-02-18 20:43:28,115 Train Loss: 0.0004216, Val Loss: 0.0004585
2025-02-18 20:43:28,115 Epoch 538/2000
2025-02-18 20:44:11,365 Current Learning Rate: 0.0021895831
2025-02-18 20:44:13,273 Train Loss: 0.0003794, Val Loss: 0.0004549
2025-02-18 20:44:13,273 Epoch 539/2000
2025-02-18 20:44:55,584 Current Learning Rate: 0.0021249737
2025-02-18 20:44:55,586 Train Loss: 0.0004229, Val Loss: 0.0004557
2025-02-18 20:44:55,586 Epoch 540/2000
2025-02-18 20:45:38,276 Current Learning Rate: 0.0020610737
2025-02-18 20:45:38,277 Train Loss: 0.0004247, Val Loss: 0.0004567
2025-02-18 20:45:38,277 Epoch 541/2000
2025-02-18 20:46:20,546 Current Learning Rate: 0.0019978989
2025-02-18 20:46:20,546 Train Loss: 0.0003781, Val Loss: 0.0004562
2025-02-18 20:46:20,546 Epoch 542/2000
2025-02-18 20:47:04,095 Current Learning Rate: 0.0019354647
2025-02-18 20:47:04,096 Train Loss: 0.0004617, Val Loss: 0.0004560
2025-02-18 20:47:04,096 Epoch 543/2000
2025-02-18 20:47:47,453 Current Learning Rate: 0.0018737867
2025-02-18 20:47:47,454 Train Loss: 0.0004313, Val Loss: 0.0004576
2025-02-18 20:47:47,454 Epoch 544/2000
2025-02-18 20:48:29,907 Current Learning Rate: 0.0018128801
2025-02-18 20:48:31,997 Train Loss: 0.0003838, Val Loss: 0.0004493
2025-02-18 20:48:31,997 Epoch 545/2000
2025-02-18 20:49:13,627 Current Learning Rate: 0.0017527598
2025-02-18 20:49:15,090 Train Loss: 0.0003385, Val Loss: 0.0004434
2025-02-18 20:49:15,091 Epoch 546/2000
2025-02-18 20:49:57,984 Current Learning Rate: 0.0016934407
2025-02-18 20:49:57,985 Train Loss: 0.0005021, Val Loss: 0.0004460
2025-02-18 20:49:57,985 Epoch 547/2000
2025-02-18 20:50:40,137 Current Learning Rate: 0.0016349374
2025-02-18 20:50:41,886 Train Loss: 0.0003976, Val Loss: 0.0004426
2025-02-18 20:50:41,887 Epoch 548/2000
2025-02-18 20:51:25,348 Current Learning Rate: 0.0015772645
2025-02-18 20:51:27,383 Train Loss: 0.0004444, Val Loss: 0.0004412
2025-02-18 20:51:27,383 Epoch 549/2000
2025-02-18 20:52:09,052 Current Learning Rate: 0.0015204360
2025-02-18 20:52:10,285 Train Loss: 0.0004327, Val Loss: 0.0004386
2025-02-18 20:52:10,285 Epoch 550/2000
2025-02-18 20:52:52,118 Current Learning Rate: 0.0014644661
2025-02-18 20:52:54,077 Train Loss: 0.0003942, Val Loss: 0.0004373
2025-02-18 20:52:54,077 Epoch 551/2000
2025-02-18 20:53:37,445 Current Learning Rate: 0.0014093685
2025-02-18 20:53:39,437 Train Loss: 0.0003673, Val Loss: 0.0004368
2025-02-18 20:53:39,437 Epoch 552/2000
2025-02-18 20:54:22,654 Current Learning Rate: 0.0013551569
2025-02-18 20:54:22,655 Train Loss: 0.0004019, Val Loss: 0.0004375
2025-02-18 20:54:22,655 Epoch 553/2000
2025-02-18 20:55:04,901 Current Learning Rate: 0.0013018445
2025-02-18 20:55:04,902 Train Loss: 0.0003794, Val Loss: 0.0004380
2025-02-18 20:55:04,902 Epoch 554/2000
2025-02-18 20:55:47,579 Current Learning Rate: 0.0012494447
2025-02-18 20:55:49,198 Train Loss: 0.0003833, Val Loss: 0.0004350
2025-02-18 20:55:49,199 Epoch 555/2000
2025-02-18 20:56:30,979 Current Learning Rate: 0.0011979702
2025-02-18 20:56:32,534 Train Loss: 0.0003432, Val Loss: 0.0004326
2025-02-18 20:56:32,540 Epoch 556/2000
2025-02-18 20:57:14,279 Current Learning Rate: 0.0011474338
2025-02-18 20:57:16,140 Train Loss: 0.0003477, Val Loss: 0.0004322
2025-02-18 20:57:16,140 Epoch 557/2000
2025-02-18 20:57:57,652 Current Learning Rate: 0.0010978480
2025-02-18 20:57:59,332 Train Loss: 0.0003552, Val Loss: 0.0004289
2025-02-18 20:57:59,333 Epoch 558/2000
2025-02-18 20:58:42,263 Current Learning Rate: 0.0010492249
2025-02-18 20:58:44,235 Train Loss: 0.0003648, Val Loss: 0.0004270
2025-02-18 20:58:44,236 Epoch 559/2000
2025-02-18 20:59:27,131 Current Learning Rate: 0.0010015767
2025-02-18 20:59:27,132 Train Loss: 0.0004117, Val Loss: 0.0004274
2025-02-18 20:59:27,132 Epoch 560/2000
2025-02-18 21:00:09,478 Current Learning Rate: 0.0009549150
2025-02-18 21:00:10,738 Train Loss: 0.0004396, Val Loss: 0.0004259
2025-02-18 21:00:10,738 Epoch 561/2000
2025-02-18 21:00:52,640 Current Learning Rate: 0.0009092514
2025-02-18 21:00:54,064 Train Loss: 0.0003469, Val Loss: 0.0004241
2025-02-18 21:00:54,064 Epoch 562/2000
2025-02-18 21:01:36,985 Current Learning Rate: 0.0008645971
2025-02-18 21:01:36,986 Train Loss: 0.0004716, Val Loss: 0.0004244
2025-02-18 21:01:36,986 Epoch 563/2000
2025-02-18 21:02:19,448 Current Learning Rate: 0.0008209632
2025-02-18 21:02:20,474 Train Loss: 0.0004245, Val Loss: 0.0004240
2025-02-18 21:02:20,474 Epoch 564/2000
2025-02-18 21:03:02,957 Current Learning Rate: 0.0007783604
2025-02-18 21:03:04,556 Train Loss: 0.0003625, Val Loss: 0.0004216
2025-02-18 21:03:04,556 Epoch 565/2000
2025-02-18 21:03:47,695 Current Learning Rate: 0.0007367992
2025-02-18 21:03:49,110 Train Loss: 0.0004495, Val Loss: 0.0004207
2025-02-18 21:03:49,111 Epoch 566/2000
2025-02-18 21:04:31,927 Current Learning Rate: 0.0006962899
2025-02-18 21:04:33,694 Train Loss: 0.0004247, Val Loss: 0.0004194
2025-02-18 21:04:33,694 Epoch 567/2000
2025-02-18 21:05:15,283 Current Learning Rate: 0.0006568424
2025-02-18 21:05:17,113 Train Loss: 0.0003381, Val Loss: 0.0004184
2025-02-18 21:05:17,113 Epoch 568/2000
2025-02-18 21:05:59,666 Current Learning Rate: 0.0006184666
2025-02-18 21:05:59,667 Train Loss: 0.0004187, Val Loss: 0.0004187
2025-02-18 21:05:59,667 Epoch 569/2000
2025-02-18 21:06:42,056 Current Learning Rate: 0.0005811718
2025-02-18 21:06:43,958 Train Loss: 0.0003780, Val Loss: 0.0004168
2025-02-18 21:06:43,959 Epoch 570/2000
2025-02-18 21:07:26,007 Current Learning Rate: 0.0005449674
2025-02-18 21:07:27,238 Train Loss: 0.0003661, Val Loss: 0.0004166
2025-02-18 21:07:27,238 Epoch 571/2000
2025-02-18 21:08:09,969 Current Learning Rate: 0.0005098621
2025-02-18 21:08:11,778 Train Loss: 0.0003576, Val Loss: 0.0004156
2025-02-18 21:08:11,779 Epoch 572/2000
2025-02-18 21:08:54,791 Current Learning Rate: 0.0004758647
2025-02-18 21:08:54,791 Train Loss: 0.0003587, Val Loss: 0.0004156
2025-02-18 21:08:54,792 Epoch 573/2000
2025-02-18 21:09:37,743 Current Learning Rate: 0.0004429836
2025-02-18 21:09:39,757 Train Loss: 0.0003924, Val Loss: 0.0004152
2025-02-18 21:09:39,758 Epoch 574/2000
2025-02-18 21:10:22,656 Current Learning Rate: 0.0004112269
2025-02-18 21:10:24,766 Train Loss: 0.0003581, Val Loss: 0.0004147
2025-02-18 21:10:24,766 Epoch 575/2000
2025-02-18 21:11:07,395 Current Learning Rate: 0.0003806023
2025-02-18 21:11:09,587 Train Loss: 0.0003441, Val Loss: 0.0004141
2025-02-18 21:11:09,588 Epoch 576/2000
2025-02-18 21:11:51,729 Current Learning Rate: 0.0003511176
2025-02-18 21:11:51,730 Train Loss: 0.0003744, Val Loss: 0.0004144
2025-02-18 21:11:51,730 Epoch 577/2000
2025-02-18 21:12:34,245 Current Learning Rate: 0.0003227798
2025-02-18 21:12:36,179 Train Loss: 0.0003960, Val Loss: 0.0004140
2025-02-18 21:12:36,180 Epoch 578/2000
2025-02-18 21:13:17,896 Current Learning Rate: 0.0002955962
2025-02-18 21:13:19,546 Train Loss: 0.0004083, Val Loss: 0.0004134
2025-02-18 21:13:19,547 Epoch 579/2000
2025-02-18 21:14:01,137 Current Learning Rate: 0.0002695732
2025-02-18 21:14:02,564 Train Loss: 0.0004647, Val Loss: 0.0004130
2025-02-18 21:14:02,564 Epoch 580/2000
2025-02-18 21:14:45,156 Current Learning Rate: 0.0002447174
2025-02-18 21:14:47,198 Train Loss: 0.0003394, Val Loss: 0.0004125
2025-02-18 21:14:47,198 Epoch 581/2000
2025-02-18 21:15:28,656 Current Learning Rate: 0.0002210349
2025-02-18 21:15:29,782 Train Loss: 0.0003907, Val Loss: 0.0004123
2025-02-18 21:15:29,785 Epoch 582/2000
2025-02-18 21:16:12,448 Current Learning Rate: 0.0001985316
2025-02-18 21:16:14,181 Train Loss: 0.0003728, Val Loss: 0.0004117
2025-02-18 21:16:14,182 Epoch 583/2000
2025-02-18 21:16:57,133 Current Learning Rate: 0.0001772129
2025-02-18 21:16:57,133 Train Loss: 0.0004333, Val Loss: 0.0004123
2025-02-18 21:16:57,134 Epoch 584/2000
2025-02-18 21:17:39,609 Current Learning Rate: 0.0001570842
2025-02-18 21:17:41,438 Train Loss: 0.0004582, Val Loss: 0.0004115
2025-02-18 21:17:41,439 Epoch 585/2000
2025-02-18 21:18:24,860 Current Learning Rate: 0.0001381504
2025-02-18 21:18:26,515 Train Loss: 0.0003865, Val Loss: 0.0004112
2025-02-18 21:18:26,515 Epoch 586/2000
2025-02-18 21:19:10,021 Current Learning Rate: 0.0001204162
2025-02-18 21:19:11,797 Train Loss: 0.0003433, Val Loss: 0.0004109
2025-02-18 21:19:11,798 Epoch 587/2000
2025-02-18 21:19:54,935 Current Learning Rate: 0.0001038859
2025-02-18 21:19:56,861 Train Loss: 0.0004351, Val Loss: 0.0004105
2025-02-18 21:19:56,862 Epoch 588/2000
2025-02-18 21:20:39,446 Current Learning Rate: 0.0000885637
2025-02-18 21:20:40,841 Train Loss: 0.0003127, Val Loss: 0.0004104
2025-02-18 21:20:40,842 Epoch 589/2000
2025-02-18 21:21:22,685 Current Learning Rate: 0.0000744534
2025-02-18 21:21:23,936 Train Loss: 0.0003826, Val Loss: 0.0004103
2025-02-18 21:21:23,936 Epoch 590/2000
2025-02-18 21:22:07,039 Current Learning Rate: 0.0000615583
2025-02-18 21:22:08,585 Train Loss: 0.0004287, Val Loss: 0.0004101
2025-02-18 21:22:08,585 Epoch 591/2000
2025-02-18 21:22:50,676 Current Learning Rate: 0.0000498817
2025-02-18 21:22:50,680 Train Loss: 0.0003664, Val Loss: 0.0004104
2025-02-18 21:22:50,680 Epoch 592/2000
2025-02-18 21:23:33,061 Current Learning Rate: 0.0000394265
2025-02-18 21:23:33,062 Train Loss: 0.0004313, Val Loss: 0.0004102
2025-02-18 21:23:33,062 Epoch 593/2000
2025-02-18 21:24:16,256 Current Learning Rate: 0.0000301952
2025-02-18 21:24:17,865 Train Loss: 0.0003584, Val Loss: 0.0004101
2025-02-18 21:24:17,865 Epoch 594/2000
2025-02-18 21:25:00,136 Current Learning Rate: 0.0000221902
2025-02-18 21:25:02,348 Train Loss: 0.0004048, Val Loss: 0.0004099
2025-02-18 21:25:02,349 Epoch 595/2000
2025-02-18 21:25:44,168 Current Learning Rate: 0.0000154133
2025-02-18 21:25:44,169 Train Loss: 0.0004053, Val Loss: 0.0004099
2025-02-18 21:25:44,169 Epoch 596/2000
2025-02-18 21:26:27,927 Current Learning Rate: 0.0000098664
2025-02-18 21:26:29,856 Train Loss: 0.0003801, Val Loss: 0.0004098
2025-02-18 21:26:29,857 Epoch 597/2000
2025-02-18 21:27:12,769 Current Learning Rate: 0.0000055506
2025-02-18 21:27:12,769 Train Loss: 0.0003361, Val Loss: 0.0004099
2025-02-18 21:27:12,770 Epoch 598/2000
2025-02-18 21:27:56,003 Current Learning Rate: 0.0000024672
2025-02-18 21:27:56,004 Train Loss: 0.0003320, Val Loss: 0.0004099
2025-02-18 21:27:56,004 Epoch 599/2000
2025-02-18 21:28:39,329 Current Learning Rate: 0.0000006168
2025-02-18 21:28:39,330 Train Loss: 0.0003529, Val Loss: 0.0004099
2025-02-18 21:28:39,330 Epoch 600/2000
2025-02-18 21:29:22,416 Current Learning Rate: 0.0000000000
2025-02-18 21:29:22,416 Train Loss: 0.0003468, Val Loss: 0.0004099
2025-02-18 21:29:22,416 Epoch 601/2000
2025-02-18 21:30:04,732 Current Learning Rate: 0.0000006168
2025-02-18 21:30:06,293 Train Loss: 0.0004434, Val Loss: 0.0004098
2025-02-18 21:30:06,296 Epoch 602/2000
2025-02-18 21:30:49,010 Current Learning Rate: 0.0000024672
2025-02-18 21:30:50,970 Train Loss: 0.0003937, Val Loss: 0.0004098
2025-02-18 21:30:50,971 Epoch 603/2000
2025-02-18 21:31:34,015 Current Learning Rate: 0.0000055506
2025-02-18 21:31:34,016 Train Loss: 0.0003213, Val Loss: 0.0004099
2025-02-18 21:31:34,016 Epoch 604/2000
2025-02-18 21:32:17,134 Current Learning Rate: 0.0000098664
2025-02-18 21:32:17,135 Train Loss: 0.0003881, Val Loss: 0.0004099
2025-02-18 21:32:17,135 Epoch 605/2000
2025-02-18 21:33:00,491 Current Learning Rate: 0.0000154133
2025-02-18 21:33:00,491 Train Loss: 0.0003433, Val Loss: 0.0004099
2025-02-18 21:33:00,492 Epoch 606/2000
2025-02-18 21:33:44,063 Current Learning Rate: 0.0000221902
2025-02-18 21:33:45,818 Train Loss: 0.0003753, Val Loss: 0.0004097
2025-02-18 21:33:45,818 Epoch 607/2000
2025-02-18 21:34:29,071 Current Learning Rate: 0.0000301952
2025-02-18 21:34:29,072 Train Loss: 0.0003136, Val Loss: 0.0004098
2025-02-18 21:34:29,072 Epoch 608/2000
2025-02-18 21:35:12,360 Current Learning Rate: 0.0000394265
2025-02-18 21:35:12,360 Train Loss: 0.0003379, Val Loss: 0.0004099
2025-02-18 21:35:12,396 Epoch 609/2000
2025-02-18 21:35:55,678 Current Learning Rate: 0.0000498817
2025-02-18 21:35:55,678 Train Loss: 0.0003809, Val Loss: 0.0004100
2025-02-18 21:35:55,678 Epoch 610/2000
2025-02-18 21:36:38,745 Current Learning Rate: 0.0000615583
2025-02-18 21:36:38,745 Train Loss: 0.0003329, Val Loss: 0.0004102
2025-02-18 21:36:38,745 Epoch 611/2000
2025-02-18 21:37:21,786 Current Learning Rate: 0.0000744534
2025-02-18 21:37:21,786 Train Loss: 0.0003848, Val Loss: 0.0004101
2025-02-18 21:37:21,786 Epoch 612/2000
2025-02-18 21:38:03,786 Current Learning Rate: 0.0000885637
2025-02-18 21:38:03,787 Train Loss: 0.0004202, Val Loss: 0.0004098
2025-02-18 21:38:03,787 Epoch 613/2000
2025-02-18 21:38:46,450 Current Learning Rate: 0.0001038859
2025-02-18 21:38:46,451 Train Loss: 0.0003490, Val Loss: 0.0004099
2025-02-18 21:38:46,452 Epoch 614/2000
2025-02-18 21:39:28,803 Current Learning Rate: 0.0001204162
2025-02-18 21:39:28,804 Train Loss: 0.0003789, Val Loss: 0.0004099
2025-02-18 21:39:28,804 Epoch 615/2000
2025-02-18 21:40:11,467 Current Learning Rate: 0.0001381504
2025-02-18 21:40:11,468 Train Loss: 0.0003130, Val Loss: 0.0004100
2025-02-18 21:40:11,468 Epoch 616/2000
2025-02-18 21:40:53,379 Current Learning Rate: 0.0001570842
2025-02-18 21:40:53,379 Train Loss: 0.0003750, Val Loss: 0.0004101
2025-02-18 21:40:53,380 Epoch 617/2000
2025-02-18 21:41:36,577 Current Learning Rate: 0.0001772129
2025-02-18 21:41:36,577 Train Loss: 0.0004359, Val Loss: 0.0004105
2025-02-18 21:41:36,577 Epoch 618/2000
2025-02-18 21:42:18,826 Current Learning Rate: 0.0001985316
2025-02-18 21:42:18,826 Train Loss: 0.0003375, Val Loss: 0.0004104
2025-02-18 21:42:18,826 Epoch 619/2000
2025-02-18 21:43:01,769 Current Learning Rate: 0.0002210349
2025-02-18 21:43:01,770 Train Loss: 0.0003533, Val Loss: 0.0004111
2025-02-18 21:43:01,770 Epoch 620/2000
2025-02-18 21:43:44,160 Current Learning Rate: 0.0002447174
2025-02-18 21:43:44,160 Train Loss: 0.0003522, Val Loss: 0.0004102
2025-02-18 21:43:44,160 Epoch 621/2000
2025-02-18 21:44:26,844 Current Learning Rate: 0.0002695732
2025-02-18 21:44:26,845 Train Loss: 0.0004008, Val Loss: 0.0004105
2025-02-18 21:44:26,845 Epoch 622/2000
2025-02-18 21:45:09,653 Current Learning Rate: 0.0002955962
2025-02-18 21:45:09,654 Train Loss: 0.0003616, Val Loss: 0.0004104
2025-02-18 21:45:09,654 Epoch 623/2000
2025-02-18 21:45:52,342 Current Learning Rate: 0.0003227798
2025-02-18 21:45:52,346 Train Loss: 0.0003655, Val Loss: 0.0004104
2025-02-18 21:45:52,347 Epoch 624/2000
2025-02-18 21:46:34,750 Current Learning Rate: 0.0003511176
2025-02-18 21:46:34,753 Train Loss: 0.0003116, Val Loss: 0.0004102
2025-02-18 21:46:34,753 Epoch 625/2000
2025-02-18 21:47:17,584 Current Learning Rate: 0.0003806023
2025-02-18 21:47:17,585 Train Loss: 0.0004073, Val Loss: 0.0004108
2025-02-18 21:47:17,586 Epoch 626/2000
2025-02-18 21:48:00,340 Current Learning Rate: 0.0004112269
2025-02-18 21:48:00,340 Train Loss: 0.0003908, Val Loss: 0.0004101
2025-02-18 21:48:00,341 Epoch 627/2000
2025-02-18 21:48:42,663 Current Learning Rate: 0.0004429836
2025-02-18 21:48:42,664 Train Loss: 0.0003863, Val Loss: 0.0004107
2025-02-18 21:48:42,665 Epoch 628/2000
2025-02-18 21:49:25,710 Current Learning Rate: 0.0004758647
2025-02-18 21:49:25,711 Train Loss: 0.0004113, Val Loss: 0.0004110
2025-02-18 21:49:25,712 Epoch 629/2000
2025-02-18 21:50:07,686 Current Learning Rate: 0.0005098621
2025-02-18 21:50:07,686 Train Loss: 0.0003493, Val Loss: 0.0004115
2025-02-18 21:50:07,687 Epoch 630/2000
2025-02-18 21:50:50,145 Current Learning Rate: 0.0005449674
2025-02-18 21:50:50,147 Train Loss: 0.0003358, Val Loss: 0.0004107
2025-02-18 21:50:50,147 Epoch 631/2000
2025-02-18 21:51:32,875 Current Learning Rate: 0.0005811718
2025-02-18 21:51:32,876 Train Loss: 0.0003717, Val Loss: 0.0004107
2025-02-18 21:51:32,877 Epoch 632/2000
2025-02-18 21:52:15,755 Current Learning Rate: 0.0006184666
2025-02-18 21:52:15,756 Train Loss: 0.0003810, Val Loss: 0.0004112
2025-02-18 21:52:15,757 Epoch 633/2000
2025-02-18 21:52:58,791 Current Learning Rate: 0.0006568424
2025-02-18 21:52:58,792 Train Loss: 0.0003285, Val Loss: 0.0004111
2025-02-18 21:52:58,793 Epoch 634/2000
2025-02-18 21:53:41,915 Current Learning Rate: 0.0006962899
2025-02-18 21:53:41,916 Train Loss: 0.0003944, Val Loss: 0.0004116
2025-02-18 21:53:41,916 Epoch 635/2000
2025-02-18 21:54:24,033 Current Learning Rate: 0.0007367992
2025-02-18 21:54:24,034 Train Loss: 0.0003961, Val Loss: 0.0004128
2025-02-18 21:54:24,035 Epoch 636/2000
2025-02-18 21:55:06,312 Current Learning Rate: 0.0007783604
2025-02-18 21:55:06,313 Train Loss: 0.0003761, Val Loss: 0.0004128
2025-02-18 21:55:06,313 Epoch 637/2000
2025-02-18 21:55:49,323 Current Learning Rate: 0.0008209632
2025-02-18 21:55:49,324 Train Loss: 0.0003402, Val Loss: 0.0004116
2025-02-18 21:55:49,324 Epoch 638/2000
2025-02-18 21:56:32,300 Current Learning Rate: 0.0008645971
2025-02-18 21:56:32,300 Train Loss: 0.0003285, Val Loss: 0.0004131
2025-02-18 21:56:32,301 Epoch 639/2000
2025-02-18 21:57:15,206 Current Learning Rate: 0.0009092514
2025-02-18 21:57:15,206 Train Loss: 0.0005459, Val Loss: 0.0005489
2025-02-18 21:57:15,207 Epoch 640/2000
2025-02-18 21:57:58,249 Current Learning Rate: 0.0009549150
2025-02-18 21:57:58,250 Train Loss: 0.0004380, Val Loss: 0.0004273
2025-02-18 21:57:58,250 Epoch 641/2000
2025-02-18 21:58:40,376 Current Learning Rate: 0.0010015767
2025-02-18 21:58:40,376 Train Loss: 0.0003262, Val Loss: 0.0004157
2025-02-18 21:58:40,376 Epoch 642/2000
2025-02-18 21:59:22,982 Current Learning Rate: 0.0010492249
2025-02-18 21:59:22,982 Train Loss: 0.0004232, Val Loss: 0.0004367
2025-02-18 21:59:22,982 Epoch 643/2000
2025-02-18 22:00:05,451 Current Learning Rate: 0.0010978480
2025-02-18 22:00:05,452 Train Loss: 0.0004041, Val Loss: 0.0004225
2025-02-18 22:00:05,452 Epoch 644/2000
2025-02-18 22:00:48,433 Current Learning Rate: 0.0011474338
2025-02-18 22:00:48,433 Train Loss: 0.0003833, Val Loss: 0.0004136
2025-02-18 22:00:48,434 Epoch 645/2000
2025-02-18 22:01:31,413 Current Learning Rate: 0.0011979702
2025-02-18 22:01:31,413 Train Loss: 0.0003760, Val Loss: 0.0004149
2025-02-18 22:01:31,414 Epoch 646/2000
2025-02-18 22:02:13,793 Current Learning Rate: 0.0012494447
2025-02-18 22:02:13,793 Train Loss: 0.0003510, Val Loss: 0.0004119
2025-02-18 22:02:13,794 Epoch 647/2000
2025-02-18 22:02:55,781 Current Learning Rate: 0.0013018445
2025-02-18 22:02:55,782 Train Loss: 0.0003317, Val Loss: 0.0004520
2025-02-18 22:02:55,782 Epoch 648/2000
2025-02-18 22:03:38,192 Current Learning Rate: 0.0013551569
2025-02-18 22:03:38,193 Train Loss: 0.0003420, Val Loss: 0.0004115
2025-02-18 22:03:38,193 Epoch 649/2000
2025-02-18 22:04:20,694 Current Learning Rate: 0.0014093685
2025-02-18 22:04:20,695 Train Loss: 0.0003548, Val Loss: 0.0004166
2025-02-18 22:04:20,695 Epoch 650/2000
2025-02-18 22:05:02,956 Current Learning Rate: 0.0014644661
2025-02-18 22:05:02,956 Train Loss: 0.0003625, Val Loss: 0.0004158
2025-02-18 22:05:02,956 Epoch 651/2000
2025-02-18 22:05:45,828 Current Learning Rate: 0.0015204360
2025-02-18 22:05:45,829 Train Loss: 0.0004189, Val Loss: 0.0004243
2025-02-18 22:05:45,830 Epoch 652/2000
2025-02-18 22:06:28,578 Current Learning Rate: 0.0015772645
2025-02-18 22:06:28,579 Train Loss: 0.0004001, Val Loss: 0.0004230
2025-02-18 22:06:28,579 Epoch 653/2000
2025-02-18 22:07:10,914 Current Learning Rate: 0.0016349374
2025-02-18 22:07:10,914 Train Loss: 0.0005663, Val Loss: 0.0004460
2025-02-18 22:07:10,915 Epoch 654/2000
2025-02-18 22:07:53,150 Current Learning Rate: 0.0016934407
2025-02-18 22:07:53,151 Train Loss: 0.0004263, Val Loss: 0.0004317
2025-02-18 22:07:53,151 Epoch 655/2000
2025-02-18 22:08:35,964 Current Learning Rate: 0.0017527598
2025-02-18 22:08:35,964 Train Loss: 0.0003662, Val Loss: 0.0004192
2025-02-18 22:08:35,965 Epoch 656/2000
2025-02-18 22:09:18,179 Current Learning Rate: 0.0018128801
2025-02-18 22:09:19,949 Train Loss: 0.0003390, Val Loss: 0.0004083
2025-02-18 22:09:19,950 Epoch 657/2000
2025-02-18 22:10:02,685 Current Learning Rate: 0.0018737867
2025-02-18 22:10:02,686 Train Loss: 0.0003803, Val Loss: 0.0004115
2025-02-18 22:10:02,686 Epoch 658/2000
2025-02-18 22:10:45,108 Current Learning Rate: 0.0019354647
2025-02-18 22:10:45,109 Train Loss: 0.0004103, Val Loss: 0.0004344
2025-02-18 22:10:45,109 Epoch 659/2000
2025-02-18 22:11:27,724 Current Learning Rate: 0.0019978989
2025-02-18 22:11:27,725 Train Loss: 0.0005296, Val Loss: 0.0004354
2025-02-18 22:11:27,725 Epoch 660/2000
2025-02-18 22:12:10,694 Current Learning Rate: 0.0020610737
2025-02-18 22:12:10,694 Train Loss: 0.0003503, Val Loss: 0.0004168
2025-02-18 22:12:10,695 Epoch 661/2000
2025-02-18 22:12:53,261 Current Learning Rate: 0.0021249737
2025-02-18 22:12:53,262 Train Loss: 0.0004559, Val Loss: 0.0004206
2025-02-18 22:12:53,262 Epoch 662/2000
2025-02-18 22:13:34,886 Current Learning Rate: 0.0021895831
2025-02-18 22:13:34,886 Train Loss: 0.0004105, Val Loss: 0.0004178
2025-02-18 22:13:34,887 Epoch 663/2000
2025-02-18 22:14:18,021 Current Learning Rate: 0.0022548859
2025-02-18 22:14:18,021 Train Loss: 0.0004185, Val Loss: 0.0004308
2025-02-18 22:14:18,022 Epoch 664/2000
2025-02-18 22:15:00,950 Current Learning Rate: 0.0023208660
2025-02-18 22:15:00,951 Train Loss: 0.0003724, Val Loss: 0.0004262
2025-02-18 22:15:00,951 Epoch 665/2000
2025-02-18 22:15:42,850 Current Learning Rate: 0.0023875072
2025-02-18 22:15:42,850 Train Loss: 0.0003920, Val Loss: 0.0004233
2025-02-18 22:15:42,850 Epoch 666/2000
2025-02-18 22:16:25,801 Current Learning Rate: 0.0024547929
2025-02-18 22:16:25,801 Train Loss: 0.0003366, Val Loss: 0.0004418
2025-02-18 22:16:25,802 Epoch 667/2000
2025-02-18 22:17:07,886 Current Learning Rate: 0.0025227067
2025-02-18 22:17:07,886 Train Loss: 0.0006202, Val Loss: 0.0005926
2025-02-18 22:17:07,887 Epoch 668/2000
2025-02-18 22:17:50,741 Current Learning Rate: 0.0025912316
2025-02-18 22:17:50,746 Train Loss: 0.0006037, Val Loss: 0.0007330
2025-02-18 22:17:50,747 Epoch 669/2000
2025-02-18 22:18:33,194 Current Learning Rate: 0.0026603509
2025-02-18 22:18:33,194 Train Loss: 0.0006445, Val Loss: 0.0005230
2025-02-18 22:18:33,195 Epoch 670/2000
2025-02-18 22:19:15,503 Current Learning Rate: 0.0027300475
2025-02-18 22:19:15,503 Train Loss: 0.0004145, Val Loss: 0.0004489
2025-02-18 22:19:15,503 Epoch 671/2000
2025-02-18 22:19:58,665 Current Learning Rate: 0.0028003042
2025-02-18 22:19:58,667 Train Loss: 0.0004780, Val Loss: 0.0004671
2025-02-18 22:19:58,668 Epoch 672/2000
2025-02-18 22:20:41,103 Current Learning Rate: 0.0028711035
2025-02-18 22:20:41,104 Train Loss: 0.0004208, Val Loss: 0.0004300
2025-02-18 22:20:41,104 Epoch 673/2000
2025-02-18 22:21:23,732 Current Learning Rate: 0.0029424282
2025-02-18 22:21:23,733 Train Loss: 0.0003734, Val Loss: 0.0004165
2025-02-18 22:21:23,733 Epoch 674/2000
2025-02-18 22:22:06,577 Current Learning Rate: 0.0030142605
2025-02-18 22:22:06,578 Train Loss: 0.0003577, Val Loss: 0.0004265
2025-02-18 22:22:06,578 Epoch 675/2000
2025-02-18 22:22:50,092 Current Learning Rate: 0.0030865828
2025-02-18 22:22:50,093 Train Loss: 0.0004445, Val Loss: 0.0004348
2025-02-18 22:22:50,093 Epoch 676/2000
2025-02-18 22:23:33,077 Current Learning Rate: 0.0031593772
2025-02-18 22:23:33,077 Train Loss: 0.0003811, Val Loss: 0.0004417
2025-02-18 22:23:33,077 Epoch 677/2000
2025-02-18 22:24:15,946 Current Learning Rate: 0.0032326258
2025-02-18 22:24:15,946 Train Loss: 0.0003253, Val Loss: 0.0004101
2025-02-18 22:24:15,957 Epoch 678/2000
2025-02-18 22:24:58,532 Current Learning Rate: 0.0033063104
2025-02-18 22:24:58,533 Train Loss: 0.0003587, Val Loss: 0.0004156
2025-02-18 22:24:58,533 Epoch 679/2000
2025-02-18 22:25:41,869 Current Learning Rate: 0.0033804129
2025-02-18 22:25:41,870 Train Loss: 0.0003160, Val Loss: 0.0004124
2025-02-18 22:25:41,870 Epoch 680/2000
2025-02-18 22:26:25,159 Current Learning Rate: 0.0034549150
2025-02-18 22:26:25,160 Train Loss: 0.0003565, Val Loss: 0.0005271
2025-02-18 22:26:25,160 Epoch 681/2000
2025-02-18 22:27:08,665 Current Learning Rate: 0.0035297984
2025-02-18 22:27:08,666 Train Loss: 0.0004231, Val Loss: 0.0004346
2025-02-18 22:27:08,666 Epoch 682/2000
2025-02-18 22:27:52,108 Current Learning Rate: 0.0036050445
2025-02-18 22:27:52,108 Train Loss: 0.0005557, Val Loss: 0.0006193
2025-02-18 22:27:52,109 Epoch 683/2000
2025-02-18 22:28:35,237 Current Learning Rate: 0.0036806348
2025-02-18 22:28:35,238 Train Loss: 0.0004185, Val Loss: 0.0005024
2025-02-18 22:28:35,238 Epoch 684/2000
2025-02-18 22:29:18,652 Current Learning Rate: 0.0037565506
2025-02-18 22:29:18,653 Train Loss: 0.0005002, Val Loss: 0.0005074
2025-02-18 22:29:18,656 Epoch 685/2000
2025-02-18 22:30:01,012 Current Learning Rate: 0.0038327732
2025-02-18 22:30:01,013 Train Loss: 0.0004067, Val Loss: 0.0005069
2025-02-18 22:30:01,013 Epoch 686/2000
2025-02-18 22:30:43,172 Current Learning Rate: 0.0039092838
2025-02-18 22:30:43,173 Train Loss: 0.0005250, Val Loss: 0.0005281
2025-02-18 22:30:43,173 Epoch 687/2000
2025-02-18 22:31:26,506 Current Learning Rate: 0.0039860635
2025-02-18 22:31:26,507 Train Loss: 0.0004353, Val Loss: 0.0004897
2025-02-18 22:31:26,507 Epoch 688/2000
2025-02-18 22:32:09,334 Current Learning Rate: 0.0040630934
2025-02-18 22:32:09,335 Train Loss: 0.0004570, Val Loss: 0.0004984
2025-02-18 22:32:09,335 Epoch 689/2000
2025-02-18 22:32:52,203 Current Learning Rate: 0.0041403545
2025-02-18 22:32:52,203 Train Loss: 0.0004216, Val Loss: 0.0004410
2025-02-18 22:32:52,203 Epoch 690/2000
2025-02-18 22:33:34,621 Current Learning Rate: 0.0042178277
2025-02-18 22:33:34,621 Train Loss: 0.0005267, Val Loss: 0.0004886
2025-02-18 22:33:34,622 Epoch 691/2000
2025-02-18 22:34:17,374 Current Learning Rate: 0.0042954938
2025-02-18 22:34:17,374 Train Loss: 0.0004490, Val Loss: 0.0004630
2025-02-18 22:34:17,375 Epoch 692/2000
2025-02-18 22:34:59,864 Current Learning Rate: 0.0043733338
2025-02-18 22:34:59,865 Train Loss: 0.0004000, Val Loss: 0.0004601
2025-02-18 22:34:59,865 Epoch 693/2000
2025-02-18 22:35:42,650 Current Learning Rate: 0.0044513284
2025-02-18 22:35:42,651 Train Loss: 0.0004519, Val Loss: 0.0004574
2025-02-18 22:35:42,651 Epoch 694/2000
2025-02-18 22:36:25,643 Current Learning Rate: 0.0045294584
2025-02-18 22:36:25,643 Train Loss: 0.0006276, Val Loss: 0.0005118
2025-02-18 22:36:25,643 Epoch 695/2000
2025-02-18 22:37:08,079 Current Learning Rate: 0.0046077045
2025-02-18 22:37:08,079 Train Loss: 0.0004055, Val Loss: 0.0004691
2025-02-18 22:37:08,080 Epoch 696/2000
2025-02-18 22:37:50,453 Current Learning Rate: 0.0046860474
2025-02-18 22:37:50,454 Train Loss: 0.0003858, Val Loss: 0.0004559
2025-02-18 22:37:50,454 Epoch 697/2000
2025-02-18 22:38:32,864 Current Learning Rate: 0.0047644677
2025-02-18 22:38:32,865 Train Loss: 0.0004747, Val Loss: 0.0005148
2025-02-18 22:38:32,865 Epoch 698/2000
2025-02-18 22:39:15,060 Current Learning Rate: 0.0048429462
2025-02-18 22:39:15,060 Train Loss: 0.0004183, Val Loss: 0.0005884
2025-02-18 22:39:15,061 Epoch 699/2000
2025-02-18 22:39:58,202 Current Learning Rate: 0.0049214634
2025-02-18 22:39:58,203 Train Loss: 0.0006692, Val Loss: 0.0005094
2025-02-18 22:39:58,203 Epoch 700/2000
2025-02-18 22:40:41,254 Current Learning Rate: 0.0050000000
2025-02-18 22:40:41,255 Train Loss: 0.0004523, Val Loss: 0.0005430
2025-02-18 22:40:41,255 Epoch 701/2000
2025-02-18 22:41:24,365 Current Learning Rate: 0.0050785366
2025-02-18 22:41:24,366 Train Loss: 0.0004633, Val Loss: 0.0005357
2025-02-18 22:41:24,366 Epoch 702/2000
2025-02-18 22:42:06,576 Current Learning Rate: 0.0051570538
2025-02-18 22:42:06,577 Train Loss: 0.0004168, Val Loss: 0.0005046
2025-02-18 22:42:06,577 Epoch 703/2000
2025-02-18 22:42:48,466 Current Learning Rate: 0.0052355323
2025-02-18 22:42:48,466 Train Loss: 0.0004804, Val Loss: 0.0004856
2025-02-18 22:42:48,466 Epoch 704/2000
2025-02-18 22:43:31,664 Current Learning Rate: 0.0053139526
2025-02-18 22:43:31,665 Train Loss: 0.0005865, Val Loss: 0.0005379
2025-02-18 22:43:31,665 Epoch 705/2000
2025-02-18 22:44:14,184 Current Learning Rate: 0.0053922955
2025-02-18 22:44:14,184 Train Loss: 0.0004807, Val Loss: 0.0004786
2025-02-18 22:44:14,185 Epoch 706/2000
2025-02-18 22:44:56,820 Current Learning Rate: 0.0054705416
2025-02-18 22:44:56,820 Train Loss: 0.0004413, Val Loss: 0.0004840
2025-02-18 22:44:56,821 Epoch 707/2000
2025-02-18 22:45:38,664 Current Learning Rate: 0.0055486716
2025-02-18 22:45:38,665 Train Loss: 0.0006430, Val Loss: 0.0006019
2025-02-18 22:45:38,665 Epoch 708/2000
2025-02-18 22:46:21,772 Current Learning Rate: 0.0056266662
2025-02-18 22:46:21,773 Train Loss: 0.0006133, Val Loss: 0.0006036
2025-02-18 22:46:21,773 Epoch 709/2000
2025-02-18 22:47:04,724 Current Learning Rate: 0.0057045062
2025-02-18 22:47:04,724 Train Loss: 0.0005017, Val Loss: 0.0004882
2025-02-18 22:47:04,724 Epoch 710/2000
2025-02-18 22:47:46,747 Current Learning Rate: 0.0057821723
2025-02-18 22:47:46,747 Train Loss: 0.0003873, Val Loss: 0.0004441
2025-02-18 22:47:46,748 Epoch 711/2000
2025-02-18 22:48:28,782 Current Learning Rate: 0.0058596455
2025-02-18 22:48:28,783 Train Loss: 0.0003793, Val Loss: 0.0004474
2025-02-18 22:48:28,783 Epoch 712/2000
2025-02-18 22:49:11,188 Current Learning Rate: 0.0059369066
2025-02-18 22:49:11,188 Train Loss: 0.0003912, Val Loss: 0.0004489
2025-02-18 22:49:11,189 Epoch 713/2000
2025-02-18 22:49:53,250 Current Learning Rate: 0.0060139365
2025-02-18 22:49:53,250 Train Loss: 0.0004673, Val Loss: 0.0005099
2025-02-18 22:49:53,250 Epoch 714/2000
2025-02-18 22:50:35,473 Current Learning Rate: 0.0060907162
2025-02-18 22:50:35,474 Train Loss: 0.0005575, Val Loss: 0.0004955
2025-02-18 22:50:35,474 Epoch 715/2000
2025-02-18 22:51:17,685 Current Learning Rate: 0.0061672268
2025-02-18 22:51:17,686 Train Loss: 0.0008100, Val Loss: 0.0005871
2025-02-18 22:51:17,686 Epoch 716/2000
2025-02-18 22:51:59,989 Current Learning Rate: 0.0062434494
2025-02-18 22:51:59,990 Train Loss: 0.0004465, Val Loss: 0.0005548
2025-02-18 22:51:59,990 Epoch 717/2000
2025-02-18 22:52:42,512 Current Learning Rate: 0.0063193652
2025-02-18 22:52:42,513 Train Loss: 0.0004861, Val Loss: 0.0005530
2025-02-18 22:52:42,513 Epoch 718/2000
2025-02-18 22:53:25,059 Current Learning Rate: 0.0063949555
2025-02-18 22:53:25,060 Train Loss: 0.0004071, Val Loss: 0.0004818
2025-02-18 22:53:25,060 Epoch 719/2000
2025-02-18 22:54:08,231 Current Learning Rate: 0.0064702016
2025-02-18 22:54:08,231 Train Loss: 0.0004972, Val Loss: 0.0005260
2025-02-18 22:54:08,232 Epoch 720/2000
2025-02-18 22:54:50,523 Current Learning Rate: 0.0065450850
2025-02-18 22:54:50,524 Train Loss: 0.0004369, Val Loss: 0.0005225
2025-02-18 22:54:50,524 Epoch 721/2000
2025-02-18 22:55:33,354 Current Learning Rate: 0.0066195871
2025-02-18 22:55:33,354 Train Loss: 0.0004523, Val Loss: 0.0004660
2025-02-18 22:55:33,354 Epoch 722/2000
2025-02-18 22:56:15,387 Current Learning Rate: 0.0066936896
2025-02-18 22:56:15,388 Train Loss: 0.0005368, Val Loss: 0.0006312
2025-02-18 22:56:15,388 Epoch 723/2000
2025-02-18 22:56:57,996 Current Learning Rate: 0.0067673742
2025-02-18 22:56:57,997 Train Loss: 0.0004096, Val Loss: 0.0004782
2025-02-18 22:56:57,997 Epoch 724/2000
2025-02-18 22:57:41,162 Current Learning Rate: 0.0068406228
2025-02-18 22:57:41,162 Train Loss: 0.0004552, Val Loss: 0.0004694
2025-02-18 22:57:41,162 Epoch 725/2000
2025-02-18 22:58:23,917 Current Learning Rate: 0.0069134172
2025-02-18 22:58:23,918 Train Loss: 0.0005421, Val Loss: 0.0005071
2025-02-18 22:58:23,918 Epoch 726/2000
2025-02-18 22:59:06,892 Current Learning Rate: 0.0069857395
2025-02-18 22:59:06,893 Train Loss: 0.0003859, Val Loss: 0.0004395
2025-02-18 22:59:06,893 Epoch 727/2000
2025-02-18 22:59:49,767 Current Learning Rate: 0.0070575718
2025-02-18 22:59:49,767 Train Loss: 0.0004050, Val Loss: 0.0004492
2025-02-18 22:59:49,768 Epoch 728/2000
2025-02-18 23:00:32,399 Current Learning Rate: 0.0071288965
2025-02-18 23:00:32,399 Train Loss: 0.0004189, Val Loss: 0.0004836
2025-02-18 23:00:32,400 Epoch 729/2000
2025-02-18 23:01:14,952 Current Learning Rate: 0.0071996958
2025-02-18 23:01:14,953 Train Loss: 0.0003604, Val Loss: 0.0004482
2025-02-18 23:01:14,953 Epoch 730/2000
2025-02-18 23:01:58,461 Current Learning Rate: 0.0072699525
2025-02-18 23:01:58,462 Train Loss: 0.0005782, Val Loss: 0.0005466
2025-02-18 23:01:58,462 Epoch 731/2000
2025-02-18 23:02:40,915 Current Learning Rate: 0.0073396491
2025-02-18 23:02:40,915 Train Loss: 0.0006507, Val Loss: 0.0007111
2025-02-18 23:02:40,916 Epoch 732/2000
2025-02-18 23:03:23,896 Current Learning Rate: 0.0074087684
2025-02-18 23:03:23,897 Train Loss: 0.0005913, Val Loss: 0.0005599
2025-02-18 23:03:23,897 Epoch 733/2000
2025-02-18 23:04:07,824 Current Learning Rate: 0.0074772933
2025-02-18 23:04:07,825 Train Loss: 0.0004286, Val Loss: 0.0005166
2025-02-18 23:04:07,825 Epoch 734/2000
2025-02-18 23:04:50,750 Current Learning Rate: 0.0075452071
2025-02-18 23:04:50,751 Train Loss: 0.0004992, Val Loss: 0.0005094
2025-02-18 23:04:50,751 Epoch 735/2000
2025-02-18 23:05:34,489 Current Learning Rate: 0.0076124928
2025-02-18 23:05:34,490 Train Loss: 0.0004641, Val Loss: 0.0005014
2025-02-18 23:05:34,490 Epoch 736/2000
2025-02-18 23:06:17,652 Current Learning Rate: 0.0076791340
2025-02-18 23:06:17,652 Train Loss: 0.0004634, Val Loss: 0.0007762
2025-02-18 23:06:17,653 Epoch 737/2000
2025-02-18 23:07:00,949 Current Learning Rate: 0.0077451141
2025-02-18 23:07:00,950 Train Loss: 0.0005219, Val Loss: 0.0004944
2025-02-18 23:07:00,950 Epoch 738/2000
2025-02-18 23:07:44,312 Current Learning Rate: 0.0078104169
2025-02-18 23:07:44,313 Train Loss: 0.0004473, Val Loss: 0.0004976
2025-02-18 23:07:44,313 Epoch 739/2000
2025-02-18 23:08:27,326 Current Learning Rate: 0.0078750263
2025-02-18 23:08:27,327 Train Loss: 0.0006260, Val Loss: 0.0006472
2025-02-18 23:08:27,327 Epoch 740/2000
2025-02-18 23:09:10,495 Current Learning Rate: 0.0079389263
2025-02-18 23:09:10,496 Train Loss: 0.0006513, Val Loss: 0.0006764
2025-02-18 23:09:10,496 Epoch 741/2000
2025-02-18 23:09:54,309 Current Learning Rate: 0.0080021011
2025-02-18 23:09:54,309 Train Loss: 0.0005785, Val Loss: 0.0007031
2025-02-18 23:09:54,309 Epoch 742/2000
2025-02-18 23:10:37,474 Current Learning Rate: 0.0080645353
2025-02-18 23:10:37,474 Train Loss: 0.0004421, Val Loss: 0.0004960
2025-02-18 23:10:37,475 Epoch 743/2000
2025-02-18 23:11:19,944 Current Learning Rate: 0.0081262133
2025-02-18 23:11:19,944 Train Loss: 0.0005144, Val Loss: 0.0005616
2025-02-18 23:11:19,945 Epoch 744/2000
2025-02-18 23:12:02,909 Current Learning Rate: 0.0081871199
2025-02-18 23:12:02,911 Train Loss: 0.0004935, Val Loss: 0.0005162
2025-02-18 23:12:02,912 Epoch 745/2000
2025-02-18 23:12:46,786 Current Learning Rate: 0.0082472402
2025-02-18 23:12:46,786 Train Loss: 0.0003768, Val Loss: 0.0004637
2025-02-18 23:12:46,786 Epoch 746/2000
2025-02-18 23:13:29,046 Current Learning Rate: 0.0083065593
2025-02-18 23:13:29,047 Train Loss: 0.0005217, Val Loss: 0.0004631
2025-02-18 23:13:29,047 Epoch 747/2000
2025-02-18 23:14:11,847 Current Learning Rate: 0.0083650626
2025-02-18 23:14:11,848 Train Loss: 0.0005544, Val Loss: 0.0005617
2025-02-18 23:14:11,848 Epoch 748/2000
2025-02-18 23:14:56,173 Current Learning Rate: 0.0084227355
2025-02-18 23:14:56,173 Train Loss: 0.0005401, Val Loss: 0.0005333
2025-02-18 23:14:56,174 Epoch 749/2000
2025-02-18 23:15:39,348 Current Learning Rate: 0.0084795640
2025-02-18 23:15:39,348 Train Loss: 0.0003724, Val Loss: 0.0004718
2025-02-18 23:15:39,348 Epoch 750/2000
2025-02-18 23:16:22,395 Current Learning Rate: 0.0085355339
2025-02-18 23:16:22,395 Train Loss: 0.0004473, Val Loss: 0.0004963
2025-02-18 23:16:22,396 Epoch 751/2000
2025-02-18 23:17:05,527 Current Learning Rate: 0.0085906315
2025-02-18 23:17:05,527 Train Loss: 0.0005019, Val Loss: 0.0005205
2025-02-18 23:17:05,528 Epoch 752/2000
2025-02-18 23:17:48,160 Current Learning Rate: 0.0086448431
2025-02-18 23:17:48,161 Train Loss: 0.0004212, Val Loss: 0.0004955
2025-02-18 23:17:48,161 Epoch 753/2000
2025-02-18 23:18:30,793 Current Learning Rate: 0.0086981555
2025-02-18 23:18:30,794 Train Loss: 0.0005081, Val Loss: 0.0006728
2025-02-18 23:18:30,795 Epoch 754/2000
2025-02-18 23:19:13,339 Current Learning Rate: 0.0087505553
2025-02-18 23:19:13,340 Train Loss: 0.0005041, Val Loss: 0.0005740
2025-02-18 23:19:13,340 Epoch 755/2000
2025-02-18 23:19:56,175 Current Learning Rate: 0.0088020298
2025-02-18 23:19:56,176 Train Loss: 0.0004600, Val Loss: 0.0005830
2025-02-18 23:19:56,176 Epoch 756/2000
2025-02-18 23:20:39,888 Current Learning Rate: 0.0088525662
2025-02-18 23:20:39,889 Train Loss: 0.0004196, Val Loss: 0.0005640
2025-02-18 23:20:39,889 Epoch 757/2000
2025-02-18 23:21:23,231 Current Learning Rate: 0.0089021520
2025-02-18 23:21:23,232 Train Loss: 0.0004903, Val Loss: 0.0006048
2025-02-18 23:21:23,232 Epoch 758/2000
2025-02-18 23:22:05,629 Current Learning Rate: 0.0089507751
2025-02-18 23:22:05,630 Train Loss: 0.0005105, Val Loss: 0.0006871
2025-02-18 23:22:05,630 Epoch 759/2000
2025-02-18 23:22:48,135 Current Learning Rate: 0.0089984233
2025-02-18 23:22:48,135 Train Loss: 0.0005306, Val Loss: 0.0006523
2025-02-18 23:22:48,136 Epoch 760/2000
2025-02-18 23:23:30,607 Current Learning Rate: 0.0090450850
2025-02-18 23:23:30,608 Train Loss: 0.0004529, Val Loss: 0.0004818
2025-02-18 23:23:30,608 Epoch 761/2000
2025-02-18 23:24:14,134 Current Learning Rate: 0.0090907486
2025-02-18 23:24:14,135 Train Loss: 0.0006053, Val Loss: 0.0006380
2025-02-18 23:24:14,135 Epoch 762/2000
2025-02-18 23:24:57,424 Current Learning Rate: 0.0091354029
2025-02-18 23:24:57,425 Train Loss: 0.0006056, Val Loss: 0.0005981
2025-02-18 23:24:57,426 Epoch 763/2000
2025-02-18 23:25:40,598 Current Learning Rate: 0.0091790368
2025-02-18 23:25:40,598 Train Loss: 0.0005712, Val Loss: 0.0006514
2025-02-18 23:25:40,599 Epoch 764/2000
2025-02-18 23:26:23,935 Current Learning Rate: 0.0092216396
2025-02-18 23:26:23,936 Train Loss: 0.0004432, Val Loss: 0.0004766
2025-02-18 23:26:23,936 Epoch 765/2000
2025-02-18 23:27:06,852 Current Learning Rate: 0.0092632008
2025-02-18 23:27:06,852 Train Loss: 0.0005074, Val Loss: 0.0004895
2025-02-18 23:27:06,853 Epoch 766/2000
2025-02-18 23:27:50,025 Current Learning Rate: 0.0093037101
2025-02-18 23:27:50,026 Train Loss: 0.0004087, Val Loss: 0.0004661
2025-02-18 23:27:50,026 Epoch 767/2000
2025-02-18 23:28:32,965 Current Learning Rate: 0.0093431576
2025-02-18 23:28:32,965 Train Loss: 0.0005126, Val Loss: 0.0005074
2025-02-18 23:28:32,966 Epoch 768/2000
2025-02-18 23:29:16,273 Current Learning Rate: 0.0093815334
2025-02-18 23:29:16,273 Train Loss: 0.0004244, Val Loss: 0.0004861
2025-02-18 23:29:16,273 Epoch 769/2000
2025-02-18 23:29:58,700 Current Learning Rate: 0.0094188282
2025-02-18 23:29:58,701 Train Loss: 0.0004482, Val Loss: 0.0004930
2025-02-18 23:29:58,701 Epoch 770/2000
2025-02-18 23:30:41,063 Current Learning Rate: 0.0094550326
2025-02-18 23:30:41,066 Train Loss: 0.0004860, Val Loss: 0.0005334
2025-02-18 23:30:41,069 Epoch 771/2000
2025-02-18 23:31:24,412 Current Learning Rate: 0.0094901379
2025-02-18 23:31:24,413 Train Loss: 0.0004707, Val Loss: 0.0004928
2025-02-18 23:31:24,413 Epoch 772/2000
2025-02-18 23:32:07,436 Current Learning Rate: 0.0095241353
2025-02-18 23:32:07,437 Train Loss: 0.0003521, Val Loss: 0.0004809
2025-02-18 23:32:07,437 Epoch 773/2000
2025-02-18 23:32:51,213 Current Learning Rate: 0.0095570164
2025-02-18 23:32:51,214 Train Loss: 0.0004144, Val Loss: 0.0004836
2025-02-18 23:32:51,214 Epoch 774/2000
2025-02-18 23:33:33,403 Current Learning Rate: 0.0095887731
2025-02-18 23:33:33,404 Train Loss: 0.0005278, Val Loss: 0.0005324
2025-02-18 23:33:33,404 Epoch 775/2000
2025-02-18 23:34:17,112 Current Learning Rate: 0.0096193977
2025-02-18 23:34:17,112 Train Loss: 0.0005132, Val Loss: 0.0005153
2025-02-18 23:34:17,113 Epoch 776/2000
2025-02-18 23:35:00,578 Current Learning Rate: 0.0096488824
2025-02-18 23:35:00,579 Train Loss: 0.0004904, Val Loss: 0.0005072
2025-02-18 23:35:00,579 Epoch 777/2000
2025-02-18 23:35:42,936 Current Learning Rate: 0.0096772202
2025-02-18 23:35:42,936 Train Loss: 0.0003956, Val Loss: 0.0004291
2025-02-18 23:35:42,937 Epoch 778/2000
2025-02-18 23:36:25,591 Current Learning Rate: 0.0097044038
2025-02-18 23:36:25,591 Train Loss: 0.0004297, Val Loss: 0.0004614
2025-02-18 23:36:25,591 Epoch 779/2000
2025-02-18 23:37:09,017 Current Learning Rate: 0.0097304268
2025-02-18 23:37:09,018 Train Loss: 0.0004565, Val Loss: 0.0004832
2025-02-18 23:37:09,018 Epoch 780/2000
2025-02-18 23:37:51,649 Current Learning Rate: 0.0097552826
2025-02-18 23:37:51,650 Train Loss: 0.0003956, Val Loss: 0.0004412
2025-02-18 23:37:51,650 Epoch 781/2000
2025-02-18 23:38:35,230 Current Learning Rate: 0.0097789651
2025-02-18 23:38:35,230 Train Loss: 0.0003159, Val Loss: 0.0004296
2025-02-18 23:38:35,230 Epoch 782/2000
2025-02-18 23:39:18,506 Current Learning Rate: 0.0098014684
2025-02-18 23:39:18,506 Train Loss: 0.0004671, Val Loss: 0.0005191
2025-02-18 23:39:18,506 Epoch 783/2000
2025-02-18 23:40:01,677 Current Learning Rate: 0.0098227871
2025-02-18 23:40:01,677 Train Loss: 0.0005046, Val Loss: 0.0005108
2025-02-18 23:40:01,678 Epoch 784/2000
2025-02-18 23:40:44,941 Current Learning Rate: 0.0098429158
2025-02-18 23:40:44,942 Train Loss: 0.0005220, Val Loss: 0.0006367
2025-02-18 23:40:44,942 Epoch 785/2000
2025-02-18 23:41:28,435 Current Learning Rate: 0.0098618496
2025-02-18 23:41:28,435 Train Loss: 0.0005533, Val Loss: 0.0005310
2025-02-18 23:41:28,436 Epoch 786/2000
2025-02-18 23:42:11,232 Current Learning Rate: 0.0098795838
2025-02-18 23:42:11,232 Train Loss: 0.0005087, Val Loss: 0.0005000
2025-02-18 23:42:11,233 Epoch 787/2000
2025-02-18 23:42:54,325 Current Learning Rate: 0.0098961141
2025-02-18 23:42:54,327 Train Loss: 0.0004590, Val Loss: 0.0004898
2025-02-18 23:42:54,327 Epoch 788/2000
2025-02-18 23:43:37,303 Current Learning Rate: 0.0099114363
2025-02-18 23:43:37,304 Train Loss: 0.0004490, Val Loss: 0.0004844
2025-02-18 23:43:37,304 Epoch 789/2000
2025-02-18 23:44:19,846 Current Learning Rate: 0.0099255466
2025-02-18 23:44:19,846 Train Loss: 0.0004810, Val Loss: 0.0005824
2025-02-18 23:44:19,846 Epoch 790/2000
2025-02-18 23:45:01,907 Current Learning Rate: 0.0099384417
2025-02-18 23:45:01,908 Train Loss: 0.0004144, Val Loss: 0.0004847
2025-02-18 23:45:01,909 Epoch 791/2000
2025-02-18 23:45:44,868 Current Learning Rate: 0.0099501183
2025-02-18 23:45:44,868 Train Loss: 0.0004000, Val Loss: 0.0004701
2025-02-18 23:45:44,868 Epoch 792/2000
2025-02-18 23:46:27,840 Current Learning Rate: 0.0099605735
2025-02-18 23:46:27,840 Train Loss: 0.0005417, Val Loss: 0.0005281
2025-02-18 23:46:27,841 Epoch 793/2000
2025-02-18 23:47:10,712 Current Learning Rate: 0.0099698048
2025-02-18 23:47:10,713 Train Loss: 0.0005414, Val Loss: 0.0005604
2025-02-18 23:47:10,713 Epoch 794/2000
2025-02-18 23:47:53,260 Current Learning Rate: 0.0099778098
2025-02-18 23:47:53,261 Train Loss: 0.0006029, Val Loss: 0.0005738
2025-02-18 23:47:53,261 Epoch 795/2000
2025-02-18 23:48:36,277 Current Learning Rate: 0.0099845867
2025-02-18 23:48:36,277 Train Loss: 0.0004438, Val Loss: 0.0004629
2025-02-18 23:48:36,277 Epoch 796/2000
2025-02-18 23:49:19,161 Current Learning Rate: 0.0099901336
2025-02-18 23:49:19,161 Train Loss: 0.0004035, Val Loss: 0.0004726
2025-02-18 23:49:19,161 Epoch 797/2000
2025-02-18 23:50:02,197 Current Learning Rate: 0.0099944494
2025-02-18 23:50:02,198 Train Loss: 0.0004470, Val Loss: 0.0005083
2025-02-18 23:50:02,198 Epoch 798/2000
2025-02-18 23:50:45,316 Current Learning Rate: 0.0099975328
2025-02-18 23:50:45,316 Train Loss: 0.0003833, Val Loss: 0.0004289
2025-02-18 23:50:45,317 Epoch 799/2000
2025-02-18 23:51:27,681 Current Learning Rate: 0.0099993832
2025-02-18 23:51:27,681 Train Loss: 0.0003646, Val Loss: 0.0004805
2025-02-18 23:51:27,682 Epoch 800/2000
2025-02-18 23:52:09,979 Current Learning Rate: 0.0100000000
2025-02-18 23:52:09,979 Train Loss: 0.0003941, Val Loss: 0.0004538
2025-02-18 23:52:09,980 Epoch 801/2000
2025-02-18 23:52:52,248 Current Learning Rate: 0.0099993832
2025-02-18 23:52:52,249 Train Loss: 0.0004818, Val Loss: 0.0004854
2025-02-18 23:52:52,249 Epoch 802/2000
2025-02-18 23:53:34,736 Current Learning Rate: 0.0099975328
2025-02-18 23:53:34,737 Train Loss: 0.0004143, Val Loss: 0.0004645
2025-02-18 23:53:34,737 Epoch 803/2000
2025-02-18 23:54:16,794 Current Learning Rate: 0.0099944494
2025-02-18 23:54:16,794 Train Loss: 0.0004518, Val Loss: 0.0004697
2025-02-18 23:54:16,795 Epoch 804/2000
2025-02-18 23:54:58,809 Current Learning Rate: 0.0099901336
2025-02-18 23:54:58,810 Train Loss: 0.0003482, Val Loss: 0.0004384
2025-02-18 23:54:58,810 Epoch 805/2000
2025-02-18 23:55:42,062 Current Learning Rate: 0.0099845867
2025-02-18 23:55:42,062 Train Loss: 0.0004466, Val Loss: 0.0005324
2025-02-18 23:55:42,063 Epoch 806/2000
2025-02-18 23:56:24,334 Current Learning Rate: 0.0099778098
2025-02-18 23:56:24,334 Train Loss: 0.0005096, Val Loss: 0.0004557
2025-02-18 23:56:24,335 Epoch 807/2000
2025-02-18 23:57:07,299 Current Learning Rate: 0.0099698048
2025-02-18 23:57:07,299 Train Loss: 0.0004716, Val Loss: 0.0004675
2025-02-18 23:57:07,300 Epoch 808/2000
2025-02-18 23:57:49,304 Current Learning Rate: 0.0099605735
2025-02-18 23:57:49,305 Train Loss: 0.0004419, Val Loss: 0.0004450
2025-02-18 23:57:49,305 Epoch 809/2000
2025-02-18 23:58:32,643 Current Learning Rate: 0.0099501183
2025-02-18 23:58:32,643 Train Loss: 0.0003360, Val Loss: 0.0004327
2025-02-18 23:58:32,644 Epoch 810/2000
2025-02-18 23:59:14,533 Current Learning Rate: 0.0099384417
2025-02-18 23:59:14,534 Train Loss: 0.0004934, Val Loss: 0.0004444
2025-02-18 23:59:14,534 Epoch 811/2000
2025-02-18 23:59:57,529 Current Learning Rate: 0.0099255466
2025-02-18 23:59:57,530 Train Loss: 0.0003976, Val Loss: 0.0004333
2025-02-18 23:59:57,530 Epoch 812/2000
2025-02-19 00:00:40,415 Current Learning Rate: 0.0099114363
2025-02-19 00:00:40,415 Train Loss: 0.0004216, Val Loss: 0.0004356
2025-02-19 00:00:40,416 Epoch 813/2000
2025-02-19 00:01:23,349 Current Learning Rate: 0.0098961141
2025-02-19 00:01:24,706 Train Loss: 0.0004006, Val Loss: 0.0004066
2025-02-19 00:01:24,706 Epoch 814/2000
2025-02-19 00:02:07,078 Current Learning Rate: 0.0098795838
2025-02-19 00:02:07,080 Train Loss: 0.0004658, Val Loss: 0.0004701
2025-02-19 00:02:07,080 Epoch 815/2000
2025-02-19 00:02:49,507 Current Learning Rate: 0.0098618496
2025-02-19 00:02:49,507 Train Loss: 0.0005075, Val Loss: 0.0005421
2025-02-19 00:02:49,507 Epoch 816/2000
2025-02-19 00:03:31,989 Current Learning Rate: 0.0098429158
2025-02-19 00:03:31,990 Train Loss: 0.0004353, Val Loss: 0.0004457
2025-02-19 00:03:31,990 Epoch 817/2000
2025-02-19 00:04:13,808 Current Learning Rate: 0.0098227871
2025-02-19 00:04:13,809 Train Loss: 0.0006612, Val Loss: 0.0006060
2025-02-19 00:04:13,809 Epoch 818/2000
2025-02-19 00:04:55,928 Current Learning Rate: 0.0098014684
2025-02-19 00:04:55,929 Train Loss: 0.0004894, Val Loss: 0.0005182
2025-02-19 00:04:55,929 Epoch 819/2000
2025-02-19 00:05:38,617 Current Learning Rate: 0.0097789651
2025-02-19 00:05:38,617 Train Loss: 0.0004411, Val Loss: 0.0004686
2025-02-19 00:05:38,618 Epoch 820/2000
2025-02-19 00:06:21,098 Current Learning Rate: 0.0097552826
2025-02-19 00:06:21,099 Train Loss: 0.0003869, Val Loss: 0.0004599
2025-02-19 00:06:21,099 Epoch 821/2000
2025-02-19 00:07:03,606 Current Learning Rate: 0.0097304268
2025-02-19 00:07:03,606 Train Loss: 0.0006094, Val Loss: 0.0005816
2025-02-19 00:07:03,607 Epoch 822/2000
2025-02-19 00:07:46,334 Current Learning Rate: 0.0097044038
2025-02-19 00:07:46,334 Train Loss: 0.0004938, Val Loss: 0.0004962
2025-02-19 00:07:46,335 Epoch 823/2000
2025-02-19 00:08:28,719 Current Learning Rate: 0.0096772202
2025-02-19 00:08:28,720 Train Loss: 0.0005204, Val Loss: 0.0005168
2025-02-19 00:08:28,720 Epoch 824/2000
2025-02-19 00:09:11,194 Current Learning Rate: 0.0096488824
2025-02-19 00:09:11,195 Train Loss: 0.0003909, Val Loss: 0.0005464
2025-02-19 00:09:11,195 Epoch 825/2000
2025-02-19 00:09:54,086 Current Learning Rate: 0.0096193977
2025-02-19 00:09:54,086 Train Loss: 0.0005129, Val Loss: 0.0004922
2025-02-19 00:09:54,087 Epoch 826/2000
2025-02-19 00:10:36,022 Current Learning Rate: 0.0095887731
2025-02-19 00:10:36,022 Train Loss: 0.0003842, Val Loss: 0.0004128
2025-02-19 00:10:36,022 Epoch 827/2000
2025-02-19 00:11:19,500 Current Learning Rate: 0.0095570164
2025-02-19 00:11:19,501 Train Loss: 0.0004824, Val Loss: 0.0004583
2025-02-19 00:11:19,501 Epoch 828/2000
2025-02-19 00:12:01,979 Current Learning Rate: 0.0095241353
2025-02-19 00:12:01,979 Train Loss: 0.0005277, Val Loss: 0.0004502
2025-02-19 00:12:01,979 Epoch 829/2000
2025-02-19 00:12:44,029 Current Learning Rate: 0.0094901379
2025-02-19 00:12:44,029 Train Loss: 0.0004591, Val Loss: 0.0004959
2025-02-19 00:12:44,030 Epoch 830/2000
2025-02-19 00:13:26,724 Current Learning Rate: 0.0094550326
2025-02-19 00:13:27,919 Train Loss: 0.0003378, Val Loss: 0.0003812
2025-02-19 00:13:27,919 Epoch 831/2000
2025-02-19 00:14:09,872 Current Learning Rate: 0.0094188282
2025-02-19 00:14:09,873 Train Loss: 0.0005815, Val Loss: 0.0006134
2025-02-19 00:14:09,874 Epoch 832/2000
2025-02-19 00:14:52,944 Current Learning Rate: 0.0093815334
2025-02-19 00:14:52,945 Train Loss: 0.0004553, Val Loss: 0.0004320
2025-02-19 00:14:52,945 Epoch 833/2000
2025-02-19 00:15:35,689 Current Learning Rate: 0.0093431576
2025-02-19 00:15:35,689 Train Loss: 0.0005026, Val Loss: 0.0004189
2025-02-19 00:15:35,689 Epoch 834/2000
2025-02-19 00:16:18,167 Current Learning Rate: 0.0093037101
2025-02-19 00:16:18,168 Train Loss: 0.0003888, Val Loss: 0.0003929
2025-02-19 00:16:18,168 Epoch 835/2000
2025-02-19 00:17:00,811 Current Learning Rate: 0.0092632008
2025-02-19 00:17:00,812 Train Loss: 0.0003395, Val Loss: 0.0003839
2025-02-19 00:17:00,812 Epoch 836/2000
2025-02-19 00:17:43,683 Current Learning Rate: 0.0092216396
2025-02-19 00:17:45,588 Train Loss: 0.0003507, Val Loss: 0.0003775
2025-02-19 00:17:45,589 Epoch 837/2000
2025-02-19 00:18:28,098 Current Learning Rate: 0.0091790368
2025-02-19 00:18:28,099 Train Loss: 0.0003330, Val Loss: 0.0003904
2025-02-19 00:18:28,099 Epoch 838/2000
2025-02-19 00:19:10,414 Current Learning Rate: 0.0091354029
2025-02-19 00:19:10,415 Train Loss: 0.0003368, Val Loss: 0.0003842
2025-02-19 00:19:10,415 Epoch 839/2000
2025-02-19 00:19:53,425 Current Learning Rate: 0.0090907486
2025-02-19 00:19:53,425 Train Loss: 0.0003162, Val Loss: 0.0003831
2025-02-19 00:19:53,425 Epoch 840/2000
2025-02-19 00:20:36,359 Current Learning Rate: 0.0090450850
2025-02-19 00:20:38,002 Train Loss: 0.0003632, Val Loss: 0.0003722
2025-02-19 00:20:38,002 Epoch 841/2000
2025-02-19 00:21:20,095 Current Learning Rate: 0.0089984233
2025-02-19 00:21:20,096 Train Loss: 0.0003143, Val Loss: 0.0003877
2025-02-19 00:21:20,096 Epoch 842/2000
2025-02-19 00:22:02,877 Current Learning Rate: 0.0089507751
2025-02-19 00:22:02,877 Train Loss: 0.0003477, Val Loss: 0.0003846
2025-02-19 00:22:02,878 Epoch 843/2000
2025-02-19 00:22:45,545 Current Learning Rate: 0.0089021520
2025-02-19 00:22:45,546 Train Loss: 0.0003538, Val Loss: 0.0003870
2025-02-19 00:22:45,546 Epoch 844/2000
2025-02-19 00:23:28,618 Current Learning Rate: 0.0088525662
2025-02-19 00:23:28,618 Train Loss: 0.0003649, Val Loss: 0.0004155
2025-02-19 00:23:28,619 Epoch 845/2000
2025-02-19 00:24:11,706 Current Learning Rate: 0.0088020298
2025-02-19 00:24:11,706 Train Loss: 0.0003234, Val Loss: 0.0004249
2025-02-19 00:24:11,706 Epoch 846/2000
2025-02-19 00:24:54,963 Current Learning Rate: 0.0087505553
2025-02-19 00:24:54,964 Train Loss: 0.0002978, Val Loss: 0.0003928
2025-02-19 00:24:54,964 Epoch 847/2000
2025-02-19 00:25:38,005 Current Learning Rate: 0.0086981555
2025-02-19 00:25:38,005 Train Loss: 0.0004270, Val Loss: 0.0004308
2025-02-19 00:25:38,005 Epoch 848/2000
2025-02-19 00:26:20,458 Current Learning Rate: 0.0086448431
2025-02-19 00:26:21,754 Train Loss: 0.0003397, Val Loss: 0.0003720
2025-02-19 00:26:21,754 Epoch 849/2000
2025-02-19 00:27:03,151 Current Learning Rate: 0.0085906315
2025-02-19 00:27:03,152 Train Loss: 0.0004277, Val Loss: 0.0004484
2025-02-19 00:27:03,152 Epoch 850/2000
2025-02-19 00:27:45,856 Current Learning Rate: 0.0085355339
2025-02-19 00:27:45,856 Train Loss: 0.0004994, Val Loss: 0.0004902
2025-02-19 00:27:45,857 Epoch 851/2000
2025-02-19 00:28:28,914 Current Learning Rate: 0.0084795640
2025-02-19 00:28:28,915 Train Loss: 0.0004288, Val Loss: 0.0004524
2025-02-19 00:28:28,915 Epoch 852/2000
2025-02-19 00:29:12,121 Current Learning Rate: 0.0084227355
2025-02-19 00:29:12,122 Train Loss: 0.0003680, Val Loss: 0.0003966
2025-02-19 00:29:12,122 Epoch 853/2000
2025-02-19 00:29:54,602 Current Learning Rate: 0.0083650626
2025-02-19 00:29:54,603 Train Loss: 0.0003345, Val Loss: 0.0003801
2025-02-19 00:29:54,603 Epoch 854/2000
2025-02-19 00:30:37,819 Current Learning Rate: 0.0083065593
2025-02-19 00:30:39,411 Train Loss: 0.0002856, Val Loss: 0.0003561
2025-02-19 00:30:39,413 Epoch 855/2000
2025-02-19 00:31:22,612 Current Learning Rate: 0.0082472402
2025-02-19 00:31:22,613 Train Loss: 0.0003230, Val Loss: 0.0003753
2025-02-19 00:31:22,613 Epoch 856/2000
2025-02-19 00:32:04,843 Current Learning Rate: 0.0081871199
2025-02-19 00:32:04,843 Train Loss: 0.0003978, Val Loss: 0.0003806
2025-02-19 00:32:04,843 Epoch 857/2000
2025-02-19 00:32:48,608 Current Learning Rate: 0.0081262133
2025-02-19 00:32:48,609 Train Loss: 0.0003266, Val Loss: 0.0003707
2025-02-19 00:32:48,609 Epoch 858/2000
2025-02-19 00:33:31,050 Current Learning Rate: 0.0080645353
2025-02-19 00:33:31,051 Train Loss: 0.0003065, Val Loss: 0.0003960
2025-02-19 00:33:31,051 Epoch 859/2000
2025-02-19 00:34:13,778 Current Learning Rate: 0.0080021011
2025-02-19 00:34:13,779 Train Loss: 0.0003886, Val Loss: 0.0003809
2025-02-19 00:34:13,779 Epoch 860/2000
2025-02-19 00:34:56,972 Current Learning Rate: 0.0079389263
2025-02-19 00:34:56,973 Train Loss: 0.0003327, Val Loss: 0.0003590
2025-02-19 00:34:56,974 Epoch 861/2000
2025-02-19 00:35:40,335 Current Learning Rate: 0.0078750263
2025-02-19 00:35:41,696 Train Loss: 0.0002592, Val Loss: 0.0003280
2025-02-19 00:35:41,696 Epoch 862/2000
2025-02-19 00:36:24,817 Current Learning Rate: 0.0078104169
2025-02-19 00:36:24,818 Train Loss: 0.0002728, Val Loss: 0.0003468
2025-02-19 00:36:24,818 Epoch 863/2000
2025-02-19 00:37:07,767 Current Learning Rate: 0.0077451141
2025-02-19 00:37:07,767 Train Loss: 0.0002990, Val Loss: 0.0003526
2025-02-19 00:37:07,768 Epoch 864/2000
2025-02-19 00:37:50,539 Current Learning Rate: 0.0076791340
2025-02-19 00:37:50,541 Train Loss: 0.0003495, Val Loss: 0.0003923
2025-02-19 00:37:50,545 Epoch 865/2000
2025-02-19 00:38:33,115 Current Learning Rate: 0.0076124928
2025-02-19 00:38:33,116 Train Loss: 0.0003653, Val Loss: 0.0003805
2025-02-19 00:38:33,116 Epoch 866/2000
2025-02-19 00:39:15,666 Current Learning Rate: 0.0075452071
2025-02-19 00:39:15,666 Train Loss: 0.0003262, Val Loss: 0.0003504
2025-02-19 00:39:15,666 Epoch 867/2000
2025-02-19 00:39:58,385 Current Learning Rate: 0.0074772933
2025-02-19 00:39:58,386 Train Loss: 0.0002878, Val Loss: 0.0003503
2025-02-19 00:39:58,386 Epoch 868/2000
2025-02-19 00:40:41,309 Current Learning Rate: 0.0074087684
2025-02-19 00:40:41,310 Train Loss: 0.0003398, Val Loss: 0.0003519
2025-02-19 00:40:41,310 Epoch 869/2000
2025-02-19 00:41:23,184 Current Learning Rate: 0.0073396491
2025-02-19 00:41:23,185 Train Loss: 0.0002796, Val Loss: 0.0003315
2025-02-19 00:41:23,185 Epoch 870/2000
2025-02-19 00:42:06,080 Current Learning Rate: 0.0072699525
2025-02-19 00:42:06,081 Train Loss: 0.0002905, Val Loss: 0.0003289
2025-02-19 00:42:06,081 Epoch 871/2000
2025-02-19 00:42:48,917 Current Learning Rate: 0.0071996958
2025-02-19 00:42:50,654 Train Loss: 0.0002498, Val Loss: 0.0003238
2025-02-19 00:42:50,654 Epoch 872/2000
2025-02-19 00:43:33,487 Current Learning Rate: 0.0071288965
2025-02-19 00:43:33,488 Train Loss: 0.0002763, Val Loss: 0.0003293
2025-02-19 00:43:33,488 Epoch 873/2000
2025-02-19 00:44:16,269 Current Learning Rate: 0.0070575718
2025-02-19 00:44:17,893 Train Loss: 0.0002803, Val Loss: 0.0003193
2025-02-19 00:44:17,893 Epoch 874/2000
2025-02-19 00:45:00,536 Current Learning Rate: 0.0069857395
2025-02-19 00:45:00,537 Train Loss: 0.0002881, Val Loss: 0.0003243
2025-02-19 00:45:00,537 Epoch 875/2000
2025-02-19 00:45:43,388 Current Learning Rate: 0.0069134172
2025-02-19 00:45:43,389 Train Loss: 0.0004537, Val Loss: 0.0003772
2025-02-19 00:45:43,389 Epoch 876/2000
2025-02-19 00:46:26,162 Current Learning Rate: 0.0068406228
2025-02-19 00:46:26,162 Train Loss: 0.0003113, Val Loss: 0.0003422
2025-02-19 00:46:26,162 Epoch 877/2000
2025-02-19 00:47:08,931 Current Learning Rate: 0.0067673742
2025-02-19 00:47:08,932 Train Loss: 0.0003074, Val Loss: 0.0003595
2025-02-19 00:47:08,932 Epoch 878/2000
2025-02-19 00:47:50,979 Current Learning Rate: 0.0066936896
2025-02-19 00:47:50,979 Train Loss: 0.0003054, Val Loss: 0.0003442
2025-02-19 00:47:50,980 Epoch 879/2000
2025-02-19 00:48:33,647 Current Learning Rate: 0.0066195871
2025-02-19 00:48:33,648 Train Loss: 0.0003647, Val Loss: 0.0004031
2025-02-19 00:48:33,648 Epoch 880/2000
2025-02-19 00:49:16,468 Current Learning Rate: 0.0065450850
2025-02-19 00:49:16,469 Train Loss: 0.0003204, Val Loss: 0.0003457
2025-02-19 00:49:16,469 Epoch 881/2000
2025-02-19 00:49:59,400 Current Learning Rate: 0.0064702016
2025-02-19 00:49:59,401 Train Loss: 0.0002452, Val Loss: 0.0003482
2025-02-19 00:49:59,401 Epoch 882/2000
2025-02-19 00:50:42,485 Current Learning Rate: 0.0063949555
2025-02-19 00:50:42,486 Train Loss: 0.0002904, Val Loss: 0.0003728
2025-02-19 00:50:42,486 Epoch 883/2000
2025-02-19 00:51:24,899 Current Learning Rate: 0.0063193652
2025-02-19 00:51:24,899 Train Loss: 0.0003210, Val Loss: 0.0004662
2025-02-19 00:51:24,899 Epoch 884/2000
2025-02-19 00:52:07,366 Current Learning Rate: 0.0062434494
2025-02-19 00:52:07,367 Train Loss: 0.0003640, Val Loss: 0.0003680
2025-02-19 00:52:07,367 Epoch 885/2000
2025-02-19 00:52:49,836 Current Learning Rate: 0.0061672268
2025-02-19 00:52:49,837 Train Loss: 0.0003595, Val Loss: 0.0003551
2025-02-19 00:52:49,844 Epoch 886/2000
2025-02-19 00:53:32,551 Current Learning Rate: 0.0060907162
2025-02-19 00:53:32,551 Train Loss: 0.0003183, Val Loss: 0.0003223
2025-02-19 00:53:32,551 Epoch 887/2000
2025-02-19 00:54:14,139 Current Learning Rate: 0.0060139365
2025-02-19 00:54:14,139 Train Loss: 0.0002886, Val Loss: 0.0003399
2025-02-19 00:54:14,139 Epoch 888/2000
2025-02-19 00:54:56,563 Current Learning Rate: 0.0059369066
2025-02-19 00:54:56,563 Train Loss: 0.0003013, Val Loss: 0.0003390
2025-02-19 00:54:56,564 Epoch 889/2000
2025-02-19 00:55:38,941 Current Learning Rate: 0.0058596455
2025-02-19 00:55:38,942 Train Loss: 0.0003425, Val Loss: 0.0003523
2025-02-19 00:55:38,942 Epoch 890/2000
2025-02-19 00:56:21,674 Current Learning Rate: 0.0057821723
2025-02-19 00:56:21,674 Train Loss: 0.0002476, Val Loss: 0.0003302
2025-02-19 00:56:21,674 Epoch 891/2000
2025-02-19 00:57:04,231 Current Learning Rate: 0.0057045062
2025-02-19 00:57:04,232 Train Loss: 0.0002801, Val Loss: 0.0003401
2025-02-19 00:57:04,232 Epoch 892/2000
2025-02-19 00:57:47,286 Current Learning Rate: 0.0056266662
2025-02-19 00:57:47,287 Train Loss: 0.0002960, Val Loss: 0.0003337
2025-02-19 00:57:47,287 Epoch 893/2000
2025-02-19 00:58:29,800 Current Learning Rate: 0.0055486716
2025-02-19 00:58:30,929 Train Loss: 0.0002226, Val Loss: 0.0003179
2025-02-19 00:58:30,929 Epoch 894/2000
2025-02-19 00:59:12,911 Current Learning Rate: 0.0054705416
2025-02-19 00:59:12,913 Train Loss: 0.0003057, Val Loss: 0.0003780
2025-02-19 00:59:12,913 Epoch 895/2000
2025-02-19 00:59:56,134 Current Learning Rate: 0.0053922955
2025-02-19 00:59:56,135 Train Loss: 0.0002994, Val Loss: 0.0003461
2025-02-19 00:59:56,135 Epoch 896/2000
2025-02-19 01:00:38,633 Current Learning Rate: 0.0053139526
2025-02-19 01:00:38,634 Train Loss: 0.0002500, Val Loss: 0.0003306
2025-02-19 01:00:38,634 Epoch 897/2000
2025-02-19 01:01:21,482 Current Learning Rate: 0.0052355323
2025-02-19 01:01:21,482 Train Loss: 0.0002808, Val Loss: 0.0003420
2025-02-19 01:01:21,482 Epoch 898/2000
2025-02-19 01:02:03,659 Current Learning Rate: 0.0051570538
2025-02-19 01:02:03,660 Train Loss: 0.0002643, Val Loss: 0.0003227
2025-02-19 01:02:03,660 Epoch 899/2000
2025-02-19 01:02:46,788 Current Learning Rate: 0.0050785366
2025-02-19 01:02:46,789 Train Loss: 0.0003070, Val Loss: 0.0003327
2025-02-19 01:02:46,789 Epoch 900/2000
2025-02-19 01:03:28,822 Current Learning Rate: 0.0050000000
2025-02-19 01:03:30,014 Train Loss: 0.0003231, Val Loss: 0.0003152
2025-02-19 01:03:30,014 Epoch 901/2000
2025-02-19 01:04:11,404 Current Learning Rate: 0.0049214634
2025-02-19 01:04:12,762 Train Loss: 0.0002909, Val Loss: 0.0003041
2025-02-19 01:04:12,762 Epoch 902/2000
2025-02-19 01:04:54,000 Current Learning Rate: 0.0048429462
2025-02-19 01:04:54,000 Train Loss: 0.0002575, Val Loss: 0.0003045
2025-02-19 01:04:54,001 Epoch 903/2000
2025-02-19 01:05:37,272 Current Learning Rate: 0.0047644677
2025-02-19 01:05:39,050 Train Loss: 0.0002042, Val Loss: 0.0002983
2025-02-19 01:05:39,051 Epoch 904/2000
2025-02-19 01:06:21,563 Current Learning Rate: 0.0046860474
2025-02-19 01:06:21,564 Train Loss: 0.0002590, Val Loss: 0.0002988
2025-02-19 01:06:21,564 Epoch 905/2000
2025-02-19 01:07:04,546 Current Learning Rate: 0.0046077045
2025-02-19 01:07:05,982 Train Loss: 0.0002434, Val Loss: 0.0002903
2025-02-19 01:07:05,982 Epoch 906/2000
2025-02-19 01:07:48,818 Current Learning Rate: 0.0045294584
2025-02-19 01:07:49,989 Train Loss: 0.0002208, Val Loss: 0.0002861
2025-02-19 01:07:49,989 Epoch 907/2000
2025-02-19 01:08:32,230 Current Learning Rate: 0.0044513284
2025-02-19 01:08:32,231 Train Loss: 0.0002553, Val Loss: 0.0002958
2025-02-19 01:08:32,231 Epoch 908/2000
2025-02-19 01:09:14,470 Current Learning Rate: 0.0043733338
2025-02-19 01:09:14,471 Train Loss: 0.0002997, Val Loss: 0.0003040
2025-02-19 01:09:14,471 Epoch 909/2000
2025-02-19 01:09:57,164 Current Learning Rate: 0.0042954938
2025-02-19 01:09:57,165 Train Loss: 0.0002956, Val Loss: 0.0003092
2025-02-19 01:09:57,165 Epoch 910/2000
2025-02-19 01:10:40,190 Current Learning Rate: 0.0042178277
2025-02-19 01:10:40,191 Train Loss: 0.0002455, Val Loss: 0.0002910
2025-02-19 01:10:40,191 Epoch 911/2000
2025-02-19 01:11:23,129 Current Learning Rate: 0.0041403545
2025-02-19 01:11:23,129 Train Loss: 0.0002776, Val Loss: 0.0002980
2025-02-19 01:11:23,129 Epoch 912/2000
2025-02-19 01:12:06,385 Current Learning Rate: 0.0040630934
2025-02-19 01:12:06,386 Train Loss: 0.0002499, Val Loss: 0.0002981
2025-02-19 01:12:06,386 Epoch 913/2000
2025-02-19 01:12:49,288 Current Learning Rate: 0.0039860635
2025-02-19 01:12:49,289 Train Loss: 0.0002775, Val Loss: 0.0002908
2025-02-19 01:12:49,289 Epoch 914/2000
2025-02-19 01:13:31,999 Current Learning Rate: 0.0039092838
2025-02-19 01:13:33,960 Train Loss: 0.0002435, Val Loss: 0.0002789
2025-02-19 01:13:33,961 Epoch 915/2000
2025-02-19 01:14:16,323 Current Learning Rate: 0.0038327732
2025-02-19 01:14:16,325 Train Loss: 0.0002526, Val Loss: 0.0002906
2025-02-19 01:14:16,325 Epoch 916/2000
2025-02-19 01:14:58,827 Current Learning Rate: 0.0037565506
2025-02-19 01:14:58,828 Train Loss: 0.0002669, Val Loss: 0.0002921
2025-02-19 01:14:58,828 Epoch 917/2000
2025-02-19 01:15:41,853 Current Learning Rate: 0.0036806348
2025-02-19 01:15:41,854 Train Loss: 0.0002164, Val Loss: 0.0002792
2025-02-19 01:15:41,854 Epoch 918/2000
2025-02-19 01:16:23,813 Current Learning Rate: 0.0036050445
2025-02-19 01:16:23,814 Train Loss: 0.0002255, Val Loss: 0.0002794
2025-02-19 01:16:23,814 Epoch 919/2000
2025-02-19 01:17:07,086 Current Learning Rate: 0.0035297984
2025-02-19 01:17:07,087 Train Loss: 0.0002869, Val Loss: 0.0002800
2025-02-19 01:17:07,087 Epoch 920/2000
2025-02-19 01:17:49,383 Current Learning Rate: 0.0034549150
2025-02-19 01:17:50,793 Train Loss: 0.0002698, Val Loss: 0.0002749
2025-02-19 01:17:50,793 Epoch 921/2000
2025-02-19 01:18:32,693 Current Learning Rate: 0.0033804129
2025-02-19 01:18:32,693 Train Loss: 0.0002612, Val Loss: 0.0002751
2025-02-19 01:18:32,694 Epoch 922/2000
2025-02-19 01:19:15,670 Current Learning Rate: 0.0033063104
2025-02-19 01:19:17,150 Train Loss: 0.0001899, Val Loss: 0.0002719
2025-02-19 01:19:17,150 Epoch 923/2000
2025-02-19 01:19:58,305 Current Learning Rate: 0.0032326258
2025-02-19 01:19:59,527 Train Loss: 0.0002260, Val Loss: 0.0002717
2025-02-19 01:19:59,527 Epoch 924/2000
2025-02-19 01:20:41,135 Current Learning Rate: 0.0031593772
2025-02-19 01:20:41,136 Train Loss: 0.0002574, Val Loss: 0.0002725
2025-02-19 01:20:41,136 Epoch 925/2000
2025-02-19 01:21:24,003 Current Learning Rate: 0.0030865828
2025-02-19 01:21:24,004 Train Loss: 0.0002205, Val Loss: 0.0002747
2025-02-19 01:21:24,004 Epoch 926/2000
2025-02-19 01:22:07,051 Current Learning Rate: 0.0030142605
2025-02-19 01:22:07,051 Train Loss: 0.0002199, Val Loss: 0.0002769
2025-02-19 01:22:07,052 Epoch 927/2000
2025-02-19 01:22:49,094 Current Learning Rate: 0.0029424282
2025-02-19 01:22:49,094 Train Loss: 0.0002543, Val Loss: 0.0002740
2025-02-19 01:22:49,094 Epoch 928/2000
2025-02-19 01:23:31,325 Current Learning Rate: 0.0028711035
2025-02-19 01:23:32,391 Train Loss: 0.0002096, Val Loss: 0.0002696
2025-02-19 01:23:32,392 Epoch 929/2000
2025-02-19 01:24:13,969 Current Learning Rate: 0.0028003042
2025-02-19 01:24:13,971 Train Loss: 0.0002272, Val Loss: 0.0002752
2025-02-19 01:24:13,971 Epoch 930/2000
2025-02-19 01:24:56,385 Current Learning Rate: 0.0027300475
2025-02-19 01:24:56,386 Train Loss: 0.0002240, Val Loss: 0.0002701
2025-02-19 01:24:56,386 Epoch 931/2000
2025-02-19 01:25:39,502 Current Learning Rate: 0.0026603509
2025-02-19 01:25:39,503 Train Loss: 0.0002242, Val Loss: 0.0002711
2025-02-19 01:25:39,503 Epoch 932/2000
2025-02-19 01:26:22,401 Current Learning Rate: 0.0025912316
2025-02-19 01:26:24,370 Train Loss: 0.0002436, Val Loss: 0.0002676
2025-02-19 01:26:24,371 Epoch 933/2000
2025-02-19 01:27:05,570 Current Learning Rate: 0.0025227067
2025-02-19 01:27:07,078 Train Loss: 0.0002148, Val Loss: 0.0002638
2025-02-19 01:27:07,086 Epoch 934/2000
2025-02-19 01:27:49,081 Current Learning Rate: 0.0024547929
2025-02-19 01:27:50,702 Train Loss: 0.0002251, Val Loss: 0.0002619
2025-02-19 01:27:50,702 Epoch 935/2000
2025-02-19 01:28:31,754 Current Learning Rate: 0.0023875072
2025-02-19 01:28:33,036 Train Loss: 0.0001827, Val Loss: 0.0002602
2025-02-19 01:28:33,036 Epoch 936/2000
2025-02-19 01:29:14,392 Current Learning Rate: 0.0023208660
2025-02-19 01:29:15,488 Train Loss: 0.0002014, Val Loss: 0.0002590
2025-02-19 01:29:15,489 Epoch 937/2000
2025-02-19 01:29:57,083 Current Learning Rate: 0.0022548859
2025-02-19 01:29:58,469 Train Loss: 0.0002362, Val Loss: 0.0002579
2025-02-19 01:29:58,469 Epoch 938/2000
2025-02-19 01:30:39,993 Current Learning Rate: 0.0021895831
2025-02-19 01:30:41,455 Train Loss: 0.0001736, Val Loss: 0.0002557
2025-02-19 01:30:41,458 Epoch 939/2000
2025-02-19 01:31:24,250 Current Learning Rate: 0.0021249737
2025-02-19 01:31:24,251 Train Loss: 0.0002258, Val Loss: 0.0002566
2025-02-19 01:31:24,251 Epoch 940/2000
2025-02-19 01:32:07,128 Current Learning Rate: 0.0020610737
2025-02-19 01:32:08,622 Train Loss: 0.0002203, Val Loss: 0.0002551
2025-02-19 01:32:08,622 Epoch 941/2000
2025-02-19 01:32:50,378 Current Learning Rate: 0.0019978989
2025-02-19 01:32:50,379 Train Loss: 0.0002519, Val Loss: 0.0002554
2025-02-19 01:32:50,379 Epoch 942/2000
2025-02-19 01:33:33,066 Current Learning Rate: 0.0019354647
2025-02-19 01:33:34,782 Train Loss: 0.0002501, Val Loss: 0.0002541
2025-02-19 01:33:34,784 Epoch 943/2000
2025-02-19 01:34:17,343 Current Learning Rate: 0.0018737867
2025-02-19 01:34:19,231 Train Loss: 0.0002052, Val Loss: 0.0002531
2025-02-19 01:34:19,231 Epoch 944/2000
2025-02-19 01:35:02,390 Current Learning Rate: 0.0018128801
2025-02-19 01:35:04,389 Train Loss: 0.0001850, Val Loss: 0.0002522
2025-02-19 01:35:04,389 Epoch 945/2000
2025-02-19 01:35:47,356 Current Learning Rate: 0.0017527598
2025-02-19 01:35:47,357 Train Loss: 0.0002705, Val Loss: 0.0002529
2025-02-19 01:35:47,357 Epoch 946/2000
2025-02-19 01:36:30,434 Current Learning Rate: 0.0016934407
2025-02-19 01:36:31,908 Train Loss: 0.0002173, Val Loss: 0.0002519
2025-02-19 01:36:31,908 Epoch 947/2000
2025-02-19 01:37:14,105 Current Learning Rate: 0.0016349374
2025-02-19 01:37:15,502 Train Loss: 0.0001947, Val Loss: 0.0002517
2025-02-19 01:37:15,502 Epoch 948/2000
2025-02-19 01:37:57,388 Current Learning Rate: 0.0015772645
2025-02-19 01:37:57,389 Train Loss: 0.0001892, Val Loss: 0.0002519
2025-02-19 01:37:57,389 Epoch 949/2000
2025-02-19 01:38:40,050 Current Learning Rate: 0.0015204360
2025-02-19 01:38:41,940 Train Loss: 0.0001884, Val Loss: 0.0002515
2025-02-19 01:38:41,940 Epoch 950/2000
2025-02-19 01:39:24,606 Current Learning Rate: 0.0014644661
2025-02-19 01:39:26,431 Train Loss: 0.0001907, Val Loss: 0.0002505
2025-02-19 01:39:26,431 Epoch 951/2000
2025-02-19 01:40:08,522 Current Learning Rate: 0.0014093685
2025-02-19 01:40:09,642 Train Loss: 0.0002312, Val Loss: 0.0002488
2025-02-19 01:40:09,657 Epoch 952/2000
2025-02-19 01:40:51,824 Current Learning Rate: 0.0013551569
2025-02-19 01:40:53,342 Train Loss: 0.0001940, Val Loss: 0.0002480
2025-02-19 01:40:53,343 Epoch 953/2000
2025-02-19 01:41:35,574 Current Learning Rate: 0.0013018445
2025-02-19 01:41:37,275 Train Loss: 0.0002065, Val Loss: 0.0002470
2025-02-19 01:41:37,275 Epoch 954/2000
2025-02-19 01:42:20,208 Current Learning Rate: 0.0012494447
2025-02-19 01:42:21,900 Train Loss: 0.0001652, Val Loss: 0.0002463
2025-02-19 01:42:21,900 Epoch 955/2000
2025-02-19 01:43:04,933 Current Learning Rate: 0.0011979702
2025-02-19 01:43:04,942 Train Loss: 0.0001936, Val Loss: 0.0002464
2025-02-19 01:43:04,943 Epoch 956/2000
2025-02-19 01:43:47,806 Current Learning Rate: 0.0011474338
2025-02-19 01:43:49,643 Train Loss: 0.0001767, Val Loss: 0.0002458
2025-02-19 01:43:49,643 Epoch 957/2000
2025-02-19 01:44:31,073 Current Learning Rate: 0.0010978480
2025-02-19 01:44:31,074 Train Loss: 0.0002368, Val Loss: 0.0002462
2025-02-19 01:44:31,074 Epoch 958/2000
2025-02-19 01:45:14,623 Current Learning Rate: 0.0010492249
2025-02-19 01:45:16,688 Train Loss: 0.0002402, Val Loss: 0.0002456
2025-02-19 01:45:16,689 Epoch 959/2000
2025-02-19 01:45:58,954 Current Learning Rate: 0.0010015767
2025-02-19 01:46:00,493 Train Loss: 0.0001970, Val Loss: 0.0002446
2025-02-19 01:46:00,494 Epoch 960/2000
2025-02-19 01:46:42,534 Current Learning Rate: 0.0009549150
2025-02-19 01:46:42,535 Train Loss: 0.0002244, Val Loss: 0.0002450
2025-02-19 01:46:42,535 Epoch 961/2000
2025-02-19 01:47:26,138 Current Learning Rate: 0.0009092514
2025-02-19 01:47:26,139 Train Loss: 0.0003043, Val Loss: 0.0002449
2025-02-19 01:47:26,139 Epoch 962/2000
2025-02-19 01:48:09,507 Current Learning Rate: 0.0008645971
2025-02-19 01:48:11,575 Train Loss: 0.0002121, Val Loss: 0.0002443
2025-02-19 01:48:11,575 Epoch 963/2000
2025-02-19 01:48:54,842 Current Learning Rate: 0.0008209632
2025-02-19 01:48:56,954 Train Loss: 0.0002140, Val Loss: 0.0002442
2025-02-19 01:48:56,955 Epoch 964/2000
2025-02-19 01:49:40,630 Current Learning Rate: 0.0007783604
2025-02-19 01:49:42,454 Train Loss: 0.0001741, Val Loss: 0.0002437
2025-02-19 01:49:42,454 Epoch 965/2000
2025-02-19 01:50:25,641 Current Learning Rate: 0.0007367992
2025-02-19 01:50:27,274 Train Loss: 0.0002211, Val Loss: 0.0002434
2025-02-19 01:50:27,275 Epoch 966/2000
2025-02-19 01:51:09,831 Current Learning Rate: 0.0006962899
2025-02-19 01:51:10,767 Train Loss: 0.0001928, Val Loss: 0.0002431
2025-02-19 01:51:10,768 Epoch 967/2000
2025-02-19 01:51:52,774 Current Learning Rate: 0.0006568424
2025-02-19 01:51:53,952 Train Loss: 0.0001866, Val Loss: 0.0002428
2025-02-19 01:51:53,953 Epoch 968/2000
2025-02-19 01:52:35,603 Current Learning Rate: 0.0006184666
2025-02-19 01:52:35,604 Train Loss: 0.0001941, Val Loss: 0.0002429
2025-02-19 01:52:35,604 Epoch 969/2000
2025-02-19 01:53:18,960 Current Learning Rate: 0.0005811718
2025-02-19 01:53:18,960 Train Loss: 0.0002083, Val Loss: 0.0002431
2025-02-19 01:53:18,960 Epoch 970/2000
2025-02-19 01:54:02,211 Current Learning Rate: 0.0005449674
2025-02-19 01:54:03,914 Train Loss: 0.0002040, Val Loss: 0.0002424
2025-02-19 01:54:03,915 Epoch 971/2000
2025-02-19 01:54:46,386 Current Learning Rate: 0.0005098621
2025-02-19 01:54:48,457 Train Loss: 0.0001605, Val Loss: 0.0002422
2025-02-19 01:54:48,457 Epoch 972/2000
2025-02-19 01:55:30,788 Current Learning Rate: 0.0004758647
2025-02-19 01:55:32,516 Train Loss: 0.0001745, Val Loss: 0.0002421
2025-02-19 01:55:32,516 Epoch 973/2000
2025-02-19 01:56:14,135 Current Learning Rate: 0.0004429836
2025-02-19 01:56:15,724 Train Loss: 0.0001826, Val Loss: 0.0002419
2025-02-19 01:56:15,724 Epoch 974/2000
2025-02-19 01:56:58,804 Current Learning Rate: 0.0004112269
2025-02-19 01:56:58,805 Train Loss: 0.0002467, Val Loss: 0.0002421
2025-02-19 01:56:58,805 Epoch 975/2000
2025-02-19 01:57:41,550 Current Learning Rate: 0.0003806023
2025-02-19 01:57:43,701 Train Loss: 0.0002341, Val Loss: 0.0002418
2025-02-19 01:57:43,701 Epoch 976/2000
2025-02-19 01:58:26,478 Current Learning Rate: 0.0003511176
2025-02-19 01:58:26,479 Train Loss: 0.0001757, Val Loss: 0.0002418
2025-02-19 01:58:26,480 Epoch 977/2000
2025-02-19 01:59:09,330 Current Learning Rate: 0.0003227798
2025-02-19 01:59:10,909 Train Loss: 0.0001768, Val Loss: 0.0002416
2025-02-19 01:59:10,909 Epoch 978/2000
2025-02-19 01:59:52,454 Current Learning Rate: 0.0002955962
2025-02-19 01:59:52,457 Train Loss: 0.0002672, Val Loss: 0.0002418
2025-02-19 01:59:52,461 Epoch 979/2000
2025-02-19 02:00:36,021 Current Learning Rate: 0.0002695732
2025-02-19 02:00:37,816 Train Loss: 0.0002301, Val Loss: 0.0002416
2025-02-19 02:00:37,817 Epoch 980/2000
2025-02-19 02:01:20,378 Current Learning Rate: 0.0002447174
2025-02-19 02:01:22,232 Train Loss: 0.0001873, Val Loss: 0.0002414
2025-02-19 02:01:22,233 Epoch 981/2000
2025-02-19 02:02:05,316 Current Learning Rate: 0.0002210349
2025-02-19 02:02:07,409 Train Loss: 0.0002151, Val Loss: 0.0002412
2025-02-19 02:02:07,412 Epoch 982/2000
2025-02-19 02:02:48,898 Current Learning Rate: 0.0001985316
2025-02-19 02:02:50,670 Train Loss: 0.0001875, Val Loss: 0.0002410
2025-02-19 02:02:50,673 Epoch 983/2000
2025-02-19 02:03:32,828 Current Learning Rate: 0.0001772129
2025-02-19 02:03:34,937 Train Loss: 0.0002122, Val Loss: 0.0002408
2025-02-19 02:03:34,937 Epoch 984/2000
2025-02-19 02:04:18,252 Current Learning Rate: 0.0001570842
2025-02-19 02:04:20,174 Train Loss: 0.0001830, Val Loss: 0.0002407
2025-02-19 02:04:20,174 Epoch 985/2000
2025-02-19 02:05:02,298 Current Learning Rate: 0.0001381504
2025-02-19 02:05:03,853 Train Loss: 0.0002186, Val Loss: 0.0002407
2025-02-19 02:05:03,853 Epoch 986/2000
2025-02-19 02:05:46,071 Current Learning Rate: 0.0001204162
2025-02-19 02:05:47,564 Train Loss: 0.0001752, Val Loss: 0.0002405
2025-02-19 02:05:47,564 Epoch 987/2000
2025-02-19 02:06:30,825 Current Learning Rate: 0.0001038859
2025-02-19 02:06:30,825 Train Loss: 0.0001828, Val Loss: 0.0002406
2025-02-19 02:06:30,826 Epoch 988/2000
2025-02-19 02:07:13,711 Current Learning Rate: 0.0000885637
2025-02-19 02:07:15,314 Train Loss: 0.0002191, Val Loss: 0.0002405
2025-02-19 02:07:15,314 Epoch 989/2000
2025-02-19 02:07:56,615 Current Learning Rate: 0.0000744534
2025-02-19 02:07:57,978 Train Loss: 0.0002214, Val Loss: 0.0002405
2025-02-19 02:07:57,986 Epoch 990/2000
2025-02-19 02:08:40,035 Current Learning Rate: 0.0000615583
2025-02-19 02:08:40,036 Train Loss: 0.0001844, Val Loss: 0.0002406
2025-02-19 02:08:40,037 Epoch 991/2000
2025-02-19 02:09:22,797 Current Learning Rate: 0.0000498817
2025-02-19 02:09:22,798 Train Loss: 0.0001921, Val Loss: 0.0002406
2025-02-19 02:09:22,799 Epoch 992/2000
2025-02-19 02:10:06,294 Current Learning Rate: 0.0000394265
2025-02-19 02:10:06,294 Train Loss: 0.0001921, Val Loss: 0.0002405
2025-02-19 02:10:06,295 Epoch 993/2000
2025-02-19 02:10:49,605 Current Learning Rate: 0.0000301952
2025-02-19 02:10:51,653 Train Loss: 0.0001966, Val Loss: 0.0002404
2025-02-19 02:10:51,654 Epoch 994/2000
2025-02-19 02:11:34,226 Current Learning Rate: 0.0000221902
2025-02-19 02:11:35,736 Train Loss: 0.0001957, Val Loss: 0.0002403
2025-02-19 02:11:35,736 Epoch 995/2000
2025-02-19 02:12:17,386 Current Learning Rate: 0.0000154133
2025-02-19 02:12:19,186 Train Loss: 0.0002238, Val Loss: 0.0002403
2025-02-19 02:12:19,187 Epoch 996/2000
2025-02-19 02:13:02,743 Current Learning Rate: 0.0000098664
2025-02-19 02:13:02,744 Train Loss: 0.0002499, Val Loss: 0.0002404
2025-02-19 02:13:02,744 Epoch 997/2000
2025-02-19 02:13:45,479 Current Learning Rate: 0.0000055506
2025-02-19 02:13:45,479 Train Loss: 0.0002550, Val Loss: 0.0002403
2025-02-19 02:13:45,479 Epoch 998/2000
2025-02-19 02:14:27,901 Current Learning Rate: 0.0000024672
2025-02-19 02:14:27,902 Train Loss: 0.0002278, Val Loss: 0.0002403
2025-02-19 02:14:27,902 Epoch 999/2000
2025-02-19 02:15:10,109 Current Learning Rate: 0.0000006168
2025-02-19 02:15:10,110 Train Loss: 0.0002092, Val Loss: 0.0002404
2025-02-19 02:15:10,110 Epoch 1000/2000
2025-02-19 02:15:52,914 Current Learning Rate: 0.0000000000
2025-02-19 02:15:52,915 Train Loss: 0.0002107, Val Loss: 0.0002403
2025-02-19 02:15:52,915 Epoch 1001/2000
2025-02-19 02:16:36,119 Current Learning Rate: 0.0000006168
2025-02-19 02:16:36,119 Train Loss: 0.0001768, Val Loss: 0.0002404
2025-02-19 02:16:36,120 Epoch 1002/2000
2025-02-19 02:17:19,078 Current Learning Rate: 0.0000024672
2025-02-19 02:17:19,079 Train Loss: 0.0001856, Val Loss: 0.0002404
2025-02-19 02:17:19,079 Epoch 1003/2000
2025-02-19 02:18:01,039 Current Learning Rate: 0.0000055506
2025-02-19 02:18:01,040 Train Loss: 0.0001862, Val Loss: 0.0002404
2025-02-19 02:18:01,040 Epoch 1004/2000
2025-02-19 02:18:43,205 Current Learning Rate: 0.0000098664
2025-02-19 02:18:43,206 Train Loss: 0.0002128, Val Loss: 0.0002404
2025-02-19 02:18:43,206 Epoch 1005/2000
2025-02-19 02:19:25,497 Current Learning Rate: 0.0000154133
2025-02-19 02:19:25,498 Train Loss: 0.0002376, Val Loss: 0.0002404
2025-02-19 02:19:25,498 Epoch 1006/2000
2025-02-19 02:20:08,309 Current Learning Rate: 0.0000221902
2025-02-19 02:20:08,309 Train Loss: 0.0001808, Val Loss: 0.0002404
2025-02-19 02:20:08,310 Epoch 1007/2000
2025-02-19 02:20:50,855 Current Learning Rate: 0.0000301952
2025-02-19 02:20:50,856 Train Loss: 0.0001658, Val Loss: 0.0002404
2025-02-19 02:20:50,856 Epoch 1008/2000
2025-02-19 02:21:33,196 Current Learning Rate: 0.0000394265
2025-02-19 02:21:33,197 Train Loss: 0.0002466, Val Loss: 0.0002404
2025-02-19 02:21:33,197 Epoch 1009/2000
2025-02-19 02:22:16,233 Current Learning Rate: 0.0000498817
2025-02-19 02:22:16,234 Train Loss: 0.0002309, Val Loss: 0.0002405
2025-02-19 02:22:16,234 Epoch 1010/2000
2025-02-19 02:22:58,350 Current Learning Rate: 0.0000615583
2025-02-19 02:22:58,351 Train Loss: 0.0001931, Val Loss: 0.0002405
2025-02-19 02:22:58,351 Epoch 1011/2000
2025-02-19 02:23:40,729 Current Learning Rate: 0.0000744534
2025-02-19 02:23:40,729 Train Loss: 0.0002091, Val Loss: 0.0002405
2025-02-19 02:23:40,730 Epoch 1012/2000
2025-02-19 02:24:23,413 Current Learning Rate: 0.0000885637
2025-02-19 02:24:23,414 Train Loss: 0.0001961, Val Loss: 0.0002404
2025-02-19 02:24:23,414 Epoch 1013/2000
2025-02-19 02:25:05,268 Current Learning Rate: 0.0001038859
2025-02-19 02:25:05,269 Train Loss: 0.0001905, Val Loss: 0.0002404
2025-02-19 02:25:05,269 Epoch 1014/2000
2025-02-19 02:25:48,047 Current Learning Rate: 0.0001204162
2025-02-19 02:25:48,048 Train Loss: 0.0002255, Val Loss: 0.0002404
2025-02-19 02:25:48,048 Epoch 1015/2000
2025-02-19 02:26:31,121 Current Learning Rate: 0.0001381504
2025-02-19 02:26:31,122 Train Loss: 0.0001880, Val Loss: 0.0002405
2025-02-19 02:26:31,122 Epoch 1016/2000
2025-02-19 02:27:13,479 Current Learning Rate: 0.0001570842
2025-02-19 02:27:13,480 Train Loss: 0.0002158, Val Loss: 0.0002405
2025-02-19 02:27:13,480 Epoch 1017/2000
2025-02-19 02:27:55,659 Current Learning Rate: 0.0001772129
2025-02-19 02:27:55,659 Train Loss: 0.0001954, Val Loss: 0.0002406
2025-02-19 02:27:55,660 Epoch 1018/2000
2025-02-19 02:28:38,086 Current Learning Rate: 0.0001985316
2025-02-19 02:28:38,087 Train Loss: 0.0001834, Val Loss: 0.0002407
2025-02-19 02:28:38,087 Epoch 1019/2000
2025-02-19 02:29:21,202 Current Learning Rate: 0.0002210349
2025-02-19 02:29:21,203 Train Loss: 0.0001529, Val Loss: 0.0002408
2025-02-19 02:29:21,203 Epoch 1020/2000
2025-02-19 02:30:03,353 Current Learning Rate: 0.0002447174
2025-02-19 02:30:03,353 Train Loss: 0.0002022, Val Loss: 0.0002408
2025-02-19 02:30:03,353 Epoch 1021/2000
2025-02-19 02:30:45,509 Current Learning Rate: 0.0002695732
2025-02-19 02:30:45,510 Train Loss: 0.0002511, Val Loss: 0.0002411
2025-02-19 02:30:45,510 Epoch 1022/2000
2025-02-19 02:31:28,403 Current Learning Rate: 0.0002955962
2025-02-19 02:31:28,403 Train Loss: 0.0001961, Val Loss: 0.0002411
2025-02-19 02:31:28,403 Epoch 1023/2000
2025-02-19 02:32:10,349 Current Learning Rate: 0.0003227798
2025-02-19 02:32:10,349 Train Loss: 0.0002385, Val Loss: 0.0002411
2025-02-19 02:32:10,350 Epoch 1024/2000
2025-02-19 02:32:52,876 Current Learning Rate: 0.0003511176
2025-02-19 02:32:52,877 Train Loss: 0.0001825, Val Loss: 0.0002408
2025-02-19 02:32:52,877 Epoch 1025/2000
2025-02-19 02:33:36,004 Current Learning Rate: 0.0003806023
2025-02-19 02:33:36,004 Train Loss: 0.0002116, Val Loss: 0.0002408
2025-02-19 02:33:36,005 Epoch 1026/2000
2025-02-19 02:34:19,114 Current Learning Rate: 0.0004112269
2025-02-19 02:34:19,114 Train Loss: 0.0002668, Val Loss: 0.0002409
2025-02-19 02:34:19,114 Epoch 1027/2000
2025-02-19 02:35:01,809 Current Learning Rate: 0.0004429836
2025-02-19 02:35:01,810 Train Loss: 0.0001989, Val Loss: 0.0002409
2025-02-19 02:35:01,810 Epoch 1028/2000
2025-02-19 02:35:44,730 Current Learning Rate: 0.0004758647
2025-02-19 02:35:44,731 Train Loss: 0.0002409, Val Loss: 0.0002410
2025-02-19 02:35:44,731 Epoch 1029/2000
2025-02-19 02:36:27,606 Current Learning Rate: 0.0005098621
2025-02-19 02:36:27,606 Train Loss: 0.0002303, Val Loss: 0.0002411
2025-02-19 02:36:27,606 Epoch 1030/2000
2025-02-19 02:37:09,911 Current Learning Rate: 0.0005449674
2025-02-19 02:37:09,912 Train Loss: 0.0001906, Val Loss: 0.0002410
2025-02-19 02:37:09,912 Epoch 1031/2000
2025-02-19 02:37:52,823 Current Learning Rate: 0.0005811718
2025-02-19 02:37:52,824 Train Loss: 0.0001867, Val Loss: 0.0002411
2025-02-19 02:37:52,824 Epoch 1032/2000
2025-02-19 02:38:35,812 Current Learning Rate: 0.0006184666
2025-02-19 02:38:35,812 Train Loss: 0.0002085, Val Loss: 0.0002412
2025-02-19 02:38:35,844 Epoch 1033/2000
2025-02-19 02:39:18,909 Current Learning Rate: 0.0006568424
2025-02-19 02:39:18,909 Train Loss: 0.0001863, Val Loss: 0.0002415
2025-02-19 02:39:18,909 Epoch 1034/2000
2025-02-19 02:40:01,934 Current Learning Rate: 0.0006962899
2025-02-19 02:40:01,950 Train Loss: 0.0001951, Val Loss: 0.0002417
2025-02-19 02:40:01,950 Epoch 1035/2000
2025-02-19 02:40:44,917 Current Learning Rate: 0.0007367992
2025-02-19 02:40:44,917 Train Loss: 0.0002074, Val Loss: 0.0002412
2025-02-19 02:40:44,918 Epoch 1036/2000
2025-02-19 02:41:27,037 Current Learning Rate: 0.0007783604
2025-02-19 02:41:27,038 Train Loss: 0.0002001, Val Loss: 0.0002414
2025-02-19 02:41:27,038 Epoch 1037/2000
2025-02-19 02:42:09,820 Current Learning Rate: 0.0008209632
2025-02-19 02:42:09,820 Train Loss: 0.0001536, Val Loss: 0.0002410
2025-02-19 02:42:09,821 Epoch 1038/2000
2025-02-19 02:42:52,863 Current Learning Rate: 0.0008645971
2025-02-19 02:42:52,863 Train Loss: 0.0001840, Val Loss: 0.0002419
2025-02-19 02:42:52,864 Epoch 1039/2000
2025-02-19 02:43:35,671 Current Learning Rate: 0.0009092514
2025-02-19 02:43:35,671 Train Loss: 0.0002240, Val Loss: 0.0002426
2025-02-19 02:43:35,672 Epoch 1040/2000
2025-02-19 02:44:18,664 Current Learning Rate: 0.0009549150
2025-02-19 02:44:18,664 Train Loss: 0.0001873, Val Loss: 0.0002443
2025-02-19 02:44:18,665 Epoch 1041/2000
2025-02-19 02:45:01,305 Current Learning Rate: 0.0010015767
2025-02-19 02:45:01,306 Train Loss: 0.0002169, Val Loss: 0.0002440
2025-02-19 02:45:01,306 Epoch 1042/2000
2025-02-19 02:45:44,574 Current Learning Rate: 0.0010492249
2025-02-19 02:45:44,575 Train Loss: 0.0001987, Val Loss: 0.0002429
2025-02-19 02:45:44,575 Epoch 1043/2000
2025-02-19 02:46:27,623 Current Learning Rate: 0.0010978480
2025-02-19 02:46:27,624 Train Loss: 0.0001909, Val Loss: 0.0002433
2025-02-19 02:46:27,624 Epoch 1044/2000
2025-02-19 02:47:09,458 Current Learning Rate: 0.0011474338
2025-02-19 02:47:09,458 Train Loss: 0.0001822, Val Loss: 0.0002547
2025-02-19 02:47:09,458 Epoch 1045/2000
2025-02-19 02:47:52,697 Current Learning Rate: 0.0011979702
2025-02-19 02:47:52,698 Train Loss: 0.0002643, Val Loss: 0.0002500
2025-02-19 02:47:52,698 Epoch 1046/2000
2025-02-19 02:48:35,620 Current Learning Rate: 0.0012494447
2025-02-19 02:48:35,621 Train Loss: 0.0001741, Val Loss: 0.0002426
2025-02-19 02:48:35,621 Epoch 1047/2000
2025-02-19 02:49:17,580 Current Learning Rate: 0.0013018445
2025-02-19 02:49:17,580 Train Loss: 0.0002105, Val Loss: 0.0002442
2025-02-19 02:49:17,581 Epoch 1048/2000
2025-02-19 02:50:00,683 Current Learning Rate: 0.0013551569
2025-02-19 02:50:00,683 Train Loss: 0.0002068, Val Loss: 0.0002428
2025-02-19 02:50:00,684 Epoch 1049/2000
2025-02-19 02:50:42,972 Current Learning Rate: 0.0014093685
2025-02-19 02:50:42,972 Train Loss: 0.0001789, Val Loss: 0.0002421
2025-02-19 02:50:42,973 Epoch 1050/2000
2025-02-19 02:51:25,472 Current Learning Rate: 0.0014644661
2025-02-19 02:51:25,473 Train Loss: 0.0002605, Val Loss: 0.0002467
2025-02-19 02:51:25,473 Epoch 1051/2000
2025-02-19 02:52:08,662 Current Learning Rate: 0.0015204360
2025-02-19 02:52:08,667 Train Loss: 0.0001630, Val Loss: 0.0002442
2025-02-19 02:52:08,667 Epoch 1052/2000
2025-02-19 02:52:51,733 Current Learning Rate: 0.0015772645
2025-02-19 02:52:51,734 Train Loss: 0.0002045, Val Loss: 0.0002469
2025-02-19 02:52:51,734 Epoch 1053/2000
2025-02-19 02:53:34,550 Current Learning Rate: 0.0016349374
2025-02-19 02:53:34,550 Train Loss: 0.0001714, Val Loss: 0.0002444
2025-02-19 02:53:34,550 Epoch 1054/2000
2025-02-19 02:54:17,575 Current Learning Rate: 0.0016934407
2025-02-19 02:54:17,576 Train Loss: 0.0001602, Val Loss: 0.0002427
2025-02-19 02:54:17,576 Epoch 1055/2000
2025-02-19 02:54:59,779 Current Learning Rate: 0.0017527598
2025-02-19 02:54:59,779 Train Loss: 0.0002511, Val Loss: 0.0002737
2025-02-19 02:54:59,780 Epoch 1056/2000
2025-02-19 02:55:41,777 Current Learning Rate: 0.0018128801
2025-02-19 02:55:41,778 Train Loss: 0.0002528, Val Loss: 0.0002682
2025-02-19 02:55:41,778 Epoch 1057/2000
2025-02-19 02:56:25,096 Current Learning Rate: 0.0018737867
2025-02-19 02:56:25,096 Train Loss: 0.0001692, Val Loss: 0.0002470
2025-02-19 02:56:25,097 Epoch 1058/2000
2025-02-19 02:57:07,568 Current Learning Rate: 0.0019354647
2025-02-19 02:57:07,569 Train Loss: 0.0002568, Val Loss: 0.0002665
2025-02-19 02:57:07,569 Epoch 1059/2000
2025-02-19 02:57:50,342 Current Learning Rate: 0.0019978989
2025-02-19 02:57:50,350 Train Loss: 0.0002297, Val Loss: 0.0002527
2025-02-19 02:57:50,353 Epoch 1060/2000
2025-02-19 02:58:33,580 Current Learning Rate: 0.0020610737
2025-02-19 02:58:33,581 Train Loss: 0.0002015, Val Loss: 0.0002620
2025-02-19 02:58:33,581 Epoch 1061/2000
2025-02-19 02:59:15,640 Current Learning Rate: 0.0021249737
2025-02-19 02:59:15,641 Train Loss: 0.0001785, Val Loss: 0.0002485
2025-02-19 02:59:15,641 Epoch 1062/2000
2025-02-19 02:59:58,039 Current Learning Rate: 0.0021895831
2025-02-19 02:59:58,040 Train Loss: 0.0001988, Val Loss: 0.0002520
2025-02-19 02:59:58,040 Epoch 1063/2000
2025-02-19 03:00:41,340 Current Learning Rate: 0.0022548859
2025-02-19 03:00:41,340 Train Loss: 0.0002370, Val Loss: 0.0002510
2025-02-19 03:00:41,341 Epoch 1064/2000
2025-02-19 03:01:24,515 Current Learning Rate: 0.0023208660
2025-02-19 03:01:24,515 Train Loss: 0.0002544, Val Loss: 0.0002793
2025-02-19 03:01:24,515 Epoch 1065/2000
2025-02-19 03:02:07,061 Current Learning Rate: 0.0023875072
2025-02-19 03:02:07,061 Train Loss: 0.0001976, Val Loss: 0.0002534
2025-02-19 03:02:07,062 Epoch 1066/2000
2025-02-19 03:02:49,896 Current Learning Rate: 0.0024547929
2025-02-19 03:02:49,896 Train Loss: 0.0002091, Val Loss: 0.0002630
2025-02-19 03:02:49,896 Epoch 1067/2000
2025-02-19 03:03:32,254 Current Learning Rate: 0.0025227067
2025-02-19 03:03:32,255 Train Loss: 0.0001926, Val Loss: 0.0002540
2025-02-19 03:03:32,255 Epoch 1068/2000
2025-02-19 03:04:15,089 Current Learning Rate: 0.0025912316
2025-02-19 03:04:15,090 Train Loss: 0.0002061, Val Loss: 0.0002576
2025-02-19 03:04:15,090 Epoch 1069/2000
2025-02-19 03:04:58,923 Current Learning Rate: 0.0026603509
2025-02-19 03:04:58,924 Train Loss: 0.0002317, Val Loss: 0.0002534
2025-02-19 03:04:58,925 Epoch 1070/2000
2025-02-19 03:05:42,697 Current Learning Rate: 0.0027300475
2025-02-19 03:05:42,697 Train Loss: 0.0002962, Val Loss: 0.0002856
2025-02-19 03:05:42,698 Epoch 1071/2000
2025-02-19 03:06:25,295 Current Learning Rate: 0.0028003042
2025-02-19 03:06:25,296 Train Loss: 0.0001934, Val Loss: 0.0002571
2025-02-19 03:06:25,296 Epoch 1072/2000
2025-02-19 03:07:08,345 Current Learning Rate: 0.0028711035
2025-02-19 03:07:08,346 Train Loss: 0.0001742, Val Loss: 0.0002518
2025-02-19 03:07:08,346 Epoch 1073/2000
2025-02-19 03:07:51,696 Current Learning Rate: 0.0029424282
2025-02-19 03:07:51,696 Train Loss: 0.0001922, Val Loss: 0.0002530
2025-02-19 03:07:51,697 Epoch 1074/2000
2025-02-19 03:08:34,096 Current Learning Rate: 0.0030142605
2025-02-19 03:08:34,097 Train Loss: 0.0001934, Val Loss: 0.0002503
2025-02-19 03:08:34,097 Epoch 1075/2000
2025-02-19 03:09:17,150 Current Learning Rate: 0.0030865828
2025-02-19 03:09:17,151 Train Loss: 0.0002513, Val Loss: 0.0002570
2025-02-19 03:09:17,151 Epoch 1076/2000
2025-02-19 03:10:00,981 Current Learning Rate: 0.0031593772
2025-02-19 03:10:00,982 Train Loss: 0.0002130, Val Loss: 0.0002609
2025-02-19 03:10:00,982 Epoch 1077/2000
2025-02-19 03:10:44,021 Current Learning Rate: 0.0032326258
2025-02-19 03:10:44,022 Train Loss: 0.0002131, Val Loss: 0.0002551
2025-02-19 03:10:44,022 Epoch 1078/2000
2025-02-19 03:11:27,257 Current Learning Rate: 0.0033063104
2025-02-19 03:11:27,257 Train Loss: 0.0001940, Val Loss: 0.0002535
2025-02-19 03:11:27,258 Epoch 1079/2000
2025-02-19 03:12:10,473 Current Learning Rate: 0.0033804129
2025-02-19 03:12:10,474 Train Loss: 0.0002639, Val Loss: 0.0002960
2025-02-19 03:12:10,474 Epoch 1080/2000
2025-02-19 03:12:52,938 Current Learning Rate: 0.0034549150
2025-02-19 03:12:52,939 Train Loss: 0.0002487, Val Loss: 0.0002833
2025-02-19 03:12:52,939 Epoch 1081/2000
2025-02-19 03:13:36,263 Current Learning Rate: 0.0035297984
2025-02-19 03:13:36,263 Train Loss: 0.0002314, Val Loss: 0.0002922
2025-02-19 03:13:36,264 Epoch 1082/2000
2025-02-19 03:14:19,263 Current Learning Rate: 0.0036050445
2025-02-19 03:14:19,264 Train Loss: 0.0001890, Val Loss: 0.0002646
2025-02-19 03:14:19,264 Epoch 1083/2000
2025-02-19 03:15:02,656 Current Learning Rate: 0.0036806348
2025-02-19 03:15:02,657 Train Loss: 0.0002519, Val Loss: 0.0002780
2025-02-19 03:15:02,657 Epoch 1084/2000
2025-02-19 03:15:45,570 Current Learning Rate: 0.0037565506
2025-02-19 03:15:45,571 Train Loss: 0.0001779, Val Loss: 0.0002759
2025-02-19 03:15:45,571 Epoch 1085/2000
2025-02-19 03:16:28,430 Current Learning Rate: 0.0038327732
2025-02-19 03:16:28,431 Train Loss: 0.0003325, Val Loss: 0.0003134
2025-02-19 03:16:28,432 Epoch 1086/2000
2025-02-19 03:17:10,905 Current Learning Rate: 0.0039092838
2025-02-19 03:17:10,905 Train Loss: 0.0002747, Val Loss: 0.0002782
2025-02-19 03:17:10,905 Epoch 1087/2000
2025-02-19 03:17:54,353 Current Learning Rate: 0.0039860635
2025-02-19 03:17:54,354 Train Loss: 0.0002859, Val Loss: 0.0003184
2025-02-19 03:17:54,354 Epoch 1088/2000
2025-02-19 03:18:37,800 Current Learning Rate: 0.0040630934
2025-02-19 03:18:37,801 Train Loss: 0.0002034, Val Loss: 0.0002639
2025-02-19 03:18:37,801 Epoch 1089/2000
2025-02-19 03:19:21,001 Current Learning Rate: 0.0041403545
2025-02-19 03:19:21,001 Train Loss: 0.0002202, Val Loss: 0.0002687
2025-02-19 03:19:21,001 Epoch 1090/2000
2025-02-19 03:20:04,362 Current Learning Rate: 0.0042178277
2025-02-19 03:20:04,363 Train Loss: 0.0002341, Val Loss: 0.0002729
2025-02-19 03:20:04,363 Epoch 1091/2000
2025-02-19 03:20:47,775 Current Learning Rate: 0.0042954938
2025-02-19 03:20:47,775 Train Loss: 0.0002009, Val Loss: 0.0003032
2025-02-19 03:20:47,775 Epoch 1092/2000
2025-02-19 03:21:30,223 Current Learning Rate: 0.0043733338
2025-02-19 03:21:30,223 Train Loss: 0.0003220, Val Loss: 0.0004474
2025-02-19 03:21:30,224 Epoch 1093/2000
2025-02-19 03:22:12,909 Current Learning Rate: 0.0044513284
2025-02-19 03:22:12,910 Train Loss: 0.0002945, Val Loss: 0.0002943
2025-02-19 03:22:12,911 Epoch 1094/2000
2025-02-19 03:22:55,486 Current Learning Rate: 0.0045294584
2025-02-19 03:22:55,487 Train Loss: 0.0002949, Val Loss: 0.0002978
2025-02-19 03:22:55,487 Epoch 1095/2000
2025-02-19 03:23:38,276 Current Learning Rate: 0.0046077045
2025-02-19 03:23:38,276 Train Loss: 0.0002308, Val Loss: 0.0002898
2025-02-19 03:23:38,276 Epoch 1096/2000
2025-02-19 03:24:21,624 Current Learning Rate: 0.0046860474
2025-02-19 03:24:21,625 Train Loss: 0.0002064, Val Loss: 0.0002857
2025-02-19 03:24:21,625 Epoch 1097/2000
2025-02-19 03:25:03,985 Current Learning Rate: 0.0047644677
2025-02-19 03:25:03,986 Train Loss: 0.0002253, Val Loss: 0.0002676
2025-02-19 03:25:03,986 Epoch 1098/2000
2025-02-19 03:25:47,312 Current Learning Rate: 0.0048429462
2025-02-19 03:25:47,313 Train Loss: 0.0002980, Val Loss: 0.0002916
2025-02-19 03:25:47,313 Epoch 1099/2000
2025-02-19 03:26:31,052 Current Learning Rate: 0.0049214634
2025-02-19 03:26:31,052 Train Loss: 0.0002462, Val Loss: 0.0003128
2025-02-19 03:26:31,053 Epoch 1100/2000
2025-02-19 03:27:14,228 Current Learning Rate: 0.0050000000
2025-02-19 03:27:14,229 Train Loss: 0.0002166, Val Loss: 0.0002886
2025-02-19 03:27:14,229 Epoch 1101/2000
2025-02-19 03:27:56,619 Current Learning Rate: 0.0050785366
2025-02-19 03:27:56,620 Train Loss: 0.0003070, Val Loss: 0.0003832
2025-02-19 03:27:56,620 Epoch 1102/2000
2025-02-19 03:28:38,845 Current Learning Rate: 0.0051570538
2025-02-19 03:28:38,846 Train Loss: 0.0002541, Val Loss: 0.0002917
2025-02-19 03:28:38,846 Epoch 1103/2000
2025-02-19 03:29:21,417 Current Learning Rate: 0.0052355323
2025-02-19 03:29:21,418 Train Loss: 0.0002667, Val Loss: 0.0003610
2025-02-19 03:29:21,418 Epoch 1104/2000
2025-02-19 03:30:03,744 Current Learning Rate: 0.0053139526
2025-02-19 03:30:03,745 Train Loss: 0.0003004, Val Loss: 0.0003231
2025-02-19 03:30:03,745 Epoch 1105/2000
2025-02-19 03:30:47,024 Current Learning Rate: 0.0053922955
2025-02-19 03:30:47,025 Train Loss: 0.0002553, Val Loss: 0.0003014
2025-02-19 03:30:47,025 Epoch 1106/2000
2025-02-19 03:31:30,027 Current Learning Rate: 0.0054705416
2025-02-19 03:31:30,028 Train Loss: 0.0002604, Val Loss: 0.0003149
2025-02-19 03:31:30,028 Epoch 1107/2000
2025-02-19 03:32:12,247 Current Learning Rate: 0.0055486716
2025-02-19 03:32:12,248 Train Loss: 0.0002063, Val Loss: 0.0002979
2025-02-19 03:32:12,248 Epoch 1108/2000
2025-02-19 03:32:54,546 Current Learning Rate: 0.0056266662
2025-02-19 03:32:54,546 Train Loss: 0.0002328, Val Loss: 0.0002973
2025-02-19 03:32:54,547 Epoch 1109/2000
2025-02-19 03:33:37,425 Current Learning Rate: 0.0057045062
2025-02-19 03:33:37,426 Train Loss: 0.0003118, Val Loss: 0.0003333
2025-02-19 03:33:37,426 Epoch 1110/2000
2025-02-19 03:34:19,891 Current Learning Rate: 0.0057821723
2025-02-19 03:34:19,891 Train Loss: 0.0002921, Val Loss: 0.0003189
2025-02-19 03:34:19,892 Epoch 1111/2000
2025-02-19 03:35:02,765 Current Learning Rate: 0.0058596455
2025-02-19 03:35:02,765 Train Loss: 0.0003431, Val Loss: 0.0003513
2025-02-19 03:35:02,766 Epoch 1112/2000
2025-02-19 03:35:45,607 Current Learning Rate: 0.0059369066
2025-02-19 03:35:45,608 Train Loss: 0.0003520, Val Loss: 0.0003310
2025-02-19 03:35:45,608 Epoch 1113/2000
2025-02-19 03:36:28,595 Current Learning Rate: 0.0060139365
2025-02-19 03:36:28,596 Train Loss: 0.0004791, Val Loss: 0.0003653
2025-02-19 03:36:28,596 Epoch 1114/2000
2025-02-19 03:37:11,420 Current Learning Rate: 0.0060907162
2025-02-19 03:37:11,421 Train Loss: 0.0003725, Val Loss: 0.0003362
2025-02-19 03:37:11,421 Epoch 1115/2000
2025-02-19 03:37:53,178 Current Learning Rate: 0.0061672268
2025-02-19 03:37:53,178 Train Loss: 0.0002529, Val Loss: 0.0003042
2025-02-19 03:37:53,179 Epoch 1116/2000
2025-02-19 03:38:35,640 Current Learning Rate: 0.0062434494
2025-02-19 03:38:35,641 Train Loss: 0.0002894, Val Loss: 0.0003179
2025-02-19 03:38:35,641 Epoch 1117/2000
2025-02-19 03:39:18,267 Current Learning Rate: 0.0063193652
2025-02-19 03:39:18,267 Train Loss: 0.0002789, Val Loss: 0.0003679
2025-02-19 03:39:18,267 Epoch 1118/2000
2025-02-19 03:40:00,360 Current Learning Rate: 0.0063949555
2025-02-19 03:40:00,361 Train Loss: 0.0003663, Val Loss: 0.0003915
2025-02-19 03:40:00,361 Epoch 1119/2000
2025-02-19 03:40:42,402 Current Learning Rate: 0.0064702016
2025-02-19 03:40:42,403 Train Loss: 0.0003640, Val Loss: 0.0004146
2025-02-19 03:40:42,403 Epoch 1120/2000
2025-02-19 03:41:25,325 Current Learning Rate: 0.0065450850
2025-02-19 03:41:25,325 Train Loss: 0.0003236, Val Loss: 0.0003426
2025-02-19 03:41:25,326 Epoch 1121/2000
2025-02-19 03:42:07,944 Current Learning Rate: 0.0066195871
2025-02-19 03:42:07,945 Train Loss: 0.0003442, Val Loss: 0.0003151
2025-02-19 03:42:07,945 Epoch 1122/2000
2025-02-19 03:42:50,530 Current Learning Rate: 0.0066936896
2025-02-19 03:42:50,531 Train Loss: 0.0002456, Val Loss: 0.0003012
2025-02-19 03:42:50,531 Epoch 1123/2000
2025-02-19 03:43:33,340 Current Learning Rate: 0.0067673742
2025-02-19 03:43:33,340 Train Loss: 0.0003050, Val Loss: 0.0004627
2025-02-19 03:43:33,341 Epoch 1124/2000
2025-02-19 03:44:15,499 Current Learning Rate: 0.0068406228
2025-02-19 03:44:15,499 Train Loss: 0.0004283, Val Loss: 0.0004645
2025-02-19 03:44:15,500 Epoch 1125/2000
2025-02-19 03:44:57,913 Current Learning Rate: 0.0069134172
2025-02-19 03:44:57,913 Train Loss: 0.0003717, Val Loss: 0.0003399
2025-02-19 03:44:57,914 Epoch 1126/2000
2025-02-19 03:45:40,362 Current Learning Rate: 0.0069857395
2025-02-19 03:45:40,362 Train Loss: 0.0002985, Val Loss: 0.0003369
2025-02-19 03:45:40,363 Epoch 1127/2000
2025-02-19 03:46:22,432 Current Learning Rate: 0.0070575718
2025-02-19 03:46:22,432 Train Loss: 0.0003203, Val Loss: 0.0003092
2025-02-19 03:46:22,432 Epoch 1128/2000
2025-02-19 03:47:05,642 Current Learning Rate: 0.0071288965
2025-02-19 03:47:05,642 Train Loss: 0.0002447, Val Loss: 0.0002961
2025-02-19 03:47:05,643 Epoch 1129/2000
2025-02-19 03:47:48,498 Current Learning Rate: 0.0071996958
2025-02-19 03:47:48,499 Train Loss: 0.0002411, Val Loss: 0.0002873
2025-02-19 03:47:48,499 Epoch 1130/2000
2025-02-19 03:48:31,327 Current Learning Rate: 0.0072699525
2025-02-19 03:48:31,328 Train Loss: 0.0002039, Val Loss: 0.0002897
2025-02-19 03:48:31,328 Epoch 1131/2000
2025-02-19 03:49:13,409 Current Learning Rate: 0.0073396491
2025-02-19 03:49:13,410 Train Loss: 0.0002713, Val Loss: 0.0003436
2025-02-19 03:49:13,410 Epoch 1132/2000
2025-02-19 03:49:55,525 Current Learning Rate: 0.0074087684
2025-02-19 03:49:55,526 Train Loss: 0.0002606, Val Loss: 0.0003267
2025-02-19 03:49:55,526 Epoch 1133/2000
2025-02-19 03:50:37,816 Current Learning Rate: 0.0074772933
2025-02-19 03:50:37,817 Train Loss: 0.0003241, Val Loss: 0.0003345
2025-02-19 03:50:37,817 Epoch 1134/2000
2025-02-19 03:51:20,448 Current Learning Rate: 0.0075452071
2025-02-19 03:51:20,448 Train Loss: 0.0002496, Val Loss: 0.0003114
2025-02-19 03:51:20,449 Epoch 1135/2000
2025-02-19 03:52:02,854 Current Learning Rate: 0.0076124928
2025-02-19 03:52:02,855 Train Loss: 0.0002655, Val Loss: 0.0003490
2025-02-19 03:52:02,855 Epoch 1136/2000
2025-02-19 03:52:44,720 Current Learning Rate: 0.0076791340
2025-02-19 03:52:44,721 Train Loss: 0.0003818, Val Loss: 0.0003598
2025-02-19 03:52:44,721 Epoch 1137/2000
2025-02-19 03:53:27,235 Current Learning Rate: 0.0077451141
2025-02-19 03:53:27,235 Train Loss: 0.0003065, Val Loss: 0.0003834
2025-02-19 03:53:27,236 Epoch 1138/2000
2025-02-19 03:54:09,662 Current Learning Rate: 0.0078104169
2025-02-19 03:54:09,662 Train Loss: 0.0003612, Val Loss: 0.0003496
2025-02-19 03:54:09,663 Epoch 1139/2000
2025-02-19 03:54:52,962 Current Learning Rate: 0.0078750263
2025-02-19 03:54:52,962 Train Loss: 0.0002888, Val Loss: 0.0003206
2025-02-19 03:54:52,963 Epoch 1140/2000
2025-02-19 03:55:35,924 Current Learning Rate: 0.0079389263
2025-02-19 03:55:35,925 Train Loss: 0.0003172, Val Loss: 0.0003506
2025-02-19 03:55:35,925 Epoch 1141/2000
2025-02-19 03:56:18,110 Current Learning Rate: 0.0080021011
2025-02-19 03:56:18,111 Train Loss: 0.0003200, Val Loss: 0.0003664
2025-02-19 03:56:18,112 Epoch 1142/2000
2025-02-19 03:57:00,244 Current Learning Rate: 0.0080645353
2025-02-19 03:57:00,245 Train Loss: 0.0003015, Val Loss: 0.0004287
2025-02-19 03:57:00,245 Epoch 1143/2000
2025-02-19 03:57:43,627 Current Learning Rate: 0.0081262133
2025-02-19 03:57:43,627 Train Loss: 0.0003808, Val Loss: 0.0004373
2025-02-19 03:57:43,627 Epoch 1144/2000
2025-02-19 03:58:26,253 Current Learning Rate: 0.0081871199
2025-02-19 03:58:26,254 Train Loss: 0.0003841, Val Loss: 0.0004210
2025-02-19 03:58:26,254 Epoch 1145/2000
2025-02-19 03:59:09,262 Current Learning Rate: 0.0082472402
2025-02-19 03:59:09,263 Train Loss: 0.0003528, Val Loss: 0.0003438
2025-02-19 03:59:09,263 Epoch 1146/2000
2025-02-19 03:59:51,501 Current Learning Rate: 0.0083065593
2025-02-19 03:59:51,502 Train Loss: 0.0004203, Val Loss: 0.0003761
2025-02-19 03:59:51,502 Epoch 1147/2000
2025-02-19 04:00:34,033 Current Learning Rate: 0.0083650626
2025-02-19 04:00:34,034 Train Loss: 0.0002930, Val Loss: 0.0003615
2025-02-19 04:00:34,034 Epoch 1148/2000
2025-02-19 04:01:16,362 Current Learning Rate: 0.0084227355
2025-02-19 04:01:16,362 Train Loss: 0.0003442, Val Loss: 0.0004073
2025-02-19 04:01:16,362 Epoch 1149/2000
2025-02-19 04:01:59,011 Current Learning Rate: 0.0084795640
2025-02-19 04:01:59,011 Train Loss: 0.0003440, Val Loss: 0.0003918
2025-02-19 04:01:59,012 Epoch 1150/2000
2025-02-19 04:02:41,427 Current Learning Rate: 0.0085355339
2025-02-19 04:02:41,427 Train Loss: 0.0004297, Val Loss: 0.0004923
2025-02-19 04:02:41,427 Epoch 1151/2000
2025-02-19 04:03:23,620 Current Learning Rate: 0.0085906315
2025-02-19 04:03:23,621 Train Loss: 0.0004179, Val Loss: 0.0004456
2025-02-19 04:03:23,621 Epoch 1152/2000
2025-02-19 04:04:05,571 Current Learning Rate: 0.0086448431
2025-02-19 04:04:05,571 Train Loss: 0.0003730, Val Loss: 0.0003580
2025-02-19 04:04:05,572 Epoch 1153/2000
2025-02-19 04:04:48,461 Current Learning Rate: 0.0086981555
2025-02-19 04:04:48,462 Train Loss: 0.0002873, Val Loss: 0.0003592
2025-02-19 04:04:48,462 Epoch 1154/2000
2025-02-19 04:05:31,528 Current Learning Rate: 0.0087505553
2025-02-19 04:05:31,528 Train Loss: 0.0002449, Val Loss: 0.0003035
2025-02-19 04:05:31,528 Epoch 1155/2000
2025-02-19 04:06:14,439 Current Learning Rate: 0.0088020298
2025-02-19 04:06:14,440 Train Loss: 0.0002925, Val Loss: 0.0003313
2025-02-19 04:06:14,440 Epoch 1156/2000
2025-02-19 04:06:56,342 Current Learning Rate: 0.0088525662
2025-02-19 04:06:56,343 Train Loss: 0.0003326, Val Loss: 0.0003231
2025-02-19 04:06:56,344 Epoch 1157/2000
2025-02-19 04:07:38,896 Current Learning Rate: 0.0089021520
2025-02-19 04:07:38,897 Train Loss: 0.0002309, Val Loss: 0.0003207
2025-02-19 04:07:38,897 Epoch 1158/2000
2025-02-19 04:08:21,764 Current Learning Rate: 0.0089507751
2025-02-19 04:08:21,765 Train Loss: 0.0003062, Val Loss: 0.0003277
2025-02-19 04:08:21,765 Epoch 1159/2000
2025-02-19 04:09:04,089 Current Learning Rate: 0.0089984233
2025-02-19 04:09:04,089 Train Loss: 0.0003627, Val Loss: 0.0003142
2025-02-19 04:09:04,090 Epoch 1160/2000
2025-02-19 04:09:46,154 Current Learning Rate: 0.0090450850
2025-02-19 04:09:46,155 Train Loss: 0.0002264, Val Loss: 0.0003045
2025-02-19 04:09:46,155 Epoch 1161/2000
2025-02-19 04:10:29,378 Current Learning Rate: 0.0090907486
2025-02-19 04:10:29,379 Train Loss: 0.0002137, Val Loss: 0.0003212
2025-02-19 04:10:29,379 Epoch 1162/2000
2025-02-19 04:11:12,475 Current Learning Rate: 0.0091354029
2025-02-19 04:11:12,475 Train Loss: 0.0002972, Val Loss: 0.0003439
2025-02-19 04:11:12,476 Epoch 1163/2000
2025-02-19 04:11:55,531 Current Learning Rate: 0.0091790368
2025-02-19 04:11:55,532 Train Loss: 0.0003241, Val Loss: 0.0003683
2025-02-19 04:11:55,532 Epoch 1164/2000
2025-02-19 04:12:38,417 Current Learning Rate: 0.0092216396
2025-02-19 04:12:38,417 Train Loss: 0.0002868, Val Loss: 0.0003638
2025-02-19 04:12:38,418 Epoch 1165/2000
2025-02-19 04:13:20,180 Current Learning Rate: 0.0092632008
2025-02-19 04:13:20,181 Train Loss: 0.0002849, Val Loss: 0.0003661
2025-02-19 04:13:20,181 Epoch 1166/2000
2025-02-19 04:14:02,579 Current Learning Rate: 0.0093037101
2025-02-19 04:14:02,579 Train Loss: 0.0003597, Val Loss: 0.0003550
2025-02-19 04:14:02,579 Epoch 1167/2000
2025-02-19 04:14:44,887 Current Learning Rate: 0.0093431576
2025-02-19 04:14:44,888 Train Loss: 0.0003497, Val Loss: 0.0003689
2025-02-19 04:14:44,888 Epoch 1168/2000
2025-02-19 04:15:27,353 Current Learning Rate: 0.0093815334
2025-02-19 04:15:27,353 Train Loss: 0.0004312, Val Loss: 0.0004013
2025-02-19 04:15:27,354 Epoch 1169/2000
2025-02-19 04:16:10,783 Current Learning Rate: 0.0094188282
2025-02-19 04:16:10,783 Train Loss: 0.0003465, Val Loss: 0.0003921
2025-02-19 04:16:10,784 Epoch 1170/2000
2025-02-19 04:16:53,638 Current Learning Rate: 0.0094550326
2025-02-19 04:16:53,639 Train Loss: 0.0002985, Val Loss: 0.0004199
2025-02-19 04:16:53,639 Epoch 1171/2000
2025-02-19 04:17:36,038 Current Learning Rate: 0.0094901379
2025-02-19 04:17:36,038 Train Loss: 0.0003318, Val Loss: 0.0004006
2025-02-19 04:17:36,039 Epoch 1172/2000
2025-02-19 04:18:18,977 Current Learning Rate: 0.0095241353
2025-02-19 04:18:18,978 Train Loss: 0.0003520, Val Loss: 0.0003934
2025-02-19 04:18:18,978 Epoch 1173/2000
2025-02-19 04:19:01,318 Current Learning Rate: 0.0095570164
2025-02-19 04:19:01,319 Train Loss: 0.0004049, Val Loss: 0.0004106
2025-02-19 04:19:01,319 Epoch 1174/2000
2025-02-19 04:19:43,869 Current Learning Rate: 0.0095887731
2025-02-19 04:19:43,870 Train Loss: 0.0004068, Val Loss: 0.0004243
2025-02-19 04:19:43,870 Epoch 1175/2000
2025-02-19 04:20:26,761 Current Learning Rate: 0.0096193977
2025-02-19 04:20:26,762 Train Loss: 0.0003134, Val Loss: 0.0003380
2025-02-19 04:20:26,762 Epoch 1176/2000
2025-02-19 04:21:10,058 Current Learning Rate: 0.0096488824
2025-02-19 04:21:10,059 Train Loss: 0.0002539, Val Loss: 0.0003542
2025-02-19 04:21:10,059 Epoch 1177/2000
2025-02-19 04:21:53,368 Current Learning Rate: 0.0096772202
2025-02-19 04:21:53,369 Train Loss: 0.0002805, Val Loss: 0.0004002
2025-02-19 04:21:53,369 Epoch 1178/2000
2025-02-19 04:22:36,593 Current Learning Rate: 0.0097044038
2025-02-19 04:22:36,594 Train Loss: 0.0003524, Val Loss: 0.0004084
2025-02-19 04:22:36,594 Epoch 1179/2000
2025-02-19 04:23:20,162 Current Learning Rate: 0.0097304268
2025-02-19 04:23:20,162 Train Loss: 0.0004537, Val Loss: 0.0004119
2025-02-19 04:23:20,163 Epoch 1180/2000
2025-02-19 04:24:03,971 Current Learning Rate: 0.0097552826
2025-02-19 04:24:03,972 Train Loss: 0.0003992, Val Loss: 0.0004051
2025-02-19 04:24:03,972 Epoch 1181/2000
2025-02-19 04:24:45,864 Current Learning Rate: 0.0097789651
2025-02-19 04:24:45,865 Train Loss: 0.0003883, Val Loss: 0.0003950
2025-02-19 04:24:45,865 Epoch 1182/2000
2025-02-19 04:25:28,523 Current Learning Rate: 0.0098014684
2025-02-19 04:25:28,524 Train Loss: 0.0003235, Val Loss: 0.0003632
2025-02-19 04:25:28,524 Epoch 1183/2000
2025-02-19 04:26:12,298 Current Learning Rate: 0.0098227871
2025-02-19 04:26:12,299 Train Loss: 0.0002952, Val Loss: 0.0003477
2025-02-19 04:26:12,299 Epoch 1184/2000
2025-02-19 04:26:54,488 Current Learning Rate: 0.0098429158
2025-02-19 04:26:54,489 Train Loss: 0.0002845, Val Loss: 0.0003347
2025-02-19 04:26:54,489 Epoch 1185/2000
2025-02-19 04:27:37,628 Current Learning Rate: 0.0098618496
2025-02-19 04:27:37,628 Train Loss: 0.0002304, Val Loss: 0.0003176
2025-02-19 04:27:37,629 Epoch 1186/2000
2025-02-19 04:28:20,967 Current Learning Rate: 0.0098795838
2025-02-19 04:28:20,968 Train Loss: 0.0003224, Val Loss: 0.0004063
2025-02-19 04:28:20,968 Epoch 1187/2000
2025-02-19 04:29:03,176 Current Learning Rate: 0.0098961141
2025-02-19 04:29:03,177 Train Loss: 0.0003911, Val Loss: 0.0003631
2025-02-19 04:29:03,177 Epoch 1188/2000
2025-02-19 04:29:46,280 Current Learning Rate: 0.0099114363
2025-02-19 04:29:46,280 Train Loss: 0.0002728, Val Loss: 0.0003342
2025-02-19 04:29:46,281 Epoch 1189/2000
2025-02-19 04:30:28,980 Current Learning Rate: 0.0099255466
2025-02-19 04:30:28,980 Train Loss: 0.0003905, Val Loss: 0.0004208
2025-02-19 04:30:28,981 Epoch 1190/2000
2025-02-19 04:31:12,058 Current Learning Rate: 0.0099384417
2025-02-19 04:31:12,060 Train Loss: 0.0004146, Val Loss: 0.0005108
2025-02-19 04:31:12,061 Epoch 1191/2000
2025-02-19 04:31:54,883 Current Learning Rate: 0.0099501183
2025-02-19 04:31:54,883 Train Loss: 0.0003339, Val Loss: 0.0004398
2025-02-19 04:31:54,883 Epoch 1192/2000
2025-02-19 04:32:37,650 Current Learning Rate: 0.0099605735
2025-02-19 04:32:37,651 Train Loss: 0.0005730, Val Loss: 0.0007198
2025-02-19 04:32:37,651 Epoch 1193/2000
2025-02-19 04:33:20,077 Current Learning Rate: 0.0099698048
2025-02-19 04:33:20,078 Train Loss: 0.0005289, Val Loss: 0.0015931
2025-02-19 04:33:20,079 Epoch 1194/2000
2025-02-19 04:34:02,892 Current Learning Rate: 0.0099778098
2025-02-19 04:34:02,893 Train Loss: 0.0008597, Val Loss: 0.0004949
2025-02-19 04:34:02,893 Epoch 1195/2000
2025-02-19 04:34:45,305 Current Learning Rate: 0.0099845867
2025-02-19 04:34:45,306 Train Loss: 0.0003657, Val Loss: 0.0004646
2025-02-19 04:34:45,306 Epoch 1196/2000
2025-02-19 04:35:27,921 Current Learning Rate: 0.0099901336
2025-02-19 04:35:27,922 Train Loss: 0.0003482, Val Loss: 0.0003574
2025-02-19 04:35:27,922 Epoch 1197/2000
2025-02-19 04:36:11,019 Current Learning Rate: 0.0099944494
2025-02-19 04:36:11,019 Train Loss: 0.0003333, Val Loss: 0.0004034
2025-02-19 04:36:11,020 Epoch 1198/2000
2025-02-19 04:36:54,726 Current Learning Rate: 0.0099975328
2025-02-19 04:36:54,726 Train Loss: 0.0002702, Val Loss: 0.0003077
2025-02-19 04:36:54,726 Epoch 1199/2000
2025-02-19 04:37:38,170 Current Learning Rate: 0.0099993832
2025-02-19 04:37:38,171 Train Loss: 0.0003345, Val Loss: 0.0003255
2025-02-19 04:37:38,171 Epoch 1200/2000
2025-02-19 04:38:21,367 Current Learning Rate: 0.0100000000
2025-02-19 04:38:21,368 Train Loss: 0.0003558, Val Loss: 0.0004124
2025-02-19 04:38:21,368 Epoch 1201/2000
2025-02-19 04:39:04,828 Current Learning Rate: 0.0099993832
2025-02-19 04:39:04,829 Train Loss: 0.0003815, Val Loss: 0.0003488
2025-02-19 04:39:04,829 Epoch 1202/2000
2025-02-19 04:39:46,715 Current Learning Rate: 0.0099975328
2025-02-19 04:39:46,716 Train Loss: 0.0002571, Val Loss: 0.0002980
2025-02-19 04:39:46,716 Epoch 1203/2000
2025-02-19 04:40:29,629 Current Learning Rate: 0.0099944494
2025-02-19 04:40:29,630 Train Loss: 0.0004342, Val Loss: 0.0003882
2025-02-19 04:40:29,630 Epoch 1204/2000
2025-02-19 04:41:12,975 Current Learning Rate: 0.0099901336
2025-02-19 04:41:12,975 Train Loss: 0.0003849, Val Loss: 0.0003566
2025-02-19 04:41:12,975 Epoch 1205/2000
2025-02-19 04:41:56,128 Current Learning Rate: 0.0099845867
2025-02-19 04:41:56,129 Train Loss: 0.0003055, Val Loss: 0.0003039
2025-02-19 04:41:56,129 Epoch 1206/2000
2025-02-19 04:42:39,641 Current Learning Rate: 0.0099778098
2025-02-19 04:42:39,642 Train Loss: 0.0003043, Val Loss: 0.0003126
2025-02-19 04:42:39,643 Epoch 1207/2000
2025-02-19 04:43:22,620 Current Learning Rate: 0.0099698048
2025-02-19 04:43:22,620 Train Loss: 0.0002716, Val Loss: 0.0003041
2025-02-19 04:43:22,621 Epoch 1208/2000
2025-02-19 04:44:05,795 Current Learning Rate: 0.0099605735
2025-02-19 04:44:05,795 Train Loss: 0.0002467, Val Loss: 0.0002967
2025-02-19 04:44:05,796 Epoch 1209/2000
2025-02-19 04:44:48,574 Current Learning Rate: 0.0099501183
2025-02-19 04:44:48,575 Train Loss: 0.0002712, Val Loss: 0.0002819
2025-02-19 04:44:48,575 Epoch 1210/2000
2025-02-19 04:45:31,934 Current Learning Rate: 0.0099384417
2025-02-19 04:45:31,935 Train Loss: 0.0002193, Val Loss: 0.0002984
2025-02-19 04:45:31,935 Epoch 1211/2000
2025-02-19 04:46:15,185 Current Learning Rate: 0.0099255466
2025-02-19 04:46:15,186 Train Loss: 0.0002582, Val Loss: 0.0003117
2025-02-19 04:46:15,186 Epoch 1212/2000
2025-02-19 04:46:58,076 Current Learning Rate: 0.0099114363
2025-02-19 04:46:58,077 Train Loss: 0.0003287, Val Loss: 0.0004310
2025-02-19 04:46:58,077 Epoch 1213/2000
2025-02-19 04:47:40,225 Current Learning Rate: 0.0098961141
2025-02-19 04:47:40,225 Train Loss: 0.0002960, Val Loss: 0.0003451
2025-02-19 04:47:40,225 Epoch 1214/2000
2025-02-19 04:48:22,323 Current Learning Rate: 0.0098795838
2025-02-19 04:48:22,324 Train Loss: 0.0003305, Val Loss: 0.0003503
2025-02-19 04:48:22,324 Epoch 1215/2000
2025-02-19 04:49:04,692 Current Learning Rate: 0.0098618496
2025-02-19 04:49:04,692 Train Loss: 0.0003031, Val Loss: 0.0003275
2025-02-19 04:49:04,692 Epoch 1216/2000
2025-02-19 04:49:47,698 Current Learning Rate: 0.0098429158
2025-02-19 04:49:47,699 Train Loss: 0.0003185, Val Loss: 0.0003507
2025-02-19 04:49:47,699 Epoch 1217/2000
2025-02-19 04:50:29,853 Current Learning Rate: 0.0098227871
2025-02-19 04:50:29,854 Train Loss: 0.0003555, Val Loss: 0.0003752
2025-02-19 04:50:29,854 Epoch 1218/2000
2025-02-19 04:51:11,832 Current Learning Rate: 0.0098014684
2025-02-19 04:51:11,832 Train Loss: 0.0003265, Val Loss: 0.0003389
2025-02-19 04:51:11,833 Epoch 1219/2000
2025-02-19 04:51:55,207 Current Learning Rate: 0.0097789651
2025-02-19 04:51:55,208 Train Loss: 0.0002837, Val Loss: 0.0003092
2025-02-19 04:51:55,208 Epoch 1220/2000
2025-02-19 04:52:37,705 Current Learning Rate: 0.0097552826
2025-02-19 04:52:37,706 Train Loss: 0.0002819, Val Loss: 0.0003282
2025-02-19 04:52:37,706 Epoch 1221/2000
2025-02-19 04:53:20,546 Current Learning Rate: 0.0097304268
2025-02-19 04:53:20,546 Train Loss: 0.0003215, Val Loss: 0.0003409
2025-02-19 04:53:20,547 Epoch 1222/2000
2025-02-19 04:54:02,502 Current Learning Rate: 0.0097044038
2025-02-19 04:54:02,503 Train Loss: 0.0002931, Val Loss: 0.0002935
2025-02-19 04:54:02,503 Epoch 1223/2000
2025-02-19 04:54:45,153 Current Learning Rate: 0.0096772202
2025-02-19 04:54:45,154 Train Loss: 0.0002800, Val Loss: 0.0003279
2025-02-19 04:54:45,154 Epoch 1224/2000
2025-02-19 04:55:27,369 Current Learning Rate: 0.0096488824
2025-02-19 04:55:27,369 Train Loss: 0.0002484, Val Loss: 0.0003220
2025-02-19 04:55:27,369 Epoch 1225/2000
2025-02-19 04:56:09,613 Current Learning Rate: 0.0096193977
2025-02-19 04:56:09,613 Train Loss: 0.0002307, Val Loss: 0.0002847
2025-02-19 04:56:09,613 Epoch 1226/2000
2025-02-19 04:56:51,489 Current Learning Rate: 0.0095887731
2025-02-19 04:56:51,489 Train Loss: 0.0003054, Val Loss: 0.0003279
2025-02-19 04:56:51,490 Epoch 1227/2000
2025-02-19 04:57:34,015 Current Learning Rate: 0.0095570164
2025-02-19 04:57:34,016 Train Loss: 0.0002774, Val Loss: 0.0003250
2025-02-19 04:57:34,016 Epoch 1228/2000
2025-02-19 04:58:17,051 Current Learning Rate: 0.0095241353
2025-02-19 04:58:17,051 Train Loss: 0.0002541, Val Loss: 0.0002957
2025-02-19 04:58:17,052 Epoch 1229/2000
2025-02-19 04:58:58,955 Current Learning Rate: 0.0094901379
2025-02-19 04:58:58,956 Train Loss: 0.0003336, Val Loss: 0.0003201
2025-02-19 04:58:58,956 Epoch 1230/2000
2025-02-19 04:59:41,074 Current Learning Rate: 0.0094550326
2025-02-19 04:59:41,075 Train Loss: 0.0002789, Val Loss: 0.0003138
2025-02-19 04:59:41,075 Epoch 1231/2000
2025-02-19 05:00:23,194 Current Learning Rate: 0.0094188282
2025-02-19 05:00:23,195 Train Loss: 0.0002877, Val Loss: 0.0003305
2025-02-19 05:00:23,195 Epoch 1232/2000
2025-02-19 05:01:05,466 Current Learning Rate: 0.0093815334
2025-02-19 05:01:05,467 Train Loss: 0.0002423, Val Loss: 0.0003018
2025-02-19 05:01:05,467 Epoch 1233/2000
2025-02-19 05:01:48,507 Current Learning Rate: 0.0093431576
2025-02-19 05:01:48,508 Train Loss: 0.0003048, Val Loss: 0.0003066
2025-02-19 05:01:48,508 Epoch 1234/2000
2025-02-19 05:02:31,691 Current Learning Rate: 0.0093037101
2025-02-19 05:02:31,692 Train Loss: 0.0003971, Val Loss: 0.0003299
2025-02-19 05:02:31,692 Epoch 1235/2000
2025-02-19 05:03:14,686 Current Learning Rate: 0.0092632008
2025-02-19 05:03:14,686 Train Loss: 0.0002575, Val Loss: 0.0003031
2025-02-19 05:03:14,686 Epoch 1236/2000
2025-02-19 05:03:57,696 Current Learning Rate: 0.0092216396
2025-02-19 05:03:57,697 Train Loss: 0.0002736, Val Loss: 0.0002998
2025-02-19 05:03:57,697 Epoch 1237/2000
2025-02-19 05:04:40,840 Current Learning Rate: 0.0091790368
2025-02-19 05:04:40,841 Train Loss: 0.0002595, Val Loss: 0.0002812
2025-02-19 05:04:40,841 Epoch 1238/2000
2025-02-19 05:05:23,497 Current Learning Rate: 0.0091354029
2025-02-19 05:05:23,497 Train Loss: 0.0003125, Val Loss: 0.0002800
2025-02-19 05:05:23,497 Epoch 1239/2000
2025-02-19 05:06:05,663 Current Learning Rate: 0.0090907486
2025-02-19 05:06:05,663 Train Loss: 0.0002220, Val Loss: 0.0002693
2025-02-19 05:06:05,664 Epoch 1240/2000
2025-02-19 05:06:48,578 Current Learning Rate: 0.0090450850
2025-02-19 05:06:48,578 Train Loss: 0.0002700, Val Loss: 0.0002810
2025-02-19 05:06:48,578 Epoch 1241/2000
2025-02-19 05:07:31,256 Current Learning Rate: 0.0089984233
2025-02-19 05:07:31,257 Train Loss: 0.0002639, Val Loss: 0.0002961
2025-02-19 05:07:31,257 Epoch 1242/2000
2025-02-19 05:08:13,969 Current Learning Rate: 0.0089507751
2025-02-19 05:08:13,969 Train Loss: 0.0002100, Val Loss: 0.0002593
2025-02-19 05:08:13,970 Epoch 1243/2000
2025-02-19 05:08:56,921 Current Learning Rate: 0.0089021520
2025-02-19 05:08:56,922 Train Loss: 0.0002544, Val Loss: 0.0002705
2025-02-19 05:08:56,922 Epoch 1244/2000
2025-02-19 05:09:39,700 Current Learning Rate: 0.0088525662
2025-02-19 05:09:39,701 Train Loss: 0.0002683, Val Loss: 0.0003015
2025-02-19 05:09:39,701 Epoch 1245/2000
2025-02-19 05:10:21,818 Current Learning Rate: 0.0088020298
2025-02-19 05:10:21,819 Train Loss: 0.0002700, Val Loss: 0.0002721
2025-02-19 05:10:21,819 Epoch 1246/2000
2025-02-19 05:11:05,185 Current Learning Rate: 0.0087505553
2025-02-19 05:11:05,186 Train Loss: 0.0002013, Val Loss: 0.0002730
2025-02-19 05:11:05,186 Epoch 1247/2000
2025-02-19 05:11:47,303 Current Learning Rate: 0.0086981555
2025-02-19 05:11:47,303 Train Loss: 0.0002540, Val Loss: 0.0002971
2025-02-19 05:11:47,303 Epoch 1248/2000
2025-02-19 05:12:29,779 Current Learning Rate: 0.0086448431
2025-02-19 05:12:29,780 Train Loss: 0.0002141, Val Loss: 0.0003020
2025-02-19 05:12:29,780 Epoch 1249/2000
2025-02-19 05:13:12,511 Current Learning Rate: 0.0085906315
2025-02-19 05:13:12,512 Train Loss: 0.0002372, Val Loss: 0.0002926
2025-02-19 05:13:12,512 Epoch 1250/2000
2025-02-19 05:13:55,191 Current Learning Rate: 0.0085355339
2025-02-19 05:13:55,192 Train Loss: 0.0002058, Val Loss: 0.0002994
2025-02-19 05:13:55,192 Epoch 1251/2000
2025-02-19 05:14:38,081 Current Learning Rate: 0.0084795640
2025-02-19 05:14:38,081 Train Loss: 0.0002717, Val Loss: 0.0003850
2025-02-19 05:14:38,081 Epoch 1252/2000
2025-02-19 05:15:20,883 Current Learning Rate: 0.0084227355
2025-02-19 05:15:20,884 Train Loss: 0.0003723, Val Loss: 0.0003072
2025-02-19 05:15:20,884 Epoch 1253/2000
2025-02-19 05:16:03,321 Current Learning Rate: 0.0083650626
2025-02-19 05:16:03,322 Train Loss: 0.0002526, Val Loss: 0.0002829
2025-02-19 05:16:03,322 Epoch 1254/2000
2025-02-19 05:16:46,013 Current Learning Rate: 0.0083065593
2025-02-19 05:16:46,014 Train Loss: 0.0002701, Val Loss: 0.0002778
2025-02-19 05:16:46,014 Epoch 1255/2000
2025-02-19 05:17:29,029 Current Learning Rate: 0.0082472402
2025-02-19 05:17:29,030 Train Loss: 0.0002764, Val Loss: 0.0003050
2025-02-19 05:17:29,030 Epoch 1256/2000
2025-02-19 05:18:11,815 Current Learning Rate: 0.0081871199
2025-02-19 05:18:11,816 Train Loss: 0.0002992, Val Loss: 0.0003072
2025-02-19 05:18:11,816 Epoch 1257/2000
2025-02-19 05:18:53,883 Current Learning Rate: 0.0081262133
2025-02-19 05:18:53,884 Train Loss: 0.0002123, Val Loss: 0.0003024
2025-02-19 05:18:53,884 Epoch 1258/2000
2025-02-19 05:19:36,873 Current Learning Rate: 0.0080645353
2025-02-19 05:19:36,873 Train Loss: 0.0002702, Val Loss: 0.0003362
2025-02-19 05:19:36,874 Epoch 1259/2000
2025-02-19 05:20:18,817 Current Learning Rate: 0.0080021011
2025-02-19 05:20:18,818 Train Loss: 0.0002418, Val Loss: 0.0003292
2025-02-19 05:20:18,818 Epoch 1260/2000
2025-02-19 05:21:01,479 Current Learning Rate: 0.0079389263
2025-02-19 05:21:01,480 Train Loss: 0.0002907, Val Loss: 0.0003881
2025-02-19 05:21:01,480 Epoch 1261/2000
2025-02-19 05:21:44,416 Current Learning Rate: 0.0078750263
2025-02-19 05:21:44,417 Train Loss: 0.0003452, Val Loss: 0.0003645
2025-02-19 05:21:44,417 Epoch 1262/2000
2025-02-19 05:22:26,910 Current Learning Rate: 0.0078104169
2025-02-19 05:22:26,911 Train Loss: 0.0003222, Val Loss: 0.0003064
2025-02-19 05:22:26,911 Epoch 1263/2000
2025-02-19 05:23:09,809 Current Learning Rate: 0.0077451141
2025-02-19 05:23:09,809 Train Loss: 0.0002808, Val Loss: 0.0002959
2025-02-19 05:23:09,810 Epoch 1264/2000
2025-02-19 05:23:51,636 Current Learning Rate: 0.0076791340
2025-02-19 05:23:51,636 Train Loss: 0.0002716, Val Loss: 0.0002927
2025-02-19 05:23:51,636 Epoch 1265/2000
2025-02-19 05:24:34,551 Current Learning Rate: 0.0076124928
2025-02-19 05:24:34,552 Train Loss: 0.0002731, Val Loss: 0.0002681
2025-02-19 05:24:34,552 Epoch 1266/2000
2025-02-19 05:25:17,697 Current Learning Rate: 0.0075452071
2025-02-19 05:25:17,698 Train Loss: 0.0002551, Val Loss: 0.0002604
2025-02-19 05:25:17,698 Epoch 1267/2000
2025-02-19 05:26:00,820 Current Learning Rate: 0.0074772933
2025-02-19 05:26:00,821 Train Loss: 0.0002330, Val Loss: 0.0002588
2025-02-19 05:26:00,821 Epoch 1268/2000
2025-02-19 05:26:42,966 Current Learning Rate: 0.0074087684
2025-02-19 05:26:42,967 Train Loss: 0.0002070, Val Loss: 0.0002747
2025-02-19 05:26:42,967 Epoch 1269/2000
2025-02-19 05:27:24,943 Current Learning Rate: 0.0073396491
2025-02-19 05:27:24,944 Train Loss: 0.0002312, Val Loss: 0.0002729
2025-02-19 05:27:24,944 Epoch 1270/2000
2025-02-19 05:28:07,090 Current Learning Rate: 0.0072699525
2025-02-19 05:28:07,090 Train Loss: 0.0002523, Val Loss: 0.0002654
2025-02-19 05:28:07,091 Epoch 1271/2000
2025-02-19 05:28:50,043 Current Learning Rate: 0.0071996958
2025-02-19 05:28:50,044 Train Loss: 0.0001803, Val Loss: 0.0002642
2025-02-19 05:28:50,044 Epoch 1272/2000
2025-02-19 05:29:31,973 Current Learning Rate: 0.0071288965
2025-02-19 05:29:31,975 Train Loss: 0.0002394, Val Loss: 0.0002683
2025-02-19 05:29:31,976 Epoch 1273/2000
2025-02-19 05:30:15,230 Current Learning Rate: 0.0070575718
2025-02-19 05:30:15,248 Train Loss: 0.0002191, Val Loss: 0.0002703
2025-02-19 05:30:15,249 Epoch 1274/2000
2025-02-19 05:30:58,431 Current Learning Rate: 0.0069857395
2025-02-19 05:30:58,432 Train Loss: 0.0002086, Val Loss: 0.0002544
2025-02-19 05:30:58,432 Epoch 1275/2000
2025-02-19 05:31:40,594 Current Learning Rate: 0.0069134172
2025-02-19 05:31:40,595 Train Loss: 0.0002234, Val Loss: 0.0002655
2025-02-19 05:31:40,595 Epoch 1276/2000
2025-02-19 05:32:23,008 Current Learning Rate: 0.0068406228
2025-02-19 05:32:23,009 Train Loss: 0.0002214, Val Loss: 0.0003035
2025-02-19 05:32:23,011 Epoch 1277/2000
2025-02-19 05:33:06,259 Current Learning Rate: 0.0067673742
2025-02-19 05:33:06,259 Train Loss: 0.0002642, Val Loss: 0.0003223
2025-02-19 05:33:06,259 Epoch 1278/2000
2025-02-19 05:33:49,250 Current Learning Rate: 0.0066936896
2025-02-19 05:33:49,250 Train Loss: 0.0002282, Val Loss: 0.0002573
2025-02-19 05:33:49,251 Epoch 1279/2000
2025-02-19 05:34:31,878 Current Learning Rate: 0.0066195871
2025-02-19 05:34:31,879 Train Loss: 0.0002282, Val Loss: 0.0002570
2025-02-19 05:34:31,879 Epoch 1280/2000
2025-02-19 05:35:14,927 Current Learning Rate: 0.0065450850
2025-02-19 05:35:16,499 Train Loss: 0.0001579, Val Loss: 0.0002373
2025-02-19 05:35:16,499 Epoch 1281/2000
2025-02-19 05:35:57,624 Current Learning Rate: 0.0064702016
2025-02-19 05:35:57,625 Train Loss: 0.0002475, Val Loss: 0.0002616
2025-02-19 05:35:57,625 Epoch 1282/2000
2025-02-19 05:36:41,147 Current Learning Rate: 0.0063949555
2025-02-19 05:36:41,148 Train Loss: 0.0002361, Val Loss: 0.0002520
2025-02-19 05:36:41,148 Epoch 1283/2000
2025-02-19 05:37:24,309 Current Learning Rate: 0.0063193652
2025-02-19 05:37:24,310 Train Loss: 0.0001925, Val Loss: 0.0002398
2025-02-19 05:37:24,310 Epoch 1284/2000
2025-02-19 05:38:07,087 Current Learning Rate: 0.0062434494
2025-02-19 05:38:07,088 Train Loss: 0.0002231, Val Loss: 0.0002411
2025-02-19 05:38:07,088 Epoch 1285/2000
2025-02-19 05:38:50,004 Current Learning Rate: 0.0061672268
2025-02-19 05:38:50,004 Train Loss: 0.0002115, Val Loss: 0.0002465
2025-02-19 05:38:50,007 Epoch 1286/2000
2025-02-19 05:39:33,379 Current Learning Rate: 0.0060907162
2025-02-19 05:39:33,380 Train Loss: 0.0002359, Val Loss: 0.0002487
2025-02-19 05:39:33,380 Epoch 1287/2000
2025-02-19 05:40:15,829 Current Learning Rate: 0.0060139365
2025-02-19 05:40:15,829 Train Loss: 0.0001992, Val Loss: 0.0002509
2025-02-19 05:40:15,830 Epoch 1288/2000
2025-02-19 05:40:59,004 Current Learning Rate: 0.0059369066
2025-02-19 05:40:59,005 Train Loss: 0.0001793, Val Loss: 0.0002589
2025-02-19 05:40:59,005 Epoch 1289/2000
2025-02-19 05:41:41,574 Current Learning Rate: 0.0058596455
2025-02-19 05:41:41,575 Train Loss: 0.0002360, Val Loss: 0.0002491
2025-02-19 05:41:41,575 Epoch 1290/2000
2025-02-19 05:42:24,093 Current Learning Rate: 0.0057821723
2025-02-19 05:42:24,094 Train Loss: 0.0002294, Val Loss: 0.0002512
2025-02-19 05:42:24,094 Epoch 1291/2000
2025-02-19 05:43:06,658 Current Learning Rate: 0.0057045062
2025-02-19 05:43:06,659 Train Loss: 0.0002405, Val Loss: 0.0002643
2025-02-19 05:43:06,659 Epoch 1292/2000
2025-02-19 05:43:49,847 Current Learning Rate: 0.0056266662
2025-02-19 05:43:49,848 Train Loss: 0.0002038, Val Loss: 0.0002624
2025-02-19 05:43:49,849 Epoch 1293/2000
2025-02-19 05:44:32,539 Current Learning Rate: 0.0055486716
2025-02-19 05:44:32,540 Train Loss: 0.0002392, Val Loss: 0.0002590
2025-02-19 05:44:32,540 Epoch 1294/2000
2025-02-19 05:45:15,826 Current Learning Rate: 0.0054705416
2025-02-19 05:45:15,827 Train Loss: 0.0002009, Val Loss: 0.0002517
2025-02-19 05:45:15,827 Epoch 1295/2000
2025-02-19 05:45:59,245 Current Learning Rate: 0.0053922955
2025-02-19 05:45:59,246 Train Loss: 0.0002074, Val Loss: 0.0002411
2025-02-19 05:45:59,247 Epoch 1296/2000
2025-02-19 05:46:42,238 Current Learning Rate: 0.0053139526
2025-02-19 05:46:42,238 Train Loss: 0.0002000, Val Loss: 0.0002422
2025-02-19 05:46:42,238 Epoch 1297/2000
2025-02-19 05:47:25,482 Current Learning Rate: 0.0052355323
2025-02-19 05:47:25,483 Train Loss: 0.0001729, Val Loss: 0.0002510
2025-02-19 05:47:25,483 Epoch 1298/2000
2025-02-19 05:48:08,457 Current Learning Rate: 0.0051570538
2025-02-19 05:48:08,457 Train Loss: 0.0002268, Val Loss: 0.0002501
2025-02-19 05:48:08,458 Epoch 1299/2000
2025-02-19 05:48:51,758 Current Learning Rate: 0.0050785366
2025-02-19 05:48:51,759 Train Loss: 0.0002405, Val Loss: 0.0002444
2025-02-19 05:48:51,759 Epoch 1300/2000
2025-02-19 05:49:34,470 Current Learning Rate: 0.0050000000
2025-02-19 05:49:34,470 Train Loss: 0.0002857, Val Loss: 0.0002506
2025-02-19 05:49:34,471 Epoch 1301/2000
2025-02-19 05:50:16,815 Current Learning Rate: 0.0049214634
2025-02-19 05:50:16,815 Train Loss: 0.0002398, Val Loss: 0.0002415
2025-02-19 05:50:16,816 Epoch 1302/2000
2025-02-19 05:50:59,622 Current Learning Rate: 0.0048429462
2025-02-19 05:51:01,082 Train Loss: 0.0002251, Val Loss: 0.0002352
2025-02-19 05:51:01,083 Epoch 1303/2000
2025-02-19 05:51:44,258 Current Learning Rate: 0.0047644677
2025-02-19 05:51:46,001 Train Loss: 0.0001888, Val Loss: 0.0002289
2025-02-19 05:51:46,003 Epoch 1304/2000
2025-02-19 05:52:27,774 Current Learning Rate: 0.0046860474
2025-02-19 05:52:27,776 Train Loss: 0.0001850, Val Loss: 0.0002353
2025-02-19 05:52:27,776 Epoch 1305/2000
2025-02-19 05:53:10,985 Current Learning Rate: 0.0046077045
2025-02-19 05:53:10,986 Train Loss: 0.0002298, Val Loss: 0.0002313
2025-02-19 05:53:10,986 Epoch 1306/2000
2025-02-19 05:53:54,132 Current Learning Rate: 0.0045294584
2025-02-19 05:53:54,133 Train Loss: 0.0001596, Val Loss: 0.0002313
2025-02-19 05:53:54,133 Epoch 1307/2000
2025-02-19 05:54:36,532 Current Learning Rate: 0.0044513284
2025-02-19 05:54:36,533 Train Loss: 0.0001983, Val Loss: 0.0002302
2025-02-19 05:54:36,534 Epoch 1308/2000
2025-02-19 05:55:19,006 Current Learning Rate: 0.0043733338
2025-02-19 05:55:19,007 Train Loss: 0.0001755, Val Loss: 0.0002332
2025-02-19 05:55:19,007 Epoch 1309/2000
2025-02-19 05:56:02,230 Current Learning Rate: 0.0042954938
2025-02-19 05:56:02,231 Train Loss: 0.0001757, Val Loss: 0.0002301
2025-02-19 05:56:02,231 Epoch 1310/2000
2025-02-19 05:56:45,651 Current Learning Rate: 0.0042178277
2025-02-19 05:56:45,653 Train Loss: 0.0002220, Val Loss: 0.0002334
2025-02-19 05:56:45,653 Epoch 1311/2000
2025-02-19 05:57:28,071 Current Learning Rate: 0.0041403545
2025-02-19 05:57:28,072 Train Loss: 0.0002170, Val Loss: 0.0002575
2025-02-19 05:57:28,072 Epoch 1312/2000
2025-02-19 05:58:11,618 Current Learning Rate: 0.0040630934
2025-02-19 05:58:11,619 Train Loss: 0.0002336, Val Loss: 0.0002394
2025-02-19 05:58:11,619 Epoch 1313/2000
2025-02-19 05:58:54,646 Current Learning Rate: 0.0039860635
2025-02-19 05:58:54,646 Train Loss: 0.0002126, Val Loss: 0.0002306
2025-02-19 05:58:54,647 Epoch 1314/2000
2025-02-19 05:59:37,271 Current Learning Rate: 0.0039092838
2025-02-19 05:59:38,797 Train Loss: 0.0001485, Val Loss: 0.0002283
2025-02-19 05:59:38,797 Epoch 1315/2000
2025-02-19 06:00:20,352 Current Learning Rate: 0.0038327732
2025-02-19 06:00:21,391 Train Loss: 0.0001845, Val Loss: 0.0002241
2025-02-19 06:00:21,391 Epoch 1316/2000
2025-02-19 06:01:03,445 Current Learning Rate: 0.0037565506
2025-02-19 06:01:04,606 Train Loss: 0.0001865, Val Loss: 0.0002203
2025-02-19 06:01:04,607 Epoch 1317/2000
2025-02-19 06:01:46,459 Current Learning Rate: 0.0036806348
2025-02-19 06:01:48,358 Train Loss: 0.0001609, Val Loss: 0.0002167
2025-02-19 06:01:48,358 Epoch 1318/2000
2025-02-19 06:02:31,373 Current Learning Rate: 0.0036050445
2025-02-19 06:02:33,106 Train Loss: 0.0001382, Val Loss: 0.0002156
2025-02-19 06:02:33,106 Epoch 1319/2000
2025-02-19 06:03:15,809 Current Learning Rate: 0.0035297984
2025-02-19 06:03:15,809 Train Loss: 0.0001949, Val Loss: 0.0002168
2025-02-19 06:03:15,810 Epoch 1320/2000
2025-02-19 06:03:57,648 Current Learning Rate: 0.0034549150
2025-02-19 06:03:59,411 Train Loss: 0.0001356, Val Loss: 0.0002128
2025-02-19 06:03:59,412 Epoch 1321/2000
2025-02-19 06:04:42,236 Current Learning Rate: 0.0033804129
2025-02-19 06:04:42,237 Train Loss: 0.0001599, Val Loss: 0.0002132
2025-02-19 06:04:42,237 Epoch 1322/2000
2025-02-19 06:05:25,157 Current Learning Rate: 0.0033063104
2025-02-19 06:05:26,805 Train Loss: 0.0001727, Val Loss: 0.0002122
2025-02-19 06:05:26,805 Epoch 1323/2000
2025-02-19 06:06:09,337 Current Learning Rate: 0.0032326258
2025-02-19 06:06:09,338 Train Loss: 0.0001787, Val Loss: 0.0002130
2025-02-19 06:06:09,339 Epoch 1324/2000
2025-02-19 06:06:52,146 Current Learning Rate: 0.0031593772
2025-02-19 06:06:53,992 Train Loss: 0.0001712, Val Loss: 0.0002113
2025-02-19 06:06:53,992 Epoch 1325/2000
2025-02-19 06:07:35,329 Current Learning Rate: 0.0030865828
2025-02-19 06:07:35,330 Train Loss: 0.0001806, Val Loss: 0.0002148
2025-02-19 06:07:35,330 Epoch 1326/2000
2025-02-19 06:08:18,518 Current Learning Rate: 0.0030142605
2025-02-19 06:08:18,518 Train Loss: 0.0001908, Val Loss: 0.0002160
2025-02-19 06:08:18,519 Epoch 1327/2000
2025-02-19 06:09:00,577 Current Learning Rate: 0.0029424282
2025-02-19 06:09:00,577 Train Loss: 0.0002026, Val Loss: 0.0002139
2025-02-19 06:09:00,578 Epoch 1328/2000
2025-02-19 06:09:43,062 Current Learning Rate: 0.0028711035
2025-02-19 06:09:44,376 Train Loss: 0.0001698, Val Loss: 0.0002098
2025-02-19 06:09:44,377 Epoch 1329/2000
2025-02-19 06:10:25,957 Current Learning Rate: 0.0028003042
2025-02-19 06:10:25,958 Train Loss: 0.0001617, Val Loss: 0.0002099
2025-02-19 06:10:25,958 Epoch 1330/2000
2025-02-19 06:11:08,271 Current Learning Rate: 0.0027300475
2025-02-19 06:11:10,143 Train Loss: 0.0001564, Val Loss: 0.0002087
2025-02-19 06:11:10,144 Epoch 1331/2000
2025-02-19 06:11:51,439 Current Learning Rate: 0.0026603509
2025-02-19 06:11:51,440 Train Loss: 0.0001679, Val Loss: 0.0002089
2025-02-19 06:11:51,441 Epoch 1332/2000
2025-02-19 06:12:33,918 Current Learning Rate: 0.0025912316
2025-02-19 06:12:33,919 Train Loss: 0.0001998, Val Loss: 0.0002101
2025-02-19 06:12:33,919 Epoch 1333/2000
2025-02-19 06:13:17,183 Current Learning Rate: 0.0025227067
2025-02-19 06:13:17,183 Train Loss: 0.0001545, Val Loss: 0.0002087
2025-02-19 06:13:17,184 Epoch 1334/2000
2025-02-19 06:14:00,313 Current Learning Rate: 0.0024547929
2025-02-19 06:14:02,100 Train Loss: 0.0001540, Val Loss: 0.0002071
2025-02-19 06:14:02,101 Epoch 1335/2000
2025-02-19 06:14:43,470 Current Learning Rate: 0.0023875072
2025-02-19 06:14:45,190 Train Loss: 0.0001462, Val Loss: 0.0002068
2025-02-19 06:14:45,191 Epoch 1336/2000
2025-02-19 06:15:28,107 Current Learning Rate: 0.0023208660
2025-02-19 06:15:29,456 Train Loss: 0.0001739, Val Loss: 0.0002058
2025-02-19 06:15:29,456 Epoch 1337/2000
2025-02-19 06:16:10,649 Current Learning Rate: 0.0022548859
2025-02-19 06:16:11,436 Train Loss: 0.0001912, Val Loss: 0.0002055
2025-02-19 06:16:11,437 Epoch 1338/2000
2025-02-19 06:16:53,713 Current Learning Rate: 0.0021895831
2025-02-19 06:16:53,715 Train Loss: 0.0001450, Val Loss: 0.0002069
2025-02-19 06:16:53,715 Epoch 1339/2000
2025-02-19 06:17:35,730 Current Learning Rate: 0.0021249737
2025-02-19 06:17:36,643 Train Loss: 0.0001487, Val Loss: 0.0002048
2025-02-19 06:17:36,643 Epoch 1340/2000
2025-02-19 06:18:18,130 Current Learning Rate: 0.0020610737
2025-02-19 06:18:19,300 Train Loss: 0.0001350, Val Loss: 0.0002045
2025-02-19 06:18:19,301 Epoch 1341/2000
2025-02-19 06:19:02,143 Current Learning Rate: 0.0019978989
2025-02-19 06:19:02,144 Train Loss: 0.0001432, Val Loss: 0.0002045
2025-02-19 06:19:02,144 Epoch 1342/2000
2025-02-19 06:19:45,023 Current Learning Rate: 0.0019354647
2025-02-19 06:19:46,467 Train Loss: 0.0001644, Val Loss: 0.0002041
2025-02-19 06:19:46,467 Epoch 1343/2000
2025-02-19 06:20:27,687 Current Learning Rate: 0.0018737867
2025-02-19 06:20:29,137 Train Loss: 0.0001844, Val Loss: 0.0002034
2025-02-19 06:20:29,137 Epoch 1344/2000
2025-02-19 06:21:10,768 Current Learning Rate: 0.0018128801
2025-02-19 06:21:11,857 Train Loss: 0.0001955, Val Loss: 0.0002032
2025-02-19 06:21:11,858 Epoch 1345/2000
2025-02-19 06:21:53,667 Current Learning Rate: 0.0017527598
2025-02-19 06:21:55,392 Train Loss: 0.0001249, Val Loss: 0.0002016
2025-02-19 06:21:55,393 Epoch 1346/2000
2025-02-19 06:22:36,397 Current Learning Rate: 0.0016934407
2025-02-19 06:22:37,942 Train Loss: 0.0001503, Val Loss: 0.0002009
2025-02-19 06:22:37,944 Epoch 1347/2000
2025-02-19 06:23:20,739 Current Learning Rate: 0.0016349374
2025-02-19 06:23:20,739 Train Loss: 0.0001960, Val Loss: 0.0002011
2025-02-19 06:23:20,739 Epoch 1348/2000
2025-02-19 06:24:03,696 Current Learning Rate: 0.0015772645
2025-02-19 06:24:05,537 Train Loss: 0.0001704, Val Loss: 0.0002005
2025-02-19 06:24:05,537 Epoch 1349/2000
2025-02-19 06:24:47,394 Current Learning Rate: 0.0015204360
2025-02-19 06:24:48,900 Train Loss: 0.0001617, Val Loss: 0.0002000
2025-02-19 06:24:48,901 Epoch 1350/2000
2025-02-19 06:25:31,783 Current Learning Rate: 0.0014644661
2025-02-19 06:25:33,498 Train Loss: 0.0001454, Val Loss: 0.0001996
2025-02-19 06:25:33,498 Epoch 1351/2000
2025-02-19 06:26:16,092 Current Learning Rate: 0.0014093685
2025-02-19 06:26:16,093 Train Loss: 0.0002113, Val Loss: 0.0002000
2025-02-19 06:26:16,093 Epoch 1352/2000
2025-02-19 06:26:59,198 Current Learning Rate: 0.0013551569
2025-02-19 06:26:59,198 Train Loss: 0.0002045, Val Loss: 0.0001997
2025-02-19 06:26:59,199 Epoch 1353/2000
2025-02-19 06:27:42,149 Current Learning Rate: 0.0013018445
2025-02-19 06:27:43,943 Train Loss: 0.0001216, Val Loss: 0.0001989
2025-02-19 06:27:43,943 Epoch 1354/2000
2025-02-19 06:28:26,091 Current Learning Rate: 0.0012494447
2025-02-19 06:28:26,092 Train Loss: 0.0001490, Val Loss: 0.0001990
2025-02-19 06:28:26,094 Epoch 1355/2000
2025-02-19 06:29:08,604 Current Learning Rate: 0.0011979702
2025-02-19 06:29:10,303 Train Loss: 0.0001298, Val Loss: 0.0001985
2025-02-19 06:29:10,303 Epoch 1356/2000
2025-02-19 06:29:51,997 Current Learning Rate: 0.0011474338
2025-02-19 06:29:53,412 Train Loss: 0.0001464, Val Loss: 0.0001984
2025-02-19 06:29:53,413 Epoch 1357/2000
2025-02-19 06:30:35,036 Current Learning Rate: 0.0010978480
2025-02-19 06:30:36,475 Train Loss: 0.0001327, Val Loss: 0.0001981
2025-02-19 06:30:36,476 Epoch 1358/2000
2025-02-19 06:31:18,104 Current Learning Rate: 0.0010492249
2025-02-19 06:31:18,105 Train Loss: 0.0002118, Val Loss: 0.0001984
2025-02-19 06:31:18,105 Epoch 1359/2000
2025-02-19 06:32:00,966 Current Learning Rate: 0.0010015767
2025-02-19 06:32:00,966 Train Loss: 0.0001323, Val Loss: 0.0001983
2025-02-19 06:32:00,966 Epoch 1360/2000
2025-02-19 06:32:43,892 Current Learning Rate: 0.0009549150
2025-02-19 06:32:45,203 Train Loss: 0.0001945, Val Loss: 0.0001980
2025-02-19 06:32:45,203 Epoch 1361/2000
2025-02-19 06:33:28,179 Current Learning Rate: 0.0009092514
2025-02-19 06:33:29,799 Train Loss: 0.0001507, Val Loss: 0.0001975
2025-02-19 06:33:29,800 Epoch 1362/2000
2025-02-19 06:34:12,701 Current Learning Rate: 0.0008645971
2025-02-19 06:34:13,778 Train Loss: 0.0001549, Val Loss: 0.0001973
2025-02-19 06:34:13,779 Epoch 1363/2000
2025-02-19 06:34:56,283 Current Learning Rate: 0.0008209632
2025-02-19 06:34:57,467 Train Loss: 0.0001584, Val Loss: 0.0001969
2025-02-19 06:34:57,468 Epoch 1364/2000
2025-02-19 06:35:40,163 Current Learning Rate: 0.0007783604
2025-02-19 06:35:41,744 Train Loss: 0.0001905, Val Loss: 0.0001968
2025-02-19 06:35:41,744 Epoch 1365/2000
2025-02-19 06:36:24,575 Current Learning Rate: 0.0007367992
2025-02-19 06:36:25,683 Train Loss: 0.0001476, Val Loss: 0.0001966
2025-02-19 06:36:25,683 Epoch 1366/2000
2025-02-19 06:37:08,716 Current Learning Rate: 0.0006962899
2025-02-19 06:37:08,717 Train Loss: 0.0001873, Val Loss: 0.0001968
2025-02-19 06:37:08,717 Epoch 1367/2000
2025-02-19 06:37:51,641 Current Learning Rate: 0.0006568424
2025-02-19 06:37:52,811 Train Loss: 0.0001570, Val Loss: 0.0001966
2025-02-19 06:37:52,811 Epoch 1368/2000
2025-02-19 06:38:35,639 Current Learning Rate: 0.0006184666
2025-02-19 06:38:37,401 Train Loss: 0.0001603, Val Loss: 0.0001965
2025-02-19 06:38:37,401 Epoch 1369/2000
2025-02-19 06:39:20,140 Current Learning Rate: 0.0005811718
2025-02-19 06:39:21,879 Train Loss: 0.0001335, Val Loss: 0.0001962
2025-02-19 06:39:21,880 Epoch 1370/2000
2025-02-19 06:40:04,744 Current Learning Rate: 0.0005449674
2025-02-19 06:40:06,493 Train Loss: 0.0001383, Val Loss: 0.0001962
2025-02-19 06:40:06,493 Epoch 1371/2000
2025-02-19 06:40:49,048 Current Learning Rate: 0.0005098621
2025-02-19 06:40:50,807 Train Loss: 0.0001674, Val Loss: 0.0001961
2025-02-19 06:40:50,807 Epoch 1372/2000
2025-02-19 06:41:33,702 Current Learning Rate: 0.0004758647
2025-02-19 06:41:33,703 Train Loss: 0.0001510, Val Loss: 0.0001962
2025-02-19 06:41:33,703 Epoch 1373/2000
2025-02-19 06:42:16,063 Current Learning Rate: 0.0004429836
2025-02-19 06:42:16,064 Train Loss: 0.0002038, Val Loss: 0.0001962
2025-02-19 06:42:16,064 Epoch 1374/2000
2025-02-19 06:42:58,439 Current Learning Rate: 0.0004112269
2025-02-19 06:42:58,440 Train Loss: 0.0001509, Val Loss: 0.0001962
2025-02-19 06:42:58,440 Epoch 1375/2000
2025-02-19 06:43:40,935 Current Learning Rate: 0.0003806023
2025-02-19 06:43:42,264 Train Loss: 0.0001811, Val Loss: 0.0001961
2025-02-19 06:43:42,264 Epoch 1376/2000
2025-02-19 06:44:24,636 Current Learning Rate: 0.0003511176
2025-02-19 06:44:26,103 Train Loss: 0.0001462, Val Loss: 0.0001959
2025-02-19 06:44:26,103 Epoch 1377/2000
2025-02-19 06:45:08,087 Current Learning Rate: 0.0003227798
2025-02-19 06:45:09,952 Train Loss: 0.0001257, Val Loss: 0.0001958
2025-02-19 06:45:09,952 Epoch 1378/2000
2025-02-19 06:45:52,391 Current Learning Rate: 0.0002955962
2025-02-19 06:45:54,216 Train Loss: 0.0001675, Val Loss: 0.0001957
2025-02-19 06:45:54,216 Epoch 1379/2000
2025-02-19 06:46:35,743 Current Learning Rate: 0.0002695732
2025-02-19 06:46:36,981 Train Loss: 0.0001873, Val Loss: 0.0001955
2025-02-19 06:46:36,981 Epoch 1380/2000
2025-02-19 06:47:19,012 Current Learning Rate: 0.0002447174
2025-02-19 06:47:20,141 Train Loss: 0.0001514, Val Loss: 0.0001955
2025-02-19 06:47:20,141 Epoch 1381/2000
2025-02-19 06:48:01,537 Current Learning Rate: 0.0002210349
2025-02-19 06:48:03,716 Train Loss: 0.0001452, Val Loss: 0.0001953
2025-02-19 06:48:03,716 Epoch 1382/2000
2025-02-19 06:48:45,279 Current Learning Rate: 0.0001985316
2025-02-19 06:48:47,022 Train Loss: 0.0001319, Val Loss: 0.0001953
2025-02-19 06:48:47,022 Epoch 1383/2000
2025-02-19 06:49:29,932 Current Learning Rate: 0.0001772129
2025-02-19 06:49:31,745 Train Loss: 0.0001265, Val Loss: 0.0001952
2025-02-19 06:49:31,745 Epoch 1384/2000
2025-02-19 06:50:14,021 Current Learning Rate: 0.0001570842
2025-02-19 06:50:14,022 Train Loss: 0.0001790, Val Loss: 0.0001952
2025-02-19 06:50:14,023 Epoch 1385/2000
2025-02-19 06:50:56,620 Current Learning Rate: 0.0001381504
2025-02-19 06:50:58,333 Train Loss: 0.0001809, Val Loss: 0.0001952
2025-02-19 06:50:58,334 Epoch 1386/2000
2025-02-19 06:51:40,179 Current Learning Rate: 0.0001204162
2025-02-19 06:51:40,179 Train Loss: 0.0001462, Val Loss: 0.0001952
2025-02-19 06:51:40,179 Epoch 1387/2000
2025-02-19 06:52:23,168 Current Learning Rate: 0.0001038859
2025-02-19 06:52:24,381 Train Loss: 0.0001917, Val Loss: 0.0001951
2025-02-19 06:52:24,381 Epoch 1388/2000
2025-02-19 06:53:07,148 Current Learning Rate: 0.0000885637
2025-02-19 06:53:07,149 Train Loss: 0.0001766, Val Loss: 0.0001952
2025-02-19 06:53:07,149 Epoch 1389/2000
2025-02-19 06:53:50,088 Current Learning Rate: 0.0000744534
2025-02-19 06:53:50,089 Train Loss: 0.0001360, Val Loss: 0.0001952
2025-02-19 06:53:50,089 Epoch 1390/2000
2025-02-19 06:54:32,932 Current Learning Rate: 0.0000615583
2025-02-19 06:54:34,025 Train Loss: 0.0001689, Val Loss: 0.0001951
2025-02-19 06:54:34,025 Epoch 1391/2000
2025-02-19 06:55:16,217 Current Learning Rate: 0.0000498817
2025-02-19 06:55:16,218 Train Loss: 0.0001715, Val Loss: 0.0001951
2025-02-19 06:55:16,218 Epoch 1392/2000
2025-02-19 06:55:59,315 Current Learning Rate: 0.0000394265
2025-02-19 06:56:01,175 Train Loss: 0.0001693, Val Loss: 0.0001951
2025-02-19 06:56:01,175 Epoch 1393/2000
2025-02-19 06:56:43,978 Current Learning Rate: 0.0000301952
2025-02-19 06:56:45,615 Train Loss: 0.0001297, Val Loss: 0.0001951
2025-02-19 06:56:45,615 Epoch 1394/2000
2025-02-19 06:57:28,498 Current Learning Rate: 0.0000221902
2025-02-19 06:57:30,490 Train Loss: 0.0001561, Val Loss: 0.0001951
2025-02-19 06:57:30,500 Epoch 1395/2000
2025-02-19 06:58:11,981 Current Learning Rate: 0.0000154133
2025-02-19 06:58:13,378 Train Loss: 0.0001475, Val Loss: 0.0001950
2025-02-19 06:58:13,378 Epoch 1396/2000
2025-02-19 06:58:56,290 Current Learning Rate: 0.0000098664
2025-02-19 06:58:56,291 Train Loss: 0.0001332, Val Loss: 0.0001951
2025-02-19 06:58:56,292 Epoch 1397/2000
2025-02-19 06:59:39,295 Current Learning Rate: 0.0000055506
2025-02-19 06:59:41,044 Train Loss: 0.0001668, Val Loss: 0.0001950
2025-02-19 06:59:41,044 Epoch 1398/2000
2025-02-19 07:00:22,513 Current Learning Rate: 0.0000024672
2025-02-19 07:00:22,514 Train Loss: 0.0001177, Val Loss: 0.0001951
2025-02-19 07:00:22,515 Epoch 1399/2000
2025-02-19 07:01:04,942 Current Learning Rate: 0.0000006168
2025-02-19 07:01:04,943 Train Loss: 0.0001249, Val Loss: 0.0001951
2025-02-19 07:01:04,943 Epoch 1400/2000
2025-02-19 07:01:47,740 Current Learning Rate: 0.0000000000
2025-02-19 07:01:49,925 Train Loss: 0.0001752, Val Loss: 0.0001950
2025-02-19 07:01:49,926 Epoch 1401/2000
2025-02-19 07:02:32,866 Current Learning Rate: 0.0000006168
2025-02-19 07:02:32,866 Train Loss: 0.0001747, Val Loss: 0.0001950
2025-02-19 07:02:32,867 Epoch 1402/2000
2025-02-19 07:03:16,079 Current Learning Rate: 0.0000024672
2025-02-19 07:03:16,080 Train Loss: 0.0001382, Val Loss: 0.0001950
2025-02-19 07:03:16,080 Epoch 1403/2000
2025-02-19 07:03:58,845 Current Learning Rate: 0.0000055506
2025-02-19 07:03:58,846 Train Loss: 0.0001455, Val Loss: 0.0001950
2025-02-19 07:03:58,846 Epoch 1404/2000
2025-02-19 07:04:42,380 Current Learning Rate: 0.0000098664
2025-02-19 07:04:42,380 Train Loss: 0.0001338, Val Loss: 0.0001950
2025-02-19 07:04:42,380 Epoch 1405/2000
2025-02-19 07:05:25,461 Current Learning Rate: 0.0000154133
2025-02-19 07:05:25,462 Train Loss: 0.0001571, Val Loss: 0.0001950
2025-02-19 07:05:25,462 Epoch 1406/2000
2025-02-19 07:06:08,755 Current Learning Rate: 0.0000221902
2025-02-19 07:06:08,755 Train Loss: 0.0001550, Val Loss: 0.0001950
2025-02-19 07:06:08,755 Epoch 1407/2000
2025-02-19 07:06:51,954 Current Learning Rate: 0.0000301952
2025-02-19 07:06:51,954 Train Loss: 0.0001694, Val Loss: 0.0001950
2025-02-19 07:06:51,955 Epoch 1408/2000
2025-02-19 07:07:34,195 Current Learning Rate: 0.0000394265
2025-02-19 07:07:34,196 Train Loss: 0.0001479, Val Loss: 0.0001950
2025-02-19 07:07:34,196 Epoch 1409/2000
2025-02-19 07:08:16,890 Current Learning Rate: 0.0000498817
2025-02-19 07:08:16,891 Train Loss: 0.0001402, Val Loss: 0.0001951
2025-02-19 07:08:16,891 Epoch 1410/2000
2025-02-19 07:08:59,892 Current Learning Rate: 0.0000615583
2025-02-19 07:08:59,893 Train Loss: 0.0001351, Val Loss: 0.0001951
2025-02-19 07:08:59,893 Epoch 1411/2000
2025-02-19 07:09:43,458 Current Learning Rate: 0.0000744534
2025-02-19 07:09:43,459 Train Loss: 0.0001465, Val Loss: 0.0001951
2025-02-19 07:09:43,459 Epoch 1412/2000
2025-02-19 07:10:26,831 Current Learning Rate: 0.0000885637
2025-02-19 07:10:26,832 Train Loss: 0.0001370, Val Loss: 0.0001952
2025-02-19 07:10:26,832 Epoch 1413/2000
2025-02-19 07:11:09,736 Current Learning Rate: 0.0001038859
2025-02-19 07:11:09,737 Train Loss: 0.0001614, Val Loss: 0.0001952
2025-02-19 07:11:09,737 Epoch 1414/2000
2025-02-19 07:11:52,235 Current Learning Rate: 0.0001204162
2025-02-19 07:11:52,236 Train Loss: 0.0001562, Val Loss: 0.0001951
2025-02-19 07:11:52,237 Epoch 1415/2000
2025-02-19 07:12:34,725 Current Learning Rate: 0.0001381504
2025-02-19 07:12:34,725 Train Loss: 0.0001188, Val Loss: 0.0001951
2025-02-19 07:12:34,725 Epoch 1416/2000
2025-02-19 07:13:18,166 Current Learning Rate: 0.0001570842
2025-02-19 07:13:18,167 Train Loss: 0.0001191, Val Loss: 0.0001951
2025-02-19 07:13:18,167 Epoch 1417/2000
2025-02-19 07:14:00,929 Current Learning Rate: 0.0001772129
2025-02-19 07:14:00,930 Train Loss: 0.0001645, Val Loss: 0.0001951
2025-02-19 07:14:00,931 Epoch 1418/2000
2025-02-19 07:14:43,697 Current Learning Rate: 0.0001985316
2025-02-19 07:14:43,698 Train Loss: 0.0001306, Val Loss: 0.0001951
2025-02-19 07:14:43,698 Epoch 1419/2000
2025-02-19 07:15:26,173 Current Learning Rate: 0.0002210349
2025-02-19 07:15:26,174 Train Loss: 0.0001461, Val Loss: 0.0001952
2025-02-19 07:15:26,174 Epoch 1420/2000
2025-02-19 07:16:08,869 Current Learning Rate: 0.0002447174
2025-02-19 07:16:08,870 Train Loss: 0.0001468, Val Loss: 0.0001953
2025-02-19 07:16:08,870 Epoch 1421/2000
2025-02-19 07:16:52,213 Current Learning Rate: 0.0002695732
2025-02-19 07:16:52,214 Train Loss: 0.0001603, Val Loss: 0.0001955
2025-02-19 07:16:52,214 Epoch 1422/2000
2025-02-19 07:17:35,416 Current Learning Rate: 0.0002955962
2025-02-19 07:17:35,417 Train Loss: 0.0001236, Val Loss: 0.0001956
2025-02-19 07:17:35,417 Epoch 1423/2000
2025-02-19 07:18:18,342 Current Learning Rate: 0.0003227798
2025-02-19 07:18:18,343 Train Loss: 0.0001326, Val Loss: 0.0001954
2025-02-19 07:18:18,343 Epoch 1424/2000
2025-02-19 07:19:00,444 Current Learning Rate: 0.0003511176
2025-02-19 07:19:00,445 Train Loss: 0.0001816, Val Loss: 0.0001953
2025-02-19 07:19:00,445 Epoch 1425/2000
2025-02-19 07:19:43,361 Current Learning Rate: 0.0003806023
2025-02-19 07:19:43,362 Train Loss: 0.0001778, Val Loss: 0.0001957
2025-02-19 07:19:43,362 Epoch 1426/2000
2025-02-19 07:20:25,879 Current Learning Rate: 0.0004112269
2025-02-19 07:20:25,880 Train Loss: 0.0001551, Val Loss: 0.0001955
2025-02-19 07:20:25,880 Epoch 1427/2000
2025-02-19 07:21:07,927 Current Learning Rate: 0.0004429836
2025-02-19 07:21:07,928 Train Loss: 0.0001642, Val Loss: 0.0001955
2025-02-19 07:21:07,928 Epoch 1428/2000
2025-02-19 07:21:50,554 Current Learning Rate: 0.0004758647
2025-02-19 07:21:50,555 Train Loss: 0.0001581, Val Loss: 0.0001954
2025-02-19 07:21:50,555 Epoch 1429/2000
2025-02-19 07:22:33,968 Current Learning Rate: 0.0005098621
2025-02-19 07:22:33,968 Train Loss: 0.0001382, Val Loss: 0.0001953
2025-02-19 07:22:33,969 Epoch 1430/2000
2025-02-19 07:23:16,284 Current Learning Rate: 0.0005449674
2025-02-19 07:23:16,285 Train Loss: 0.0001418, Val Loss: 0.0001955
2025-02-19 07:23:16,286 Epoch 1431/2000
2025-02-19 07:23:58,924 Current Learning Rate: 0.0005811718
2025-02-19 07:23:58,924 Train Loss: 0.0001684, Val Loss: 0.0001957
2025-02-19 07:23:58,924 Epoch 1432/2000
2025-02-19 07:24:42,267 Current Learning Rate: 0.0006184666
2025-02-19 07:24:42,267 Train Loss: 0.0001765, Val Loss: 0.0001958
2025-02-19 07:24:42,268 Epoch 1433/2000
2025-02-19 07:25:24,393 Current Learning Rate: 0.0006568424
2025-02-19 07:25:24,394 Train Loss: 0.0001495, Val Loss: 0.0001956
2025-02-19 07:25:24,394 Epoch 1434/2000
2025-02-19 07:26:07,348 Current Learning Rate: 0.0006962899
2025-02-19 07:26:07,349 Train Loss: 0.0001431, Val Loss: 0.0001956
2025-02-19 07:26:07,349 Epoch 1435/2000
2025-02-19 07:26:49,238 Current Learning Rate: 0.0007367992
2025-02-19 07:26:49,239 Train Loss: 0.0001518, Val Loss: 0.0001957
2025-02-19 07:26:49,239 Epoch 1436/2000
2025-02-19 07:27:31,465 Current Learning Rate: 0.0007783604
2025-02-19 07:27:31,466 Train Loss: 0.0001716, Val Loss: 0.0001960
2025-02-19 07:27:31,466 Epoch 1437/2000
2025-02-19 07:28:14,564 Current Learning Rate: 0.0008209632
2025-02-19 07:28:14,564 Train Loss: 0.0001429, Val Loss: 0.0001957
2025-02-19 07:28:14,565 Epoch 1438/2000
2025-02-19 07:28:56,776 Current Learning Rate: 0.0008645971
2025-02-19 07:28:56,777 Train Loss: 0.0001973, Val Loss: 0.0001964
2025-02-19 07:28:56,777 Epoch 1439/2000
2025-02-19 07:29:39,241 Current Learning Rate: 0.0009092514
2025-02-19 07:29:39,241 Train Loss: 0.0001190, Val Loss: 0.0001956
2025-02-19 07:29:39,242 Epoch 1440/2000
2025-02-19 07:30:22,133 Current Learning Rate: 0.0009549150
2025-02-19 07:30:22,133 Train Loss: 0.0001409, Val Loss: 0.0001958
2025-02-19 07:30:22,133 Epoch 1441/2000
2025-02-19 07:31:05,119 Current Learning Rate: 0.0010015767
2025-02-19 07:31:05,120 Train Loss: 0.0001946, Val Loss: 0.0001972
2025-02-19 07:31:05,120 Epoch 1442/2000
2025-02-19 07:31:47,480 Current Learning Rate: 0.0010492249
2025-02-19 07:31:47,481 Train Loss: 0.0001441, Val Loss: 0.0001968
2025-02-19 07:31:47,481 Epoch 1443/2000
2025-02-19 07:32:30,057 Current Learning Rate: 0.0010978480
2025-02-19 07:32:30,058 Train Loss: 0.0001590, Val Loss: 0.0001968
2025-02-19 07:32:30,058 Epoch 1444/2000
2025-02-19 07:33:12,069 Current Learning Rate: 0.0011474338
2025-02-19 07:33:12,070 Train Loss: 0.0001558, Val Loss: 0.0001981
2025-02-19 07:33:12,070 Epoch 1445/2000
2025-02-19 07:33:54,369 Current Learning Rate: 0.0011979702
2025-02-19 07:33:54,370 Train Loss: 0.0001661, Val Loss: 0.0001973
2025-02-19 07:33:54,371 Epoch 1446/2000
2025-02-19 07:34:36,343 Current Learning Rate: 0.0012494447
2025-02-19 07:34:36,343 Train Loss: 0.0001696, Val Loss: 0.0001982
2025-02-19 07:34:36,344 Epoch 1447/2000
2025-02-19 07:35:19,023 Current Learning Rate: 0.0013018445
2025-02-19 07:35:19,024 Train Loss: 0.0001508, Val Loss: 0.0001969
2025-02-19 07:35:19,024 Epoch 1448/2000
2025-02-19 07:36:01,460 Current Learning Rate: 0.0013551569
2025-02-19 07:36:01,460 Train Loss: 0.0001188, Val Loss: 0.0001963
2025-02-19 07:36:01,461 Epoch 1449/2000
2025-02-19 07:36:43,924 Current Learning Rate: 0.0014093685
2025-02-19 07:36:43,925 Train Loss: 0.0001430, Val Loss: 0.0001983
2025-02-19 07:36:43,925 Epoch 1450/2000
2025-02-19 07:37:26,178 Current Learning Rate: 0.0014644661
2025-02-19 07:37:26,178 Train Loss: 0.0001637, Val Loss: 0.0001976
2025-02-19 07:37:26,178 Epoch 1451/2000
2025-02-19 07:38:08,176 Current Learning Rate: 0.0015204360
2025-02-19 07:38:08,177 Train Loss: 0.0001851, Val Loss: 0.0002001
2025-02-19 07:38:08,177 Epoch 1452/2000
2025-02-19 07:38:50,761 Current Learning Rate: 0.0015772645
2025-02-19 07:38:50,762 Train Loss: 0.0001441, Val Loss: 0.0001977
2025-02-19 07:38:50,762 Epoch 1453/2000
2025-02-19 07:39:33,883 Current Learning Rate: 0.0016349374
2025-02-19 07:39:33,883 Train Loss: 0.0001329, Val Loss: 0.0001964
2025-02-19 07:39:33,883 Epoch 1454/2000
2025-02-19 07:40:15,781 Current Learning Rate: 0.0016934407
2025-02-19 07:40:15,781 Train Loss: 0.0001266, Val Loss: 0.0001959
2025-02-19 07:40:15,781 Epoch 1455/2000
2025-02-19 07:40:59,063 Current Learning Rate: 0.0017527598
2025-02-19 07:40:59,063 Train Loss: 0.0001695, Val Loss: 0.0001972
2025-02-19 07:40:59,064 Epoch 1456/2000
2025-02-19 07:41:41,674 Current Learning Rate: 0.0018128801
2025-02-19 07:41:41,674 Train Loss: 0.0001289, Val Loss: 0.0001970
2025-02-19 07:41:41,675 Epoch 1457/2000
2025-02-19 07:42:23,564 Current Learning Rate: 0.0018737867
2025-02-19 07:42:23,565 Train Loss: 0.0001478, Val Loss: 0.0001978
2025-02-19 07:42:23,565 Epoch 1458/2000
2025-02-19 07:43:06,594 Current Learning Rate: 0.0019354647
2025-02-19 07:43:06,594 Train Loss: 0.0001802, Val Loss: 0.0001977
2025-02-19 07:43:06,594 Epoch 1459/2000
2025-02-19 07:43:49,553 Current Learning Rate: 0.0019978989
2025-02-19 07:43:49,553 Train Loss: 0.0001816, Val Loss: 0.0002013
2025-02-19 07:43:49,553 Epoch 1460/2000
2025-02-19 07:44:32,429 Current Learning Rate: 0.0020610737
2025-02-19 07:44:32,430 Train Loss: 0.0001608, Val Loss: 0.0001992
2025-02-19 07:44:32,430 Epoch 1461/2000
2025-02-19 07:45:15,467 Current Learning Rate: 0.0021249737
2025-02-19 07:45:15,467 Train Loss: 0.0001295, Val Loss: 0.0002001
2025-02-19 07:45:15,468 Epoch 1462/2000
2025-02-19 07:45:57,528 Current Learning Rate: 0.0021895831
2025-02-19 07:45:57,529 Train Loss: 0.0001627, Val Loss: 0.0001976
2025-02-19 07:45:57,529 Epoch 1463/2000
2025-02-19 07:46:40,580 Current Learning Rate: 0.0022548859
2025-02-19 07:46:40,580 Train Loss: 0.0001390, Val Loss: 0.0001990
2025-02-19 07:46:40,581 Epoch 1464/2000
2025-02-19 07:47:22,593 Current Learning Rate: 0.0023208660
2025-02-19 07:47:22,594 Train Loss: 0.0001428, Val Loss: 0.0002021
2025-02-19 07:47:22,594 Epoch 1465/2000
2025-02-19 07:48:05,379 Current Learning Rate: 0.0023875072
2025-02-19 07:48:05,379 Train Loss: 0.0002034, Val Loss: 0.0002133
2025-02-19 07:48:05,380 Epoch 1466/2000
2025-02-19 07:48:48,294 Current Learning Rate: 0.0024547929
2025-02-19 07:48:48,295 Train Loss: 0.0001337, Val Loss: 0.0002009
2025-02-19 07:48:48,295 Epoch 1467/2000
2025-02-19 07:49:31,187 Current Learning Rate: 0.0025227067
2025-02-19 07:49:31,188 Train Loss: 0.0001948, Val Loss: 0.0002251
2025-02-19 07:49:31,188 Epoch 1468/2000
2025-02-19 07:50:14,190 Current Learning Rate: 0.0025912316
2025-02-19 07:50:14,191 Train Loss: 0.0001540, Val Loss: 0.0002046
2025-02-19 07:50:14,191 Epoch 1469/2000
2025-02-19 07:50:57,107 Current Learning Rate: 0.0026603509
2025-02-19 07:50:57,107 Train Loss: 0.0001357, Val Loss: 0.0001993
2025-02-19 07:50:57,108 Epoch 1470/2000
2025-02-19 07:51:39,828 Current Learning Rate: 0.0027300475
2025-02-19 07:51:39,828 Train Loss: 0.0001682, Val Loss: 0.0002071
2025-02-19 07:51:39,829 Epoch 1471/2000
2025-02-19 07:52:22,560 Current Learning Rate: 0.0028003042
2025-02-19 07:52:22,560 Train Loss: 0.0001686, Val Loss: 0.0002344
2025-02-19 07:52:22,560 Epoch 1472/2000
2025-02-19 07:53:05,615 Current Learning Rate: 0.0028711035
2025-02-19 07:53:05,615 Train Loss: 0.0001732, Val Loss: 0.0002047
2025-02-19 07:53:05,615 Epoch 1473/2000
2025-02-19 07:53:47,800 Current Learning Rate: 0.0029424282
2025-02-19 07:53:47,801 Train Loss: 0.0001470, Val Loss: 0.0002015
2025-02-19 07:53:47,801 Epoch 1474/2000
2025-02-19 07:54:30,930 Current Learning Rate: 0.0030142605
2025-02-19 07:54:30,931 Train Loss: 0.0001695, Val Loss: 0.0002009
2025-02-19 07:54:30,931 Epoch 1475/2000
2025-02-19 07:55:13,890 Current Learning Rate: 0.0030865828
2025-02-19 07:55:13,891 Train Loss: 0.0001791, Val Loss: 0.0002123
2025-02-19 07:55:13,891 Epoch 1476/2000
2025-02-19 07:55:56,883 Current Learning Rate: 0.0031593772
2025-02-19 07:55:56,883 Train Loss: 0.0001339, Val Loss: 0.0002033
2025-02-19 07:55:56,884 Epoch 1477/2000
2025-02-19 07:56:39,587 Current Learning Rate: 0.0032326258
2025-02-19 07:56:39,588 Train Loss: 0.0001420, Val Loss: 0.0002072
2025-02-19 07:56:39,588 Epoch 1478/2000
2025-02-19 07:57:21,698 Current Learning Rate: 0.0033063104
2025-02-19 07:57:21,699 Train Loss: 0.0001889, Val Loss: 0.0002220
2025-02-19 07:57:21,699 Epoch 1479/2000
2025-02-19 07:58:04,838 Current Learning Rate: 0.0033804129
2025-02-19 07:58:04,838 Train Loss: 0.0001504, Val Loss: 0.0002127
2025-02-19 07:58:04,839 Epoch 1480/2000
2025-02-19 07:58:47,368 Current Learning Rate: 0.0034549150
2025-02-19 07:58:47,377 Train Loss: 0.0002265, Val Loss: 0.0002265
2025-02-19 07:58:47,384 Epoch 1481/2000
2025-02-19 07:59:30,479 Current Learning Rate: 0.0035297984
2025-02-19 07:59:30,480 Train Loss: 0.0001680, Val Loss: 0.0002286
2025-02-19 07:59:30,481 Epoch 1482/2000
2025-02-19 08:00:13,167 Current Learning Rate: 0.0036050445
2025-02-19 08:00:13,167 Train Loss: 0.0001633, Val Loss: 0.0002089
2025-02-19 08:00:13,167 Epoch 1483/2000
2025-02-19 08:00:56,106 Current Learning Rate: 0.0036806348
2025-02-19 08:00:56,107 Train Loss: 0.0001451, Val Loss: 0.0002081
2025-02-19 08:00:56,107 Epoch 1484/2000
2025-02-19 08:01:39,142 Current Learning Rate: 0.0037565506
2025-02-19 08:01:39,142 Train Loss: 0.0001489, Val Loss: 0.0002080
2025-02-19 08:01:39,142 Epoch 1485/2000
2025-02-19 08:02:22,079 Current Learning Rate: 0.0038327732
2025-02-19 08:02:22,079 Train Loss: 0.0002045, Val Loss: 0.0002199
2025-02-19 08:02:22,079 Epoch 1486/2000
2025-02-19 08:03:04,020 Current Learning Rate: 0.0039092838
2025-02-19 08:03:04,021 Train Loss: 0.0003976, Val Loss: 0.0002651
2025-02-19 08:03:04,021 Epoch 1487/2000
2025-02-19 08:03:46,943 Current Learning Rate: 0.0039860635
2025-02-19 08:03:46,943 Train Loss: 0.0002031, Val Loss: 0.0002236
2025-02-19 08:03:46,943 Epoch 1488/2000
2025-02-19 08:04:29,872 Current Learning Rate: 0.0040630934
2025-02-19 08:04:29,872 Train Loss: 0.0002540, Val Loss: 0.0002175
2025-02-19 08:04:29,873 Epoch 1489/2000
2025-02-19 08:05:12,694 Current Learning Rate: 0.0041403545
2025-02-19 08:05:12,695 Train Loss: 0.0001855, Val Loss: 0.0002180
2025-02-19 08:05:12,695 Epoch 1490/2000
2025-02-19 08:05:55,463 Current Learning Rate: 0.0042178277
2025-02-19 08:05:55,464 Train Loss: 0.0002066, Val Loss: 0.0002193
2025-02-19 08:05:55,464 Epoch 1491/2000
2025-02-19 08:06:38,285 Current Learning Rate: 0.0042954938
2025-02-19 08:06:38,285 Train Loss: 0.0001675, Val Loss: 0.0002054
2025-02-19 08:06:38,285 Epoch 1492/2000
2025-02-19 08:07:20,383 Current Learning Rate: 0.0043733338
2025-02-19 08:07:20,383 Train Loss: 0.0001201, Val Loss: 0.0002018
2025-02-19 08:07:20,383 Epoch 1493/2000
2025-02-19 08:08:02,498 Current Learning Rate: 0.0044513284
2025-02-19 08:08:02,499 Train Loss: 0.0001626, Val Loss: 0.0002240
2025-02-19 08:08:02,499 Epoch 1494/2000
2025-02-19 08:08:44,793 Current Learning Rate: 0.0045294584
2025-02-19 08:08:44,794 Train Loss: 0.0001457, Val Loss: 0.0002082
2025-02-19 08:08:44,794 Epoch 1495/2000
2025-02-19 08:09:26,759 Current Learning Rate: 0.0046077045
2025-02-19 08:09:26,759 Train Loss: 0.0004107, Val Loss: 0.0002833
2025-02-19 08:09:26,759 Epoch 1496/2000
2025-02-19 08:10:08,953 Current Learning Rate: 0.0046860474
2025-02-19 08:10:08,954 Train Loss: 0.0001688, Val Loss: 0.0002164
2025-02-19 08:10:08,954 Epoch 1497/2000
2025-02-19 08:10:51,890 Current Learning Rate: 0.0047644677
2025-02-19 08:10:51,891 Train Loss: 0.0001997, Val Loss: 0.0002262
2025-02-19 08:10:51,891 Epoch 1498/2000
2025-02-19 08:11:33,874 Current Learning Rate: 0.0048429462
2025-02-19 08:11:33,874 Train Loss: 0.0001954, Val Loss: 0.0002259
2025-02-19 08:11:33,875 Epoch 1499/2000
2025-02-19 08:12:16,451 Current Learning Rate: 0.0049214634
2025-02-19 08:12:16,452 Train Loss: 0.0001865, Val Loss: 0.0002165
2025-02-19 08:12:16,452 Epoch 1500/2000
2025-02-19 08:12:59,403 Current Learning Rate: 0.0050000000
2025-02-19 08:12:59,404 Train Loss: 0.0001820, Val Loss: 0.0002292
2025-02-19 08:12:59,404 Epoch 1501/2000
2025-02-19 08:13:41,519 Current Learning Rate: 0.0050785366
2025-02-19 08:13:41,519 Train Loss: 0.0001468, Val Loss: 0.0002126
2025-02-19 08:13:41,520 Epoch 1502/2000
2025-02-19 08:14:24,491 Current Learning Rate: 0.0051570538
2025-02-19 08:14:24,492 Train Loss: 0.0002013, Val Loss: 0.0002498
2025-02-19 08:14:24,492 Epoch 1503/2000
2025-02-19 08:15:07,078 Current Learning Rate: 0.0052355323
2025-02-19 08:15:07,079 Train Loss: 0.0001968, Val Loss: 0.0002388
2025-02-19 08:15:07,079 Epoch 1504/2000
2025-02-19 08:15:49,792 Current Learning Rate: 0.0053139526
2025-02-19 08:15:49,792 Train Loss: 0.0001710, Val Loss: 0.0002253
2025-02-19 08:15:49,792 Epoch 1505/2000
2025-02-19 08:16:32,705 Current Learning Rate: 0.0053922955
2025-02-19 08:16:32,706 Train Loss: 0.0001604, Val Loss: 0.0002181
2025-02-19 08:16:32,707 Epoch 1506/2000
2025-02-19 08:17:15,674 Current Learning Rate: 0.0054705416
2025-02-19 08:17:15,675 Train Loss: 0.0002435, Val Loss: 0.0002649
2025-02-19 08:17:15,675 Epoch 1507/2000
2025-02-19 08:17:58,042 Current Learning Rate: 0.0055486716
2025-02-19 08:17:58,042 Train Loss: 0.0002222, Val Loss: 0.0002365
2025-02-19 08:17:58,042 Epoch 1508/2000
2025-02-19 08:18:40,363 Current Learning Rate: 0.0056266662
2025-02-19 08:18:40,363 Train Loss: 0.0001988, Val Loss: 0.0002559
2025-02-19 08:18:40,364 Epoch 1509/2000
2025-02-19 08:19:22,871 Current Learning Rate: 0.0057045062
2025-02-19 08:19:22,871 Train Loss: 0.0001844, Val Loss: 0.0002882
2025-02-19 08:19:22,871 Epoch 1510/2000
2025-02-19 08:20:06,022 Current Learning Rate: 0.0057821723
2025-02-19 08:20:06,023 Train Loss: 0.0002560, Val Loss: 0.0003296
2025-02-19 08:20:06,023 Epoch 1511/2000
2025-02-19 08:20:49,215 Current Learning Rate: 0.0058596455
2025-02-19 08:20:49,215 Train Loss: 0.0002513, Val Loss: 0.0002483
2025-02-19 08:20:49,216 Epoch 1512/2000
2025-02-19 08:21:32,706 Current Learning Rate: 0.0059369066
2025-02-19 08:21:32,707 Train Loss: 0.0002178, Val Loss: 0.0002721
2025-02-19 08:21:32,707 Epoch 1513/2000
2025-02-19 08:22:15,210 Current Learning Rate: 0.0060139365
2025-02-19 08:22:15,210 Train Loss: 0.0002082, Val Loss: 0.0002953
2025-02-19 08:22:15,211 Epoch 1514/2000
2025-02-19 08:22:57,401 Current Learning Rate: 0.0060907162
2025-02-19 08:22:57,401 Train Loss: 0.0002167, Val Loss: 0.0002572
2025-02-19 08:22:57,402 Epoch 1515/2000
2025-02-19 08:23:39,877 Current Learning Rate: 0.0061672268
2025-02-19 08:23:39,877 Train Loss: 0.0002100, Val Loss: 0.0002608
2025-02-19 08:23:39,878 Epoch 1516/2000
2025-02-19 08:24:23,054 Current Learning Rate: 0.0062434494
2025-02-19 08:24:23,054 Train Loss: 0.0002465, Val Loss: 0.0002791
2025-02-19 08:24:23,067 Epoch 1517/2000
2025-02-19 08:25:05,590 Current Learning Rate: 0.0063193652
2025-02-19 08:25:05,591 Train Loss: 0.0002212, Val Loss: 0.0002738
2025-02-19 08:25:05,591 Epoch 1518/2000
2025-02-19 08:25:49,613 Current Learning Rate: 0.0063949555
2025-02-19 08:25:49,614 Train Loss: 0.0002870, Val Loss: 0.0003399
2025-02-19 08:25:49,614 Epoch 1519/2000
2025-02-19 08:26:32,891 Current Learning Rate: 0.0064702016
2025-02-19 08:26:32,892 Train Loss: 0.0002522, Val Loss: 0.0003258
2025-02-19 08:26:32,892 Epoch 1520/2000
2025-02-19 08:27:15,615 Current Learning Rate: 0.0065450850
2025-02-19 08:27:15,615 Train Loss: 0.0002557, Val Loss: 0.0002717
2025-02-19 08:27:15,615 Epoch 1521/2000
2025-02-19 08:27:57,952 Current Learning Rate: 0.0066195871
2025-02-19 08:27:57,953 Train Loss: 0.0002116, Val Loss: 0.0002916
2025-02-19 08:27:57,953 Epoch 1522/2000
2025-02-19 08:28:41,020 Current Learning Rate: 0.0066936896
2025-02-19 08:28:41,021 Train Loss: 0.0002302, Val Loss: 0.0002633
2025-02-19 08:28:41,021 Epoch 1523/2000
2025-02-19 08:29:24,670 Current Learning Rate: 0.0067673742
2025-02-19 08:29:24,670 Train Loss: 0.0002558, Val Loss: 0.0002535
2025-02-19 08:29:24,671 Epoch 1524/2000
2025-02-19 08:30:06,915 Current Learning Rate: 0.0068406228
2025-02-19 08:30:06,916 Train Loss: 0.0001685, Val Loss: 0.0002497
2025-02-19 08:30:06,917 Epoch 1525/2000
2025-02-19 08:30:50,259 Current Learning Rate: 0.0069134172
2025-02-19 08:30:50,259 Train Loss: 0.0001982, Val Loss: 0.0002606
2025-02-19 08:30:50,260 Epoch 1526/2000
2025-02-19 08:31:32,710 Current Learning Rate: 0.0069857395
2025-02-19 08:31:32,711 Train Loss: 0.0002570, Val Loss: 0.0002472
2025-02-19 08:31:32,711 Epoch 1527/2000
2025-02-19 08:32:14,865 Current Learning Rate: 0.0070575718
2025-02-19 08:32:14,865 Train Loss: 0.0002172, Val Loss: 0.0003000
2025-02-19 08:32:14,866 Epoch 1528/2000
2025-02-19 08:32:58,001 Current Learning Rate: 0.0071288965
2025-02-19 08:32:58,002 Train Loss: 0.0002228, Val Loss: 0.0003270
2025-02-19 08:32:58,002 Epoch 1529/2000
2025-02-19 08:33:40,614 Current Learning Rate: 0.0071996958
2025-02-19 08:33:40,614 Train Loss: 0.0001987, Val Loss: 0.0002412
2025-02-19 08:33:40,614 Epoch 1530/2000
2025-02-19 08:34:23,652 Current Learning Rate: 0.0072699525
2025-02-19 08:34:23,652 Train Loss: 0.0006390, Val Loss: 0.0007646
2025-02-19 08:34:23,652 Epoch 1531/2000
2025-02-19 08:35:06,696 Current Learning Rate: 0.0073396491
2025-02-19 08:35:06,697 Train Loss: 0.0011702, Val Loss: 0.0004564
2025-02-19 08:35:06,697 Epoch 1532/2000
2025-02-19 08:35:49,230 Current Learning Rate: 0.0074087684
2025-02-19 08:35:49,231 Train Loss: 0.0003034, Val Loss: 0.0002843
2025-02-19 08:35:49,232 Epoch 1533/2000
2025-02-19 08:36:31,424 Current Learning Rate: 0.0074772933
2025-02-19 08:36:31,425 Train Loss: 0.0002477, Val Loss: 0.0002916
2025-02-19 08:36:31,425 Epoch 1534/2000
2025-02-19 08:37:13,755 Current Learning Rate: 0.0075452071
2025-02-19 08:37:13,755 Train Loss: 0.0002565, Val Loss: 0.0002823
2025-02-19 08:37:13,755 Epoch 1535/2000
2025-02-19 08:37:56,447 Current Learning Rate: 0.0076124928
2025-02-19 08:37:56,470 Train Loss: 0.0002207, Val Loss: 0.0002487
2025-02-19 08:37:56,471 Epoch 1536/2000
2025-02-19 08:38:39,462 Current Learning Rate: 0.0076791340
2025-02-19 08:38:39,462 Train Loss: 0.0002332, Val Loss: 0.0002517
2025-02-19 08:38:39,463 Epoch 1537/2000
2025-02-19 08:39:21,757 Current Learning Rate: 0.0077451141
2025-02-19 08:39:21,758 Train Loss: 0.0001866, Val Loss: 0.0002585
2025-02-19 08:39:21,758 Epoch 1538/2000
2025-02-19 08:40:04,213 Current Learning Rate: 0.0078104169
2025-02-19 08:40:04,214 Train Loss: 0.0002167, Val Loss: 0.0002570
2025-02-19 08:40:04,214 Epoch 1539/2000
2025-02-19 08:40:46,443 Current Learning Rate: 0.0078750263
2025-02-19 08:40:46,444 Train Loss: 0.0002286, Val Loss: 0.0002564
2025-02-19 08:40:46,445 Epoch 1540/2000
2025-02-19 08:41:28,759 Current Learning Rate: 0.0079389263
2025-02-19 08:41:28,759 Train Loss: 0.0002637, Val Loss: 0.0002583
2025-02-19 08:41:28,760 Epoch 1541/2000
2025-02-19 08:42:11,881 Current Learning Rate: 0.0080021011
2025-02-19 08:42:11,881 Train Loss: 0.0002244, Val Loss: 0.0002482
2025-02-19 08:42:11,881 Epoch 1542/2000
2025-02-19 08:42:53,861 Current Learning Rate: 0.0080645353
2025-02-19 08:42:53,861 Train Loss: 0.0002571, Val Loss: 0.0002690
2025-02-19 08:42:53,861 Epoch 1543/2000
2025-02-19 08:43:36,844 Current Learning Rate: 0.0081262133
2025-02-19 08:43:36,844 Train Loss: 0.0002353, Val Loss: 0.0002479
2025-02-19 08:43:36,844 Epoch 1544/2000
2025-02-19 08:44:19,353 Current Learning Rate: 0.0081871199
2025-02-19 08:44:19,354 Train Loss: 0.0002326, Val Loss: 0.0002681
2025-02-19 08:44:19,354 Epoch 1545/2000
2025-02-19 08:45:01,954 Current Learning Rate: 0.0082472402
2025-02-19 08:45:01,955 Train Loss: 0.0002169, Val Loss: 0.0002961
2025-02-19 08:45:01,955 Epoch 1546/2000
2025-02-19 08:45:43,918 Current Learning Rate: 0.0083065593
2025-02-19 08:45:43,919 Train Loss: 0.0002374, Val Loss: 0.0002582
2025-02-19 08:45:43,919 Epoch 1547/2000
2025-02-19 08:46:26,835 Current Learning Rate: 0.0083650626
2025-02-19 08:46:26,836 Train Loss: 0.0002647, Val Loss: 0.0002561
2025-02-19 08:46:26,836 Epoch 1548/2000
2025-02-19 08:47:09,699 Current Learning Rate: 0.0084227355
2025-02-19 08:47:09,699 Train Loss: 0.0001918, Val Loss: 0.0002443
2025-02-19 08:47:09,699 Epoch 1549/2000
2025-02-19 08:47:52,098 Current Learning Rate: 0.0084795640
2025-02-19 08:47:52,098 Train Loss: 0.0002346, Val Loss: 0.0002501
2025-02-19 08:47:52,099 Epoch 1550/2000
2025-02-19 08:48:34,665 Current Learning Rate: 0.0085355339
2025-02-19 08:48:34,665 Train Loss: 0.0002625, Val Loss: 0.0002557
2025-02-19 08:48:34,665 Epoch 1551/2000
2025-02-19 08:49:17,182 Current Learning Rate: 0.0085906315
2025-02-19 08:49:17,182 Train Loss: 0.0003306, Val Loss: 0.0002691
2025-02-19 08:49:17,182 Epoch 1552/2000
2025-02-19 08:50:00,131 Current Learning Rate: 0.0086448431
2025-02-19 08:50:00,132 Train Loss: 0.0001846, Val Loss: 0.0002536
2025-02-19 08:50:00,132 Epoch 1553/2000
2025-02-19 08:50:42,022 Current Learning Rate: 0.0086981555
2025-02-19 08:50:42,022 Train Loss: 0.0002053, Val Loss: 0.0002573
2025-02-19 08:50:42,023 Epoch 1554/2000
2025-02-19 08:51:24,493 Current Learning Rate: 0.0087505553
2025-02-19 08:51:24,493 Train Loss: 0.0002493, Val Loss: 0.0002722
2025-02-19 08:51:24,493 Epoch 1555/2000
2025-02-19 08:52:07,767 Current Learning Rate: 0.0088020298
2025-02-19 08:52:07,768 Train Loss: 0.0003195, Val Loss: 0.0002814
2025-02-19 08:52:07,768 Epoch 1556/2000
2025-02-19 08:52:50,868 Current Learning Rate: 0.0088525662
2025-02-19 08:52:50,869 Train Loss: 0.0002280, Val Loss: 0.0002864
2025-02-19 08:52:50,869 Epoch 1557/2000
2025-02-19 08:53:32,911 Current Learning Rate: 0.0089021520
2025-02-19 08:53:32,912 Train Loss: 0.0002404, Val Loss: 0.0002823
2025-02-19 08:53:32,912 Epoch 1558/2000
2025-02-19 08:54:15,212 Current Learning Rate: 0.0089507751
2025-02-19 08:54:15,212 Train Loss: 0.0002315, Val Loss: 0.0002688
2025-02-19 08:54:15,212 Epoch 1559/2000
2025-02-19 08:54:57,581 Current Learning Rate: 0.0089984233
2025-02-19 08:54:57,582 Train Loss: 0.0002853, Val Loss: 0.0003297
2025-02-19 08:54:57,582 Epoch 1560/2000
2025-02-19 08:55:39,988 Current Learning Rate: 0.0090450850
2025-02-19 08:55:39,988 Train Loss: 0.0002139, Val Loss: 0.0002876
2025-02-19 08:55:39,988 Epoch 1561/2000
2025-02-19 08:56:22,629 Current Learning Rate: 0.0090907486
2025-02-19 08:56:22,662 Train Loss: 0.0002782, Val Loss: 0.0003619
2025-02-19 08:56:22,663 Epoch 1562/2000
2025-02-19 08:57:05,576 Current Learning Rate: 0.0091354029
2025-02-19 08:57:05,582 Train Loss: 0.0002684, Val Loss: 0.0003981
2025-02-19 08:57:05,583 Epoch 1563/2000
2025-02-19 08:57:48,427 Current Learning Rate: 0.0091790368
2025-02-19 08:57:48,428 Train Loss: 0.0002909, Val Loss: 0.0003039
2025-02-19 08:57:48,428 Epoch 1564/2000
2025-02-19 08:58:31,779 Current Learning Rate: 0.0092216396
2025-02-19 08:58:31,779 Train Loss: 0.0003100, Val Loss: 0.0004087
2025-02-19 08:58:31,779 Epoch 1565/2000
2025-02-19 08:59:14,876 Current Learning Rate: 0.0092632008
2025-02-19 08:59:14,876 Train Loss: 0.0002565, Val Loss: 0.0003147
2025-02-19 08:59:14,877 Epoch 1566/2000
2025-02-19 08:59:56,864 Current Learning Rate: 0.0093037101
2025-02-19 08:59:56,865 Train Loss: 0.0002524, Val Loss: 0.0003331
2025-02-19 08:59:56,865 Epoch 1567/2000
2025-02-19 09:00:40,291 Current Learning Rate: 0.0093431576
2025-02-19 09:00:40,292 Train Loss: 0.0002138, Val Loss: 0.0003181
2025-02-19 09:00:40,292 Epoch 1568/2000
2025-02-19 09:01:22,366 Current Learning Rate: 0.0093815334
2025-02-19 09:01:22,366 Train Loss: 0.0003294, Val Loss: 0.0004356
2025-02-19 09:01:22,367 Epoch 1569/2000
2025-02-19 09:02:05,118 Current Learning Rate: 0.0094188282
2025-02-19 09:02:05,119 Train Loss: 0.0002855, Val Loss: 0.0003168
2025-02-19 09:02:05,119 Epoch 1570/2000
2025-02-19 09:02:48,224 Current Learning Rate: 0.0094550326
2025-02-19 09:02:48,225 Train Loss: 0.0002839, Val Loss: 0.0003345
2025-02-19 09:02:48,225 Epoch 1571/2000
2025-02-19 09:03:31,206 Current Learning Rate: 0.0094901379
2025-02-19 09:03:31,206 Train Loss: 0.0002302, Val Loss: 0.0003205
2025-02-19 09:03:31,206 Epoch 1572/2000
2025-02-19 09:04:13,715 Current Learning Rate: 0.0095241353
2025-02-19 09:04:13,716 Train Loss: 0.0002399, Val Loss: 0.0003471
2025-02-19 09:04:13,716 Epoch 1573/2000
2025-02-19 09:04:56,137 Current Learning Rate: 0.0095570164
2025-02-19 09:04:56,138 Train Loss: 0.0002557, Val Loss: 0.0003277
2025-02-19 09:04:56,139 Epoch 1574/2000
2025-02-19 09:05:38,987 Current Learning Rate: 0.0095887731
2025-02-19 09:05:38,987 Train Loss: 0.0003472, Val Loss: 0.0003464
2025-02-19 09:05:38,988 Epoch 1575/2000
2025-02-19 09:06:20,933 Current Learning Rate: 0.0096193977
2025-02-19 09:06:20,934 Train Loss: 0.0002312, Val Loss: 0.0002899
2025-02-19 09:06:20,934 Epoch 1576/2000
2025-02-19 09:07:03,799 Current Learning Rate: 0.0096488824
2025-02-19 09:07:03,799 Train Loss: 0.0002064, Val Loss: 0.0002947
2025-02-19 09:07:03,800 Epoch 1577/2000
2025-02-19 09:07:46,990 Current Learning Rate: 0.0096772202
2025-02-19 09:07:46,991 Train Loss: 0.0002814, Val Loss: 0.0003216
2025-02-19 09:07:47,018 Epoch 1578/2000
2025-02-19 09:08:28,920 Current Learning Rate: 0.0097044038
2025-02-19 09:08:28,921 Train Loss: 0.0002777, Val Loss: 0.0003434
2025-02-19 09:08:28,922 Epoch 1579/2000
2025-02-19 09:09:11,370 Current Learning Rate: 0.0097304268
2025-02-19 09:09:11,371 Train Loss: 0.0003055, Val Loss: 0.0003128
2025-02-19 09:09:11,371 Epoch 1580/2000
2025-02-19 09:09:54,257 Current Learning Rate: 0.0097552826
2025-02-19 09:09:54,258 Train Loss: 0.0003652, Val Loss: 0.0004352
2025-02-19 09:09:54,258 Epoch 1581/2000
2025-02-19 09:10:37,224 Current Learning Rate: 0.0097789651
2025-02-19 09:10:37,225 Train Loss: 0.0002872, Val Loss: 0.0003580
2025-02-19 09:10:37,225 Epoch 1582/2000
2025-02-19 09:11:20,234 Current Learning Rate: 0.0098014684
2025-02-19 09:11:20,234 Train Loss: 0.0005867, Val Loss: 0.0005102
2025-02-19 09:11:20,235 Epoch 1583/2000
2025-02-19 09:12:03,101 Current Learning Rate: 0.0098227871
2025-02-19 09:12:03,102 Train Loss: 0.0004367, Val Loss: 0.0003194
2025-02-19 09:12:03,102 Epoch 1584/2000
2025-02-19 09:12:46,051 Current Learning Rate: 0.0098429158
2025-02-19 09:12:46,051 Train Loss: 0.0003085, Val Loss: 0.0003412
2025-02-19 09:12:46,051 Epoch 1585/2000
2025-02-19 09:13:28,185 Current Learning Rate: 0.0098618496
2025-02-19 09:13:28,186 Train Loss: 0.0003700, Val Loss: 0.0003821
2025-02-19 09:13:28,186 Epoch 1586/2000
2025-02-19 09:14:11,328 Current Learning Rate: 0.0098795838
2025-02-19 09:14:11,329 Train Loss: 0.0002836, Val Loss: 0.0002979
2025-02-19 09:14:11,329 Epoch 1587/2000
2025-02-19 09:14:54,638 Current Learning Rate: 0.0098961141
2025-02-19 09:14:54,639 Train Loss: 0.0002756, Val Loss: 0.0002496
2025-02-19 09:14:54,639 Epoch 1588/2000
2025-02-19 09:15:36,515 Current Learning Rate: 0.0099114363
2025-02-19 09:15:36,515 Train Loss: 0.0002898, Val Loss: 0.0002686
2025-02-19 09:15:36,516 Epoch 1589/2000
2025-02-19 09:16:19,076 Current Learning Rate: 0.0099255466
2025-02-19 09:16:19,077 Train Loss: 0.0002404, Val Loss: 0.0002352
2025-02-19 09:16:19,077 Epoch 1590/2000
2025-02-19 09:17:02,084 Current Learning Rate: 0.0099384417
2025-02-19 09:17:02,085 Train Loss: 0.0002026, Val Loss: 0.0002316
2025-02-19 09:17:02,085 Epoch 1591/2000
2025-02-19 09:17:44,639 Current Learning Rate: 0.0099501183
2025-02-19 09:17:44,639 Train Loss: 0.0001676, Val Loss: 0.0002330
2025-02-19 09:17:44,640 Epoch 1592/2000
2025-02-19 09:18:27,135 Current Learning Rate: 0.0099605735
2025-02-19 09:18:27,136 Train Loss: 0.0002034, Val Loss: 0.0002348
2025-02-19 09:18:27,136 Epoch 1593/2000
2025-02-19 09:19:09,203 Current Learning Rate: 0.0099698048
2025-02-19 09:19:09,204 Train Loss: 0.0001832, Val Loss: 0.0002477
2025-02-19 09:19:09,204 Epoch 1594/2000
2025-02-19 09:19:51,481 Current Learning Rate: 0.0099778098
2025-02-19 09:19:51,481 Train Loss: 0.0001805, Val Loss: 0.0002525
2025-02-19 09:19:51,481 Epoch 1595/2000
2025-02-19 09:20:34,170 Current Learning Rate: 0.0099845867
2025-02-19 09:20:34,170 Train Loss: 0.0002115, Val Loss: 0.0002476
2025-02-19 09:20:34,171 Epoch 1596/2000
2025-02-19 09:21:16,605 Current Learning Rate: 0.0099901336
2025-02-19 09:21:16,605 Train Loss: 0.0002473, Val Loss: 0.0002739
2025-02-19 09:21:16,606 Epoch 1597/2000
2025-02-19 09:21:59,495 Current Learning Rate: 0.0099944494
2025-02-19 09:21:59,496 Train Loss: 0.0002047, Val Loss: 0.0002565
2025-02-19 09:21:59,496 Epoch 1598/2000
2025-02-19 09:22:42,799 Current Learning Rate: 0.0099975328
2025-02-19 09:22:42,799 Train Loss: 0.0001905, Val Loss: 0.0002592
2025-02-19 09:22:42,800 Epoch 1599/2000
2025-02-19 09:23:25,193 Current Learning Rate: 0.0099993832
2025-02-19 09:23:25,194 Train Loss: 0.0002237, Val Loss: 0.0002779
2025-02-19 09:23:25,194 Epoch 1600/2000
2025-02-19 09:24:08,309 Current Learning Rate: 0.0100000000
2025-02-19 09:24:08,310 Train Loss: 0.0002927, Val Loss: 0.0002949
2025-02-19 09:24:08,310 Epoch 1601/2000
2025-02-19 09:24:51,201 Current Learning Rate: 0.0099993832
2025-02-19 09:24:51,201 Train Loss: 0.0002353, Val Loss: 0.0002670
2025-02-19 09:24:51,202 Epoch 1602/2000
2025-02-19 09:25:34,175 Current Learning Rate: 0.0099975328
2025-02-19 09:25:34,175 Train Loss: 0.0002587, Val Loss: 0.0002710
2025-02-19 09:25:34,175 Epoch 1603/2000
2025-02-19 09:26:16,988 Current Learning Rate: 0.0099944494
2025-02-19 09:26:16,988 Train Loss: 0.0002121, Val Loss: 0.0002577
2025-02-19 09:26:16,988 Epoch 1604/2000
2025-02-19 09:26:59,569 Current Learning Rate: 0.0099901336
2025-02-19 09:26:59,570 Train Loss: 0.0002278, Val Loss: 0.0002654
2025-02-19 09:26:59,570 Epoch 1605/2000
2025-02-19 09:27:41,682 Current Learning Rate: 0.0099845867
2025-02-19 09:27:41,683 Train Loss: 0.0002458, Val Loss: 0.0002833
2025-02-19 09:27:41,684 Epoch 1606/2000
2025-02-19 09:28:24,761 Current Learning Rate: 0.0099778098
2025-02-19 09:28:24,761 Train Loss: 0.0001878, Val Loss: 0.0002676
2025-02-19 09:28:24,762 Epoch 1607/2000
2025-02-19 09:29:07,131 Current Learning Rate: 0.0099698048
2025-02-19 09:29:07,132 Train Loss: 0.0002379, Val Loss: 0.0002700
2025-02-19 09:29:07,132 Epoch 1608/2000
2025-02-19 09:29:49,596 Current Learning Rate: 0.0099605735
2025-02-19 09:29:49,597 Train Loss: 0.0002581, Val Loss: 0.0002632
2025-02-19 09:29:49,598 Epoch 1609/2000
2025-02-19 09:30:32,361 Current Learning Rate: 0.0099501183
2025-02-19 09:30:32,361 Train Loss: 0.0003075, Val Loss: 0.0002759
2025-02-19 09:30:32,362 Epoch 1610/2000
2025-02-19 09:31:14,803 Current Learning Rate: 0.0099384417
2025-02-19 09:31:14,804 Train Loss: 0.0002475, Val Loss: 0.0003342
2025-02-19 09:31:14,804 Epoch 1611/2000
2025-02-19 09:31:57,354 Current Learning Rate: 0.0099255466
2025-02-19 09:31:57,355 Train Loss: 0.0002522, Val Loss: 0.0002756
2025-02-19 09:31:57,355 Epoch 1612/2000
2025-02-19 09:32:40,478 Current Learning Rate: 0.0099114363
2025-02-19 09:32:40,478 Train Loss: 0.0002776, Val Loss: 0.0002887
2025-02-19 09:32:40,479 Epoch 1613/2000
2025-02-19 09:33:22,657 Current Learning Rate: 0.0098961141
2025-02-19 09:33:22,657 Train Loss: 0.0002157, Val Loss: 0.0002747
2025-02-19 09:33:22,658 Epoch 1614/2000
2025-02-19 09:34:04,620 Current Learning Rate: 0.0098795838
2025-02-19 09:34:04,621 Train Loss: 0.0002304, Val Loss: 0.0002682
2025-02-19 09:34:04,621 Epoch 1615/2000
2025-02-19 09:34:47,192 Current Learning Rate: 0.0098618496
2025-02-19 09:34:47,192 Train Loss: 0.0001979, Val Loss: 0.0002703
2025-02-19 09:34:47,193 Epoch 1616/2000
2025-02-19 09:35:30,351 Current Learning Rate: 0.0098429158
2025-02-19 09:35:30,352 Train Loss: 0.0002676, Val Loss: 0.0002633
2025-02-19 09:35:30,352 Epoch 1617/2000
2025-02-19 09:36:12,322 Current Learning Rate: 0.0098227871
2025-02-19 09:36:12,322 Train Loss: 0.0002367, Val Loss: 0.0002702
2025-02-19 09:36:12,323 Epoch 1618/2000
2025-02-19 09:36:54,959 Current Learning Rate: 0.0098014684
2025-02-19 09:36:54,960 Train Loss: 0.0002292, Val Loss: 0.0002609
2025-02-19 09:36:54,960 Epoch 1619/2000
2025-02-19 09:37:38,086 Current Learning Rate: 0.0097789651
2025-02-19 09:37:38,087 Train Loss: 0.0002406, Val Loss: 0.0002725
2025-02-19 09:37:38,087 Epoch 1620/2000
2025-02-19 09:38:21,246 Current Learning Rate: 0.0097552826
2025-02-19 09:38:21,248 Train Loss: 0.0001725, Val Loss: 0.0003059
2025-02-19 09:38:21,248 Epoch 1621/2000
2025-02-19 09:39:03,394 Current Learning Rate: 0.0097304268
2025-02-19 09:39:03,395 Train Loss: 0.0002304, Val Loss: 0.0002967
2025-02-19 09:39:03,395 Epoch 1622/2000
2025-02-19 09:39:45,495 Current Learning Rate: 0.0097044038
2025-02-19 09:39:45,496 Train Loss: 0.0002388, Val Loss: 0.0002990
2025-02-19 09:39:45,497 Epoch 1623/2000
2025-02-19 09:40:28,714 Current Learning Rate: 0.0096772202
2025-02-19 09:40:28,714 Train Loss: 0.0002905, Val Loss: 0.0005311
2025-02-19 09:40:28,731 Epoch 1624/2000
2025-02-19 09:41:11,763 Current Learning Rate: 0.0096488824
2025-02-19 09:41:11,764 Train Loss: 0.0004078, Val Loss: 0.0003294
2025-02-19 09:41:11,764 Epoch 1625/2000
2025-02-19 09:41:54,919 Current Learning Rate: 0.0096193977
2025-02-19 09:41:54,920 Train Loss: 0.0002248, Val Loss: 0.0002973
2025-02-19 09:41:54,920 Epoch 1626/2000
2025-02-19 09:42:38,383 Current Learning Rate: 0.0095887731
2025-02-19 09:42:38,384 Train Loss: 0.0002325, Val Loss: 0.0002689
2025-02-19 09:42:38,410 Epoch 1627/2000
2025-02-19 09:43:21,573 Current Learning Rate: 0.0095570164
2025-02-19 09:43:21,574 Train Loss: 0.0002908, Val Loss: 0.0002823
2025-02-19 09:43:21,574 Epoch 1628/2000
2025-02-19 09:44:04,066 Current Learning Rate: 0.0095241353
2025-02-19 09:44:04,067 Train Loss: 0.0002969, Val Loss: 0.0003105
2025-02-19 09:44:04,067 Epoch 1629/2000
2025-02-19 09:44:46,454 Current Learning Rate: 0.0094901379
2025-02-19 09:44:46,454 Train Loss: 0.0003243, Val Loss: 0.0002674
2025-02-19 09:44:46,454 Epoch 1630/2000
2025-02-19 09:45:29,671 Current Learning Rate: 0.0094550326
2025-02-19 09:45:29,671 Train Loss: 0.0002718, Val Loss: 0.0002601
2025-02-19 09:45:29,671 Epoch 1631/2000
2025-02-19 09:46:11,831 Current Learning Rate: 0.0094188282
2025-02-19 09:46:11,832 Train Loss: 0.0002243, Val Loss: 0.0002562
2025-02-19 09:46:11,832 Epoch 1632/2000
2025-02-19 09:46:54,900 Current Learning Rate: 0.0093815334
2025-02-19 09:46:54,901 Train Loss: 0.0002142, Val Loss: 0.0002776
2025-02-19 09:46:54,901 Epoch 1633/2000
2025-02-19 09:47:37,671 Current Learning Rate: 0.0093431576
2025-02-19 09:47:37,672 Train Loss: 0.0001991, Val Loss: 0.0002457
2025-02-19 09:47:37,672 Epoch 1634/2000
2025-02-19 09:48:20,161 Current Learning Rate: 0.0093037101
2025-02-19 09:48:20,162 Train Loss: 0.0002672, Val Loss: 0.0002986
2025-02-19 09:48:20,162 Epoch 1635/2000
2025-02-19 09:49:02,908 Current Learning Rate: 0.0092632008
2025-02-19 09:49:02,909 Train Loss: 0.0002957, Val Loss: 0.0003189
2025-02-19 09:49:02,909 Epoch 1636/2000
2025-02-19 09:49:46,008 Current Learning Rate: 0.0092216396
2025-02-19 09:49:46,009 Train Loss: 0.0002988, Val Loss: 0.0003616
2025-02-19 09:49:46,009 Epoch 1637/2000
2025-02-19 09:50:29,052 Current Learning Rate: 0.0091790368
2025-02-19 09:50:29,053 Train Loss: 0.0002641, Val Loss: 0.0004105
2025-02-19 09:50:29,053 Epoch 1638/2000
2025-02-19 09:51:11,860 Current Learning Rate: 0.0091354029
2025-02-19 09:51:11,862 Train Loss: 0.0003434, Val Loss: 0.0003362
2025-02-19 09:51:11,862 Epoch 1639/2000
2025-02-19 09:51:54,988 Current Learning Rate: 0.0090907486
2025-02-19 09:51:54,989 Train Loss: 0.0002708, Val Loss: 0.0002941
2025-02-19 09:51:54,989 Epoch 1640/2000
2025-02-19 09:52:38,360 Current Learning Rate: 0.0090450850
2025-02-19 09:52:38,361 Train Loss: 0.0004133, Val Loss: 0.0004922
2025-02-19 09:52:38,361 Epoch 1641/2000
2025-02-19 09:53:22,131 Current Learning Rate: 0.0089984233
2025-02-19 09:53:22,131 Train Loss: 0.0003010, Val Loss: 0.0002547
2025-02-19 09:53:22,132 Epoch 1642/2000
2025-02-19 09:54:04,699 Current Learning Rate: 0.0089507751
2025-02-19 09:54:04,700 Train Loss: 0.0001816, Val Loss: 0.0002466
2025-02-19 09:54:04,700 Epoch 1643/2000
2025-02-19 09:54:47,929 Current Learning Rate: 0.0089021520
2025-02-19 09:54:47,930 Train Loss: 0.0002275, Val Loss: 0.0002345
2025-02-19 09:54:47,930 Epoch 1644/2000
2025-02-19 09:55:30,883 Current Learning Rate: 0.0088525662
2025-02-19 09:55:30,883 Train Loss: 0.0001878, Val Loss: 0.0002415
2025-02-19 09:55:30,884 Epoch 1645/2000
2025-02-19 09:56:13,953 Current Learning Rate: 0.0088020298
2025-02-19 09:56:13,954 Train Loss: 0.0002528, Val Loss: 0.0002482
2025-02-19 09:56:13,954 Epoch 1646/2000
2025-02-19 09:56:57,409 Current Learning Rate: 0.0087505553
2025-02-19 09:56:57,410 Train Loss: 0.0001908, Val Loss: 0.0002499
2025-02-19 09:56:57,410 Epoch 1647/2000
2025-02-19 09:57:39,847 Current Learning Rate: 0.0086981555
2025-02-19 09:57:39,848 Train Loss: 0.0002432, Val Loss: 0.0002435
2025-02-19 09:57:39,849 Epoch 1648/2000
2025-02-19 09:58:22,417 Current Learning Rate: 0.0086448431
2025-02-19 09:58:22,418 Train Loss: 0.0002923, Val Loss: 0.0003018
2025-02-19 09:58:22,418 Epoch 1649/2000
2025-02-19 09:59:05,106 Current Learning Rate: 0.0085906315
2025-02-19 09:59:05,107 Train Loss: 0.0002096, Val Loss: 0.0002283
2025-02-19 09:59:05,107 Epoch 1650/2000
2025-02-19 09:59:48,233 Current Learning Rate: 0.0085355339
2025-02-19 09:59:48,234 Train Loss: 0.0001936, Val Loss: 0.0002239
2025-02-19 09:59:48,234 Epoch 1651/2000
2025-02-19 10:00:32,028 Current Learning Rate: 0.0084795640
2025-02-19 10:00:32,029 Train Loss: 0.0002051, Val Loss: 0.0002288
2025-02-19 10:00:32,029 Epoch 1652/2000
2025-02-19 10:01:15,682 Current Learning Rate: 0.0084227355
2025-02-19 10:01:15,683 Train Loss: 0.0001934, Val Loss: 0.0002536
2025-02-19 10:01:15,684 Epoch 1653/2000
2025-02-19 10:01:58,054 Current Learning Rate: 0.0083650626
2025-02-19 10:01:58,055 Train Loss: 0.0001884, Val Loss: 0.0002708
2025-02-19 10:01:58,055 Epoch 1654/2000
2025-02-19 10:02:40,231 Current Learning Rate: 0.0083065593
2025-02-19 10:02:40,231 Train Loss: 0.0001937, Val Loss: 0.0002945
2025-02-19 10:02:40,231 Epoch 1655/2000
2025-02-19 10:03:23,175 Current Learning Rate: 0.0082472402
2025-02-19 10:03:23,175 Train Loss: 0.0002469, Val Loss: 0.0002605
2025-02-19 10:03:23,176 Epoch 1656/2000
2025-02-19 10:04:05,877 Current Learning Rate: 0.0081871199
2025-02-19 10:04:05,878 Train Loss: 0.0002953, Val Loss: 0.0002979
2025-02-19 10:04:05,878 Epoch 1657/2000
2025-02-19 10:04:49,286 Current Learning Rate: 0.0081262133
2025-02-19 10:04:49,287 Train Loss: 0.0002433, Val Loss: 0.0002573
2025-02-19 10:04:49,287 Epoch 1658/2000
2025-02-19 10:05:32,426 Current Learning Rate: 0.0080645353
2025-02-19 10:05:32,426 Train Loss: 0.0002056, Val Loss: 0.0002339
2025-02-19 10:05:32,426 Epoch 1659/2000
2025-02-19 10:06:14,552 Current Learning Rate: 0.0080021011
2025-02-19 10:06:14,552 Train Loss: 0.0001758, Val Loss: 0.0002204
2025-02-19 10:06:14,552 Epoch 1660/2000
2025-02-19 10:06:57,614 Current Learning Rate: 0.0079389263
2025-02-19 10:06:57,615 Train Loss: 0.0001951, Val Loss: 0.0002218
2025-02-19 10:06:57,615 Epoch 1661/2000
2025-02-19 10:07:40,525 Current Learning Rate: 0.0078750263
2025-02-19 10:07:40,526 Train Loss: 0.0002073, Val Loss: 0.0002191
2025-02-19 10:07:40,526 Epoch 1662/2000
2025-02-19 10:08:23,576 Current Learning Rate: 0.0078104169
2025-02-19 10:08:23,577 Train Loss: 0.0001961, Val Loss: 0.0002135
2025-02-19 10:08:23,577 Epoch 1663/2000
2025-02-19 10:09:06,303 Current Learning Rate: 0.0077451141
2025-02-19 10:09:06,304 Train Loss: 0.0001724, Val Loss: 0.0002208
2025-02-19 10:09:06,304 Epoch 1664/2000
2025-02-19 10:09:48,667 Current Learning Rate: 0.0076791340
2025-02-19 10:09:48,667 Train Loss: 0.0001803, Val Loss: 0.0002248
2025-02-19 10:09:48,667 Epoch 1665/2000
2025-02-19 10:10:31,222 Current Learning Rate: 0.0076124928
2025-02-19 10:10:31,223 Train Loss: 0.0001806, Val Loss: 0.0002272
2025-02-19 10:10:31,223 Epoch 1666/2000
2025-02-19 10:11:13,651 Current Learning Rate: 0.0075452071
2025-02-19 10:11:13,652 Train Loss: 0.0001736, Val Loss: 0.0002255
2025-02-19 10:11:13,652 Epoch 1667/2000
2025-02-19 10:11:56,233 Current Learning Rate: 0.0074772933
2025-02-19 10:11:56,234 Train Loss: 0.0001418, Val Loss: 0.0002225
2025-02-19 10:11:56,234 Epoch 1668/2000
2025-02-19 10:12:38,573 Current Learning Rate: 0.0074087684
2025-02-19 10:12:38,574 Train Loss: 0.0001704, Val Loss: 0.0002238
2025-02-19 10:12:38,574 Epoch 1669/2000
2025-02-19 10:13:21,175 Current Learning Rate: 0.0073396491
2025-02-19 10:13:21,175 Train Loss: 0.0002268, Val Loss: 0.0002252
2025-02-19 10:13:21,175 Epoch 1670/2000
2025-02-19 10:14:04,527 Current Learning Rate: 0.0072699525
2025-02-19 10:14:04,527 Train Loss: 0.0001976, Val Loss: 0.0002204
2025-02-19 10:14:04,527 Epoch 1671/2000
2025-02-19 10:14:47,697 Current Learning Rate: 0.0071996958
2025-02-19 10:14:47,698 Train Loss: 0.0001554, Val Loss: 0.0002144
2025-02-19 10:14:47,698 Epoch 1672/2000
2025-02-19 10:15:30,502 Current Learning Rate: 0.0071288965
2025-02-19 10:15:30,502 Train Loss: 0.0001801, Val Loss: 0.0002126
2025-02-19 10:15:30,502 Epoch 1673/2000
2025-02-19 10:16:13,637 Current Learning Rate: 0.0070575718
2025-02-19 10:16:13,637 Train Loss: 0.0002318, Val Loss: 0.0002162
2025-02-19 10:16:13,638 Epoch 1674/2000
2025-02-19 10:16:56,130 Current Learning Rate: 0.0069857395
2025-02-19 10:16:56,131 Train Loss: 0.0001830, Val Loss: 0.0002118
2025-02-19 10:16:56,131 Epoch 1675/2000
2025-02-19 10:17:38,892 Current Learning Rate: 0.0069134172
2025-02-19 10:17:38,893 Train Loss: 0.0001627, Val Loss: 0.0002141
2025-02-19 10:17:38,893 Epoch 1676/2000
2025-02-19 10:18:21,555 Current Learning Rate: 0.0068406228
2025-02-19 10:18:21,555 Train Loss: 0.0002087, Val Loss: 0.0002275
2025-02-19 10:18:21,556 Epoch 1677/2000
2025-02-19 10:19:03,574 Current Learning Rate: 0.0067673742
2025-02-19 10:19:03,575 Train Loss: 0.0001394, Val Loss: 0.0002252
2025-02-19 10:19:03,575 Epoch 1678/2000
2025-02-19 10:19:45,977 Current Learning Rate: 0.0066936896
2025-02-19 10:19:45,977 Train Loss: 0.0001526, Val Loss: 0.0002338
2025-02-19 10:19:45,977 Epoch 1679/2000
2025-02-19 10:20:29,134 Current Learning Rate: 0.0066195871
2025-02-19 10:20:29,135 Train Loss: 0.0001597, Val Loss: 0.0002561
2025-02-19 10:20:29,135 Epoch 1680/2000
2025-02-19 10:21:12,176 Current Learning Rate: 0.0065450850
2025-02-19 10:21:12,177 Train Loss: 0.0002065, Val Loss: 0.0002654
2025-02-19 10:21:12,177 Epoch 1681/2000
2025-02-19 10:21:54,847 Current Learning Rate: 0.0064702016
2025-02-19 10:21:54,848 Train Loss: 0.0002071, Val Loss: 0.0002726
2025-02-19 10:21:54,848 Epoch 1682/2000
2025-02-19 10:22:37,788 Current Learning Rate: 0.0063949555
2025-02-19 10:22:37,789 Train Loss: 0.0002267, Val Loss: 0.0002320
2025-02-19 10:22:37,789 Epoch 1683/2000
2025-02-19 10:23:20,033 Current Learning Rate: 0.0063193652
2025-02-19 10:23:20,034 Train Loss: 0.0001583, Val Loss: 0.0002230
2025-02-19 10:23:20,034 Epoch 1684/2000
2025-02-19 10:24:03,351 Current Learning Rate: 0.0062434494
2025-02-19 10:24:03,352 Train Loss: 0.0002333, Val Loss: 0.0002360
2025-02-19 10:24:03,352 Epoch 1685/2000
2025-02-19 10:24:46,290 Current Learning Rate: 0.0061672268
2025-02-19 10:24:46,290 Train Loss: 0.0001720, Val Loss: 0.0002120
2025-02-19 10:24:46,290 Epoch 1686/2000
2025-02-19 10:25:29,342 Current Learning Rate: 0.0060907162
2025-02-19 10:25:29,343 Train Loss: 0.0001615, Val Loss: 0.0002056
2025-02-19 10:25:29,343 Epoch 1687/2000
2025-02-19 10:26:11,949 Current Learning Rate: 0.0060139365
2025-02-19 10:26:11,949 Train Loss: 0.0001668, Val Loss: 0.0002014
2025-02-19 10:26:11,949 Epoch 1688/2000
2025-02-19 10:26:54,898 Current Learning Rate: 0.0059369066
2025-02-19 10:26:54,899 Train Loss: 0.0001672, Val Loss: 0.0002014
2025-02-19 10:26:54,899 Epoch 1689/2000
2025-02-19 10:27:37,572 Current Learning Rate: 0.0058596455
2025-02-19 10:27:37,572 Train Loss: 0.0001726, Val Loss: 0.0002031
2025-02-19 10:27:37,573 Epoch 1690/2000
2025-02-19 10:28:19,338 Current Learning Rate: 0.0057821723
2025-02-19 10:28:19,338 Train Loss: 0.0001944, Val Loss: 0.0002086
2025-02-19 10:28:19,339 Epoch 1691/2000
2025-02-19 10:29:01,941 Current Learning Rate: 0.0057045062
2025-02-19 10:29:01,942 Train Loss: 0.0002045, Val Loss: 0.0002185
2025-02-19 10:29:01,942 Epoch 1692/2000
2025-02-19 10:29:44,412 Current Learning Rate: 0.0056266662
2025-02-19 10:29:44,413 Train Loss: 0.0001981, Val Loss: 0.0002047
2025-02-19 10:29:44,413 Epoch 1693/2000
2025-02-19 10:30:27,621 Current Learning Rate: 0.0055486716
2025-02-19 10:30:27,622 Train Loss: 0.0001535, Val Loss: 0.0002047
2025-02-19 10:30:27,622 Epoch 1694/2000
2025-02-19 10:31:10,958 Current Learning Rate: 0.0054705416
2025-02-19 10:31:10,958 Train Loss: 0.0001417, Val Loss: 0.0002046
2025-02-19 10:31:10,959 Epoch 1695/2000
2025-02-19 10:31:53,852 Current Learning Rate: 0.0053922955
2025-02-19 10:31:53,852 Train Loss: 0.0001232, Val Loss: 0.0002031
2025-02-19 10:31:53,887 Epoch 1696/2000
2025-02-19 10:32:36,908 Current Learning Rate: 0.0053139526
2025-02-19 10:32:36,909 Train Loss: 0.0001290, Val Loss: 0.0002043
2025-02-19 10:32:36,909 Epoch 1697/2000
2025-02-19 10:33:18,765 Current Learning Rate: 0.0052355323
2025-02-19 10:33:18,765 Train Loss: 0.0001534, Val Loss: 0.0002079
2025-02-19 10:33:18,766 Epoch 1698/2000
2025-02-19 10:34:01,022 Current Learning Rate: 0.0051570538
2025-02-19 10:34:01,023 Train Loss: 0.0001871, Val Loss: 0.0002070
2025-02-19 10:34:01,023 Epoch 1699/2000
2025-02-19 10:34:43,310 Current Learning Rate: 0.0050785366
2025-02-19 10:34:43,311 Train Loss: 0.0001549, Val Loss: 0.0002044
2025-02-19 10:34:43,311 Epoch 1700/2000
2025-02-19 10:35:25,658 Current Learning Rate: 0.0050000000
2025-02-19 10:35:25,659 Train Loss: 0.0001552, Val Loss: 0.0002023
2025-02-19 10:35:25,659 Epoch 1701/2000
2025-02-19 10:36:08,029 Current Learning Rate: 0.0049214634
2025-02-19 10:36:08,030 Train Loss: 0.0001636, Val Loss: 0.0002007
2025-02-19 10:36:08,030 Epoch 1702/2000
2025-02-19 10:36:50,268 Current Learning Rate: 0.0048429462
2025-02-19 10:36:50,269 Train Loss: 0.0001980, Val Loss: 0.0001999
2025-02-19 10:36:50,269 Epoch 1703/2000
2025-02-19 10:37:33,649 Current Learning Rate: 0.0047644677
2025-02-19 10:37:33,650 Train Loss: 0.0001826, Val Loss: 0.0002055
2025-02-19 10:37:33,650 Epoch 1704/2000
2025-02-19 10:38:16,344 Current Learning Rate: 0.0046860474
2025-02-19 10:38:16,344 Train Loss: 0.0001670, Val Loss: 0.0002095
2025-02-19 10:38:16,345 Epoch 1705/2000
2025-02-19 10:38:58,866 Current Learning Rate: 0.0046077045
2025-02-19 10:38:58,867 Train Loss: 0.0001822, Val Loss: 0.0002067
2025-02-19 10:38:58,868 Epoch 1706/2000
2025-02-19 10:39:40,846 Current Learning Rate: 0.0045294584
2025-02-19 10:39:40,847 Train Loss: 0.0001717, Val Loss: 0.0002086
2025-02-19 10:39:40,847 Epoch 1707/2000
2025-02-19 10:40:23,375 Current Learning Rate: 0.0044513284
2025-02-19 10:40:23,375 Train Loss: 0.0001635, Val Loss: 0.0002265
2025-02-19 10:40:23,375 Epoch 1708/2000
2025-02-19 10:41:06,307 Current Learning Rate: 0.0043733338
2025-02-19 10:41:06,307 Train Loss: 0.0001665, Val Loss: 0.0002255
2025-02-19 10:41:06,308 Epoch 1709/2000
2025-02-19 10:41:48,429 Current Learning Rate: 0.0042954938
2025-02-19 10:41:48,430 Train Loss: 0.0001882, Val Loss: 0.0002023
2025-02-19 10:41:48,430 Epoch 1710/2000
2025-02-19 10:42:30,935 Current Learning Rate: 0.0042178277
2025-02-19 10:42:30,936 Train Loss: 0.0002167, Val Loss: 0.0002014
2025-02-19 10:42:30,936 Epoch 1711/2000
2025-02-19 10:43:13,367 Current Learning Rate: 0.0041403545
2025-02-19 10:43:13,367 Train Loss: 0.0001915, Val Loss: 0.0002015
2025-02-19 10:43:13,368 Epoch 1712/2000
2025-02-19 10:43:55,743 Current Learning Rate: 0.0040630934
2025-02-19 10:43:55,743 Train Loss: 0.0001431, Val Loss: 0.0001962
2025-02-19 10:43:55,744 Epoch 1713/2000
2025-02-19 10:44:38,233 Current Learning Rate: 0.0039860635
2025-02-19 10:44:39,737 Train Loss: 0.0001364, Val Loss: 0.0001943
2025-02-19 10:44:39,737 Epoch 1714/2000
2025-02-19 10:45:22,551 Current Learning Rate: 0.0039092838
2025-02-19 10:45:24,597 Train Loss: 0.0001314, Val Loss: 0.0001934
2025-02-19 10:45:24,598 Epoch 1715/2000
2025-02-19 10:46:07,167 Current Learning Rate: 0.0038327732
2025-02-19 10:46:09,093 Train Loss: 0.0002020, Val Loss: 0.0001908
2025-02-19 10:46:09,093 Epoch 1716/2000
2025-02-19 10:46:51,822 Current Learning Rate: 0.0037565506
2025-02-19 10:46:53,872 Train Loss: 0.0001500, Val Loss: 0.0001890
2025-02-19 10:46:53,872 Epoch 1717/2000
2025-02-19 10:47:35,049 Current Learning Rate: 0.0036806348
2025-02-19 10:47:36,818 Train Loss: 0.0001583, Val Loss: 0.0001882
2025-02-19 10:47:36,819 Epoch 1718/2000
2025-02-19 10:48:18,213 Current Learning Rate: 0.0036050445
2025-02-19 10:48:18,214 Train Loss: 0.0001931, Val Loss: 0.0001923
2025-02-19 10:48:18,214 Epoch 1719/2000
2025-02-19 10:49:00,414 Current Learning Rate: 0.0035297984
2025-02-19 10:49:00,414 Train Loss: 0.0001274, Val Loss: 0.0001897
2025-02-19 10:49:00,415 Epoch 1720/2000
2025-02-19 10:49:43,169 Current Learning Rate: 0.0034549150
2025-02-19 10:49:43,169 Train Loss: 0.0001133, Val Loss: 0.0001902
2025-02-19 10:49:43,170 Epoch 1721/2000
2025-02-19 10:50:25,447 Current Learning Rate: 0.0033804129
2025-02-19 10:50:25,449 Train Loss: 0.0001188, Val Loss: 0.0001900
2025-02-19 10:50:25,449 Epoch 1722/2000
2025-02-19 10:51:07,680 Current Learning Rate: 0.0033063104
2025-02-19 10:51:07,680 Train Loss: 0.0001248, Val Loss: 0.0001912
2025-02-19 10:51:07,681 Epoch 1723/2000
2025-02-19 10:51:50,357 Current Learning Rate: 0.0032326258
2025-02-19 10:51:50,357 Train Loss: 0.0001197, Val Loss: 0.0001914
2025-02-19 10:51:50,358 Epoch 1724/2000
2025-02-19 10:52:33,306 Current Learning Rate: 0.0031593772
2025-02-19 10:52:33,306 Train Loss: 0.0001763, Val Loss: 0.0001917
2025-02-19 10:52:33,306 Epoch 1725/2000
2025-02-19 10:53:16,277 Current Learning Rate: 0.0030865828
2025-02-19 10:53:16,278 Train Loss: 0.0001528, Val Loss: 0.0001898
2025-02-19 10:53:16,278 Epoch 1726/2000
2025-02-19 10:53:59,220 Current Learning Rate: 0.0030142605
2025-02-19 10:53:59,220 Train Loss: 0.0001919, Val Loss: 0.0001885
2025-02-19 10:53:59,221 Epoch 1727/2000
2025-02-19 10:54:41,168 Current Learning Rate: 0.0029424282
2025-02-19 10:54:42,781 Train Loss: 0.0001527, Val Loss: 0.0001860
2025-02-19 10:54:42,782 Epoch 1728/2000
2025-02-19 10:55:24,580 Current Learning Rate: 0.0028711035
2025-02-19 10:55:24,581 Train Loss: 0.0001788, Val Loss: 0.0001863
2025-02-19 10:55:24,581 Epoch 1729/2000
2025-02-19 10:56:07,480 Current Learning Rate: 0.0028003042
2025-02-19 10:56:09,049 Train Loss: 0.0001536, Val Loss: 0.0001857
2025-02-19 10:56:09,050 Epoch 1730/2000
2025-02-19 10:56:50,612 Current Learning Rate: 0.0027300475
2025-02-19 10:56:51,968 Train Loss: 0.0001604, Val Loss: 0.0001852
2025-02-19 10:56:51,968 Epoch 1731/2000
2025-02-19 10:57:33,530 Current Learning Rate: 0.0026603509
2025-02-19 10:57:35,070 Train Loss: 0.0001426, Val Loss: 0.0001848
2025-02-19 10:57:35,071 Epoch 1732/2000
2025-02-19 10:58:17,582 Current Learning Rate: 0.0025912316
2025-02-19 10:58:19,516 Train Loss: 0.0001639, Val Loss: 0.0001834
2025-02-19 10:58:19,516 Epoch 1733/2000
2025-02-19 10:59:01,818 Current Learning Rate: 0.0025227067
2025-02-19 10:59:04,175 Train Loss: 0.0001128, Val Loss: 0.0001827
2025-02-19 10:59:04,176 Epoch 1734/2000
2025-02-19 10:59:47,503 Current Learning Rate: 0.0024547929
2025-02-19 10:59:47,504 Train Loss: 0.0001674, Val Loss: 0.0001830
2025-02-19 10:59:47,504 Epoch 1735/2000
2025-02-19 11:00:31,070 Current Learning Rate: 0.0023875072
2025-02-19 11:00:31,071 Train Loss: 0.0001733, Val Loss: 0.0001829
2025-02-19 11:00:31,071 Epoch 1736/2000
2025-02-19 11:01:13,992 Current Learning Rate: 0.0023208660
2025-02-19 11:01:15,800 Train Loss: 0.0001913, Val Loss: 0.0001820
2025-02-19 11:01:15,801 Epoch 1737/2000
2025-02-19 11:01:58,281 Current Learning Rate: 0.0022548859
2025-02-19 11:01:59,906 Train Loss: 0.0001643, Val Loss: 0.0001818
2025-02-19 11:01:59,907 Epoch 1738/2000
2025-02-19 11:02:42,284 Current Learning Rate: 0.0021895831
2025-02-19 11:02:43,516 Train Loss: 0.0001467, Val Loss: 0.0001811
2025-02-19 11:02:43,517 Epoch 1739/2000
2025-02-19 11:02:55,275 Loading best model from checkpoint.
2025-02-19 11:02:56,158 Error loading model checkpoint directly: Error(s) in loading state_dict for Triton:
	Missing key(s) in state_dict: "atmospheric_encoder.enc.0.conv.conv.weight", "atmospheric_encoder.enc.0.conv.conv.bias", "atmospheric_encoder.enc.0.conv.norm.weight", "atmospheric_encoder.enc.0.conv.norm.bias", "atmospheric_encoder.enc.1.conv.conv.weight", "atmospheric_encoder.enc.1.conv.conv.bias", "atmospheric_encoder.enc.1.conv.norm.weight", "atmospheric_encoder.enc.1.conv.norm.bias", "atmospheric_encoder.enc.2.conv.conv.weight", "atmospheric_encoder.enc.2.conv.conv.bias", "atmospheric_encoder.enc.2.conv.norm.weight", "atmospheric_encoder.enc.2.conv.norm.bias", "atmospheric_encoder.enc.3.conv.conv.weight", "atmospheric_encoder.enc.3.conv.conv.bias", "atmospheric_encoder.enc.3.conv.norm.weight", "atmospheric_encoder.enc.3.conv.norm.bias", "temporal_evolution.enc.0.block.pos_embed.weight", "temporal_evolution.enc.0.block.pos_embed.bias", "temporal_evolution.enc.0.block.norm1.weight", "temporal_evolution.enc.0.block.norm1.bias", "temporal_evolution.enc.0.block.norm1.running_mean", "temporal_evolution.enc.0.block.norm1.running_var", "temporal_evolution.enc.0.block.conv1.weight", "temporal_evolution.enc.0.block.conv1.bias", "temporal_evolution.enc.0.block.conv2.weight", "temporal_evolution.enc.0.block.conv2.bias", "temporal_evolution.enc.0.block.attn.weight", "temporal_evolution.enc.0.block.attn.bias", "temporal_evolution.enc.0.block.norm2.weight", "temporal_evolution.enc.0.block.norm2.bias", "temporal_evolution.enc.0.block.norm2.running_mean", "temporal_evolution.enc.0.block.norm2.running_var", "temporal_evolution.enc.0.block.mlp.fc1.weight", "temporal_evolution.enc.0.block.mlp.fc1.bias", "temporal_evolution.enc.0.block.mlp.fc2.weight", "temporal_evolution.enc.0.block.mlp.fc2.bias", "temporal_evolution.enc.0.reduction.weight", "temporal_evolution.enc.0.reduction.bias", "temporal_evolution.enc.1.block.gamma_1", "temporal_evolution.enc.1.block.gamma_2", "temporal_evolution.enc.1.block.pos_embed.weight", "temporal_evolution.enc.1.block.pos_embed.bias", "temporal_evolution.enc.1.block.norm1.weight", "temporal_evolution.enc.1.block.norm1.bias", "temporal_evolution.enc.1.block.attn.qkv.weight", "temporal_evolution.enc.1.block.attn.qkv.bias", "temporal_evolution.enc.1.block.attn.proj.weight", "temporal_evolution.enc.1.block.attn.proj.bias", "temporal_evolution.enc.1.block.norm2.weight", "temporal_evolution.enc.1.block.norm2.bias", "temporal_evolution.enc.1.block.mlp.fc1.weight", "temporal_evolution.enc.1.block.mlp.fc1.bias", "temporal_evolution.enc.1.block.mlp.fc2.weight", "temporal_evolution.enc.1.block.mlp.fc2.bias", "temporal_evolution.enc.2.block.gamma_1", "temporal_evolution.enc.2.block.gamma_2", "temporal_evolution.enc.2.block.pos_embed.weight", "temporal_evolution.enc.2.block.pos_embed.bias", "temporal_evolution.enc.2.block.norm1.weight", "temporal_evolution.enc.2.block.norm1.bias", "temporal_evolution.enc.2.block.attn.qkv.weight", "temporal_evolution.enc.2.block.attn.qkv.bias", "temporal_evolution.enc.2.block.attn.proj.weight", "temporal_evolution.enc.2.block.attn.proj.bias", "temporal_evolution.enc.2.block.norm2.weight", "temporal_evolution.enc.2.block.norm2.bias", "temporal_evolution.enc.2.block.mlp.fc1.weight", "temporal_evolution.enc.2.block.mlp.fc1.bias", "temporal_evolution.enc.2.block.mlp.fc2.weight", "temporal_evolution.enc.2.block.mlp.fc2.bias", "temporal_evolution.enc.3.block.gamma_1", "temporal_evolution.enc.3.block.gamma_2", "temporal_evolution.enc.3.block.pos_embed.weight", "temporal_evolution.enc.3.block.pos_embed.bias", "temporal_evolution.enc.3.block.norm1.weight", "temporal_evolution.enc.3.block.norm1.bias", "temporal_evolution.enc.3.block.attn.qkv.weight", "temporal_evolution.enc.3.block.attn.qkv.bias", "temporal_evolution.enc.3.block.attn.proj.weight", "temporal_evolution.enc.3.block.attn.proj.bias", "temporal_evolution.enc.3.block.norm2.weight", "temporal_evolution.enc.3.block.norm2.bias", "temporal_evolution.enc.3.block.mlp.fc1.weight", "temporal_evolution.enc.3.block.mlp.fc1.bias", "temporal_evolution.enc.3.block.mlp.fc2.weight", "temporal_evolution.enc.3.block.mlp.fc2.bias", "temporal_evolution.enc.4.block.gamma_1", "temporal_evolution.enc.4.block.gamma_2", "temporal_evolution.enc.4.block.pos_embed.weight", "temporal_evolution.enc.4.block.pos_embed.bias", "temporal_evolution.enc.4.block.norm1.weight", "temporal_evolution.enc.4.block.norm1.bias", "temporal_evolution.enc.4.block.attn.qkv.weight", "temporal_evolution.enc.4.block.attn.qkv.bias", "temporal_evolution.enc.4.block.attn.proj.weight", "temporal_evolution.enc.4.block.attn.proj.bias", "temporal_evolution.enc.4.block.norm2.weight", "temporal_evolution.enc.4.block.norm2.bias", "temporal_evolution.enc.4.block.mlp.fc1.weight", "temporal_evolution.enc.4.block.mlp.fc1.bias", "temporal_evolution.enc.4.block.mlp.fc2.weight", "temporal_evolution.enc.4.block.mlp.fc2.bias", "temporal_evolution.enc.5.block.gamma_1", "temporal_evolution.enc.5.block.gamma_2", "temporal_evolution.enc.5.block.pos_embed.weight", "temporal_evolution.enc.5.block.pos_embed.bias", "temporal_evolution.enc.5.block.norm1.weight", "temporal_evolution.enc.5.block.norm1.bias", "temporal_evolution.enc.5.block.attn.qkv.weight", "temporal_evolution.enc.5.block.attn.qkv.bias", "temporal_evolution.enc.5.block.attn.proj.weight", "temporal_evolution.enc.5.block.attn.proj.bias", "temporal_evolution.enc.5.block.norm2.weight", "temporal_evolution.enc.5.block.norm2.bias", "temporal_evolution.enc.5.block.mlp.fc1.weight", "temporal_evolution.enc.5.block.mlp.fc1.bias", "temporal_evolution.enc.5.block.mlp.fc2.weight", "temporal_evolution.enc.5.block.mlp.fc2.bias", "temporal_evolution.enc.6.block.gamma_1", "temporal_evolution.enc.6.block.gamma_2", "temporal_evolution.enc.6.block.pos_embed.weight", "temporal_evolution.enc.6.block.pos_embed.bias", "temporal_evolution.enc.6.block.norm1.weight", "temporal_evolution.enc.6.block.norm1.bias", "temporal_evolution.enc.6.block.attn.qkv.weight", "temporal_evolution.enc.6.block.attn.qkv.bias", "temporal_evolution.enc.6.block.attn.proj.weight", "temporal_evolution.enc.6.block.attn.proj.bias", "temporal_evolution.enc.6.block.norm2.weight", "temporal_evolution.enc.6.block.norm2.bias", "temporal_evolution.enc.6.block.mlp.fc1.weight", "temporal_evolution.enc.6.block.mlp.fc1.bias", "temporal_evolution.enc.6.block.mlp.fc2.weight", "temporal_evolution.enc.6.block.mlp.fc2.bias", "temporal_evolution.enc.7.block.pos_embed.weight", "temporal_evolution.enc.7.block.pos_embed.bias", "temporal_evolution.enc.7.block.norm1.weight", "temporal_evolution.enc.7.block.norm1.bias", "temporal_evolution.enc.7.block.norm1.running_mean", "temporal_evolution.enc.7.block.norm1.running_var", "temporal_evolution.enc.7.block.conv1.weight", "temporal_evolution.enc.7.block.conv1.bias", "temporal_evolution.enc.7.block.conv2.weight", "temporal_evolution.enc.7.block.conv2.bias", "temporal_evolution.enc.7.block.attn.weight", "temporal_evolution.enc.7.block.attn.bias", "temporal_evolution.enc.7.block.norm2.weight", "temporal_evolution.enc.7.block.norm2.bias", "temporal_evolution.enc.7.block.norm2.running_mean", "temporal_evolution.enc.7.block.norm2.running_var", "temporal_evolution.enc.7.block.mlp.fc1.weight", "temporal_evolution.enc.7.block.mlp.fc1.bias", "temporal_evolution.enc.7.block.mlp.fc2.weight", "temporal_evolution.enc.7.block.mlp.fc2.bias", "temporal_evolution.enc.7.reduction.weight", "temporal_evolution.enc.7.reduction.bias", "atmospheric_decoder.dec.0.conv.conv.weight", "atmospheric_decoder.dec.0.conv.conv.bias", "atmospheric_decoder.dec.0.conv.norm.weight", "atmospheric_decoder.dec.0.conv.norm.bias", "atmospheric_decoder.dec.1.conv.conv.weight", "atmospheric_decoder.dec.1.conv.conv.bias", "atmospheric_decoder.dec.1.conv.norm.weight", "atmospheric_decoder.dec.1.conv.norm.bias", "atmospheric_decoder.dec.2.conv.conv.weight", "atmospheric_decoder.dec.2.conv.conv.bias", "atmospheric_decoder.dec.2.conv.norm.weight", "atmospheric_decoder.dec.2.conv.norm.bias", "atmospheric_decoder.dec.3.conv.conv.weight", "atmospheric_decoder.dec.3.conv.conv.bias", "atmospheric_decoder.dec.3.conv.norm.weight", "atmospheric_decoder.dec.3.conv.norm.bias", "atmospheric_decoder.readout.weight", "atmospheric_decoder.readout.bias". 
	Unexpected key(s) in state_dict: "module.atmospheric_encoder.enc.0.conv.conv.weight", "module.atmospheric_encoder.enc.0.conv.conv.bias", "module.atmospheric_encoder.enc.0.conv.norm.weight", "module.atmospheric_encoder.enc.0.conv.norm.bias", "module.atmospheric_encoder.enc.1.conv.conv.weight", "module.atmospheric_encoder.enc.1.conv.conv.bias", "module.atmospheric_encoder.enc.1.conv.norm.weight", "module.atmospheric_encoder.enc.1.conv.norm.bias", "module.atmospheric_encoder.enc.2.conv.conv.weight", "module.atmospheric_encoder.enc.2.conv.conv.bias", "module.atmospheric_encoder.enc.2.conv.norm.weight", "module.atmospheric_encoder.enc.2.conv.norm.bias", "module.atmospheric_encoder.enc.3.conv.conv.weight", "module.atmospheric_encoder.enc.3.conv.conv.bias", "module.atmospheric_encoder.enc.3.conv.norm.weight", "module.atmospheric_encoder.enc.3.conv.norm.bias", "module.temporal_evolution.enc.0.block.pos_embed.weight", "module.temporal_evolution.enc.0.block.pos_embed.bias", "module.temporal_evolution.enc.0.block.norm1.weight", "module.temporal_evolution.enc.0.block.norm1.bias", "module.temporal_evolution.enc.0.block.norm1.running_mean", "module.temporal_evolution.enc.0.block.norm1.running_var", "module.temporal_evolution.enc.0.block.norm1.num_batches_tracked", "module.temporal_evolution.enc.0.block.conv1.weight", "module.temporal_evolution.enc.0.block.conv1.bias", "module.temporal_evolution.enc.0.block.conv2.weight", "module.temporal_evolution.enc.0.block.conv2.bias", "module.temporal_evolution.enc.0.block.attn.weight", "module.temporal_evolution.enc.0.block.attn.bias", "module.temporal_evolution.enc.0.block.norm2.weight", "module.temporal_evolution.enc.0.block.norm2.bias", "module.temporal_evolution.enc.0.block.norm2.running_mean", "module.temporal_evolution.enc.0.block.norm2.running_var", "module.temporal_evolution.enc.0.block.norm2.num_batches_tracked", "module.temporal_evolution.enc.0.block.mlp.fc1.weight", "module.temporal_evolution.enc.0.block.mlp.fc1.bias", "module.temporal_evolution.enc.0.block.mlp.fc2.weight", "module.temporal_evolution.enc.0.block.mlp.fc2.bias", "module.temporal_evolution.enc.0.reduction.weight", "module.temporal_evolution.enc.0.reduction.bias", "module.temporal_evolution.enc.1.block.gamma_1", "module.temporal_evolution.enc.1.block.gamma_2", "module.temporal_evolution.enc.1.block.pos_embed.weight", "module.temporal_evolution.enc.1.block.pos_embed.bias", "module.temporal_evolution.enc.1.block.norm1.weight", "module.temporal_evolution.enc.1.block.norm1.bias", "module.temporal_evolution.enc.1.block.attn.qkv.weight", "module.temporal_evolution.enc.1.block.attn.qkv.bias", "module.temporal_evolution.enc.1.block.attn.proj.weight", "module.temporal_evolution.enc.1.block.attn.proj.bias", "module.temporal_evolution.enc.1.block.norm2.weight", "module.temporal_evolution.enc.1.block.norm2.bias", "module.temporal_evolution.enc.1.block.mlp.fc1.weight", "module.temporal_evolution.enc.1.block.mlp.fc1.bias", "module.temporal_evolution.enc.1.block.mlp.fc2.weight", "module.temporal_evolution.enc.1.block.mlp.fc2.bias", "module.temporal_evolution.enc.2.block.gamma_1", "module.temporal_evolution.enc.2.block.gamma_2", "module.temporal_evolution.enc.2.block.pos_embed.weight", "module.temporal_evolution.enc.2.block.pos_embed.bias", "module.temporal_evolution.enc.2.block.norm1.weight", "module.temporal_evolution.enc.2.block.norm1.bias", "module.temporal_evolution.enc.2.block.attn.qkv.weight", "module.temporal_evolution.enc.2.block.attn.qkv.bias", "module.temporal_evolution.enc.2.block.attn.proj.weight", "module.temporal_evolution.enc.2.block.attn.proj.bias", "module.temporal_evolution.enc.2.block.norm2.weight", "module.temporal_evolution.enc.2.block.norm2.bias", "module.temporal_evolution.enc.2.block.mlp.fc1.weight", "module.temporal_evolution.enc.2.block.mlp.fc1.bias", "module.temporal_evolution.enc.2.block.mlp.fc2.weight", "module.temporal_evolution.enc.2.block.mlp.fc2.bias", "module.temporal_evolution.enc.3.block.gamma_1", "module.temporal_evolution.enc.3.block.gamma_2", "module.temporal_evolution.enc.3.block.pos_embed.weight", "module.temporal_evolution.enc.3.block.pos_embed.bias", "module.temporal_evolution.enc.3.block.norm1.weight", "module.temporal_evolution.enc.3.block.norm1.bias", "module.temporal_evolution.enc.3.block.attn.qkv.weight", "module.temporal_evolution.enc.3.block.attn.qkv.bias", "module.temporal_evolution.enc.3.block.attn.proj.weight", "module.temporal_evolution.enc.3.block.attn.proj.bias", "module.temporal_evolution.enc.3.block.norm2.weight", "module.temporal_evolution.enc.3.block.norm2.bias", "module.temporal_evolution.enc.3.block.mlp.fc1.weight", "module.temporal_evolution.enc.3.block.mlp.fc1.bias", "module.temporal_evolution.enc.3.block.mlp.fc2.weight", "module.temporal_evolution.enc.3.block.mlp.fc2.bias", "module.temporal_evolution.enc.4.block.gamma_1", "module.temporal_evolution.enc.4.block.gamma_2", "module.temporal_evolution.enc.4.block.pos_embed.weight", "module.temporal_evolution.enc.4.block.pos_embed.bias", "module.temporal_evolution.enc.4.block.norm1.weight", "module.temporal_evolution.enc.4.block.norm1.bias", "module.temporal_evolution.enc.4.block.attn.qkv.weight", "module.temporal_evolution.enc.4.block.attn.qkv.bias", "module.temporal_evolution.enc.4.block.attn.proj.weight", "module.temporal_evolution.enc.4.block.attn.proj.bias", "module.temporal_evolution.enc.4.block.norm2.weight", "module.temporal_evolution.enc.4.block.norm2.bias", "module.temporal_evolution.enc.4.block.mlp.fc1.weight", "module.temporal_evolution.enc.4.block.mlp.fc1.bias", "module.temporal_evolution.enc.4.block.mlp.fc2.weight", "module.temporal_evolution.enc.4.block.mlp.fc2.bias", "module.temporal_evolution.enc.5.block.gamma_1", "module.temporal_evolution.enc.5.block.gamma_2", "module.temporal_evolution.enc.5.block.pos_embed.weight", "module.temporal_evolution.enc.5.block.pos_embed.bias", "module.temporal_evolution.enc.5.block.norm1.weight", "module.temporal_evolution.enc.5.block.norm1.bias", "module.temporal_evolution.enc.5.block.attn.qkv.weight", "module.temporal_evolution.enc.5.block.attn.qkv.bias", "module.temporal_evolution.enc.5.block.attn.proj.weight", "module.temporal_evolution.enc.5.block.attn.proj.bias", "module.temporal_evolution.enc.5.block.norm2.weight", "module.temporal_evolution.enc.5.block.norm2.bias", "module.temporal_evolution.enc.5.block.mlp.fc1.weight", "module.temporal_evolution.enc.5.block.mlp.fc1.bias", "module.temporal_evolution.enc.5.block.mlp.fc2.weight", "module.temporal_evolution.enc.5.block.mlp.fc2.bias", "module.temporal_evolution.enc.6.block.gamma_1", "module.temporal_evolution.enc.6.block.gamma_2", "module.temporal_evolution.enc.6.block.pos_embed.weight", "module.temporal_evolution.enc.6.block.pos_embed.bias", "module.temporal_evolution.enc.6.block.norm1.weight", "module.temporal_evolution.enc.6.block.norm1.bias", "module.temporal_evolution.enc.6.block.attn.qkv.weight", "module.temporal_evolution.enc.6.block.attn.qkv.bias", "module.temporal_evolution.enc.6.block.attn.proj.weight", "module.temporal_evolution.enc.6.block.attn.proj.bias", "module.temporal_evolution.enc.6.block.norm2.weight", "module.temporal_evolution.enc.6.block.norm2.bias", "module.temporal_evolution.enc.6.block.mlp.fc1.weight", "module.temporal_evolution.enc.6.block.mlp.fc1.bias", "module.temporal_evolution.enc.6.block.mlp.fc2.weight", "module.temporal_evolution.enc.6.block.mlp.fc2.bias", "module.temporal_evolution.enc.7.block.pos_embed.weight", "module.temporal_evolution.enc.7.block.pos_embed.bias", "module.temporal_evolution.enc.7.block.norm1.weight", "module.temporal_evolution.enc.7.block.norm1.bias", "module.temporal_evolution.enc.7.block.norm1.running_mean", "module.temporal_evolution.enc.7.block.norm1.running_var", "module.temporal_evolution.enc.7.block.norm1.num_batches_tracked", "module.temporal_evolution.enc.7.block.conv1.weight", "module.temporal_evolution.enc.7.block.conv1.bias", "module.temporal_evolution.enc.7.block.conv2.weight", "module.temporal_evolution.enc.7.block.conv2.bias", "module.temporal_evolution.enc.7.block.attn.weight", "module.temporal_evolution.enc.7.block.attn.bias", "module.temporal_evolution.enc.7.block.norm2.weight", "module.temporal_evolution.enc.7.block.norm2.bias", "module.temporal_evolution.enc.7.block.norm2.running_mean", "module.temporal_evolution.enc.7.block.norm2.running_var", "module.temporal_evolution.enc.7.block.norm2.num_batches_tracked", "module.temporal_evolution.enc.7.block.mlp.fc1.weight", "module.temporal_evolution.enc.7.block.mlp.fc1.bias", "module.temporal_evolution.enc.7.block.mlp.fc2.weight", "module.temporal_evolution.enc.7.block.mlp.fc2.bias", "module.temporal_evolution.enc.7.reduction.weight", "module.temporal_evolution.enc.7.reduction.bias", "module.atmospheric_decoder.dec.0.conv.conv.weight", "module.atmospheric_decoder.dec.0.conv.conv.bias", "module.atmospheric_decoder.dec.0.conv.norm.weight", "module.atmospheric_decoder.dec.0.conv.norm.bias", "module.atmospheric_decoder.dec.1.conv.conv.weight", "module.atmospheric_decoder.dec.1.conv.conv.bias", "module.atmospheric_decoder.dec.1.conv.norm.weight", "module.atmospheric_decoder.dec.1.conv.norm.bias", "module.atmospheric_decoder.dec.2.conv.conv.weight", "module.atmospheric_decoder.dec.2.conv.conv.bias", "module.atmospheric_decoder.dec.2.conv.norm.weight", "module.atmospheric_decoder.dec.2.conv.norm.bias", "module.atmospheric_decoder.dec.3.conv.conv.weight", "module.atmospheric_decoder.dec.3.conv.conv.bias", "module.atmospheric_decoder.dec.3.conv.norm.weight", "module.atmospheric_decoder.dec.3.conv.norm.bias", "module.atmospheric_decoder.readout.weight", "module.atmospheric_decoder.readout.bias". 
2025-02-19 11:02:56,161 Attempting to fix the state_dict by removing "module." prefix.
2025-02-19 11:02:56,187 Model loaded successfully after fixing state_dict.
2025-02-19 11:03:27,534 Current Learning Rate: 0.0021249737
2025-02-19 11:03:29,375 Train Loss: 0.0001328, Val Loss: 0.0001803
2025-02-19 11:03:29,378 Epoch 1740/2000
2025-02-19 11:04:11,590 Current Learning Rate: 0.0020610737
2025-02-19 11:04:11,593 Train Loss: 0.0001162, Val Loss: 0.0001806
2025-02-19 11:04:11,594 Epoch 1741/2000
2025-02-19 11:04:54,293 Current Learning Rate: 0.0019978989
2025-02-19 11:04:55,557 Train Loss: 0.0001201, Val Loss: 0.0001802
2025-02-19 11:04:55,560 Epoch 1742/2000
2025-02-19 11:05:37,312 Current Learning Rate: 0.0019354647
2025-02-19 11:05:37,314 Train Loss: 0.0001346, Val Loss: 0.0001804
2025-02-19 11:05:37,315 Epoch 1743/2000
2025-02-19 11:06:16,746 Animation.save using <class 'matplotlib.animation.PillowWriter'>
2025-02-19 11:06:20,942 Current Learning Rate: 0.0018737867
2025-02-19 11:06:22,787 Train Loss: 0.0001412, Val Loss: 0.0001800
2025-02-19 11:06:22,792 Epoch 1744/2000
2025-02-19 11:07:06,142 Current Learning Rate: 0.0018128801
2025-02-19 11:07:07,991 Train Loss: 0.0001156, Val Loss: 0.0001790
2025-02-19 11:07:07,994 Epoch 1745/2000
2025-02-19 11:07:51,431 Current Learning Rate: 0.0017527598
2025-02-19 11:07:53,633 Train Loss: 0.0001673, Val Loss: 0.0001788
2025-02-19 11:07:53,640 Epoch 1746/2000
2025-02-19 11:08:35,163 Current Learning Rate: 0.0016934407
2025-02-19 11:08:36,252 Train Loss: 0.0001235, Val Loss: 0.0001781
2025-02-19 11:08:36,253 Epoch 1747/2000
2025-02-19 11:08:44,955 Loading best model from checkpoint.
2025-02-19 11:08:45,663 Error loading model checkpoint directly: Error(s) in loading state_dict for Triton:
	Missing key(s) in state_dict: "atmospheric_encoder.enc.0.conv.conv.weight", "atmospheric_encoder.enc.0.conv.conv.bias", "atmospheric_encoder.enc.0.conv.norm.weight", "atmospheric_encoder.enc.0.conv.norm.bias", "atmospheric_encoder.enc.1.conv.conv.weight", "atmospheric_encoder.enc.1.conv.conv.bias", "atmospheric_encoder.enc.1.conv.norm.weight", "atmospheric_encoder.enc.1.conv.norm.bias", "atmospheric_encoder.enc.2.conv.conv.weight", "atmospheric_encoder.enc.2.conv.conv.bias", "atmospheric_encoder.enc.2.conv.norm.weight", "atmospheric_encoder.enc.2.conv.norm.bias", "atmospheric_encoder.enc.3.conv.conv.weight", "atmospheric_encoder.enc.3.conv.conv.bias", "atmospheric_encoder.enc.3.conv.norm.weight", "atmospheric_encoder.enc.3.conv.norm.bias", "temporal_evolution.enc.0.block.pos_embed.weight", "temporal_evolution.enc.0.block.pos_embed.bias", "temporal_evolution.enc.0.block.norm1.weight", "temporal_evolution.enc.0.block.norm1.bias", "temporal_evolution.enc.0.block.norm1.running_mean", "temporal_evolution.enc.0.block.norm1.running_var", "temporal_evolution.enc.0.block.conv1.weight", "temporal_evolution.enc.0.block.conv1.bias", "temporal_evolution.enc.0.block.conv2.weight", "temporal_evolution.enc.0.block.conv2.bias", "temporal_evolution.enc.0.block.attn.weight", "temporal_evolution.enc.0.block.attn.bias", "temporal_evolution.enc.0.block.norm2.weight", "temporal_evolution.enc.0.block.norm2.bias", "temporal_evolution.enc.0.block.norm2.running_mean", "temporal_evolution.enc.0.block.norm2.running_var", "temporal_evolution.enc.0.block.mlp.fc1.weight", "temporal_evolution.enc.0.block.mlp.fc1.bias", "temporal_evolution.enc.0.block.mlp.fc2.weight", "temporal_evolution.enc.0.block.mlp.fc2.bias", "temporal_evolution.enc.0.reduction.weight", "temporal_evolution.enc.0.reduction.bias", "temporal_evolution.enc.1.block.gamma_1", "temporal_evolution.enc.1.block.gamma_2", "temporal_evolution.enc.1.block.pos_embed.weight", "temporal_evolution.enc.1.block.pos_embed.bias", "temporal_evolution.enc.1.block.norm1.weight", "temporal_evolution.enc.1.block.norm1.bias", "temporal_evolution.enc.1.block.attn.qkv.weight", "temporal_evolution.enc.1.block.attn.qkv.bias", "temporal_evolution.enc.1.block.attn.proj.weight", "temporal_evolution.enc.1.block.attn.proj.bias", "temporal_evolution.enc.1.block.norm2.weight", "temporal_evolution.enc.1.block.norm2.bias", "temporal_evolution.enc.1.block.mlp.fc1.weight", "temporal_evolution.enc.1.block.mlp.fc1.bias", "temporal_evolution.enc.1.block.mlp.fc2.weight", "temporal_evolution.enc.1.block.mlp.fc2.bias", "temporal_evolution.enc.2.block.gamma_1", "temporal_evolution.enc.2.block.gamma_2", "temporal_evolution.enc.2.block.pos_embed.weight", "temporal_evolution.enc.2.block.pos_embed.bias", "temporal_evolution.enc.2.block.norm1.weight", "temporal_evolution.enc.2.block.norm1.bias", "temporal_evolution.enc.2.block.attn.qkv.weight", "temporal_evolution.enc.2.block.attn.qkv.bias", "temporal_evolution.enc.2.block.attn.proj.weight", "temporal_evolution.enc.2.block.attn.proj.bias", "temporal_evolution.enc.2.block.norm2.weight", "temporal_evolution.enc.2.block.norm2.bias", "temporal_evolution.enc.2.block.mlp.fc1.weight", "temporal_evolution.enc.2.block.mlp.fc1.bias", "temporal_evolution.enc.2.block.mlp.fc2.weight", "temporal_evolution.enc.2.block.mlp.fc2.bias", "temporal_evolution.enc.3.block.gamma_1", "temporal_evolution.enc.3.block.gamma_2", "temporal_evolution.enc.3.block.pos_embed.weight", "temporal_evolution.enc.3.block.pos_embed.bias", "temporal_evolution.enc.3.block.norm1.weight", "temporal_evolution.enc.3.block.norm1.bias", "temporal_evolution.enc.3.block.attn.qkv.weight", "temporal_evolution.enc.3.block.attn.qkv.bias", "temporal_evolution.enc.3.block.attn.proj.weight", "temporal_evolution.enc.3.block.attn.proj.bias", "temporal_evolution.enc.3.block.norm2.weight", "temporal_evolution.enc.3.block.norm2.bias", "temporal_evolution.enc.3.block.mlp.fc1.weight", "temporal_evolution.enc.3.block.mlp.fc1.bias", "temporal_evolution.enc.3.block.mlp.fc2.weight", "temporal_evolution.enc.3.block.mlp.fc2.bias", "temporal_evolution.enc.4.block.gamma_1", "temporal_evolution.enc.4.block.gamma_2", "temporal_evolution.enc.4.block.pos_embed.weight", "temporal_evolution.enc.4.block.pos_embed.bias", "temporal_evolution.enc.4.block.norm1.weight", "temporal_evolution.enc.4.block.norm1.bias", "temporal_evolution.enc.4.block.attn.qkv.weight", "temporal_evolution.enc.4.block.attn.qkv.bias", "temporal_evolution.enc.4.block.attn.proj.weight", "temporal_evolution.enc.4.block.attn.proj.bias", "temporal_evolution.enc.4.block.norm2.weight", "temporal_evolution.enc.4.block.norm2.bias", "temporal_evolution.enc.4.block.mlp.fc1.weight", "temporal_evolution.enc.4.block.mlp.fc1.bias", "temporal_evolution.enc.4.block.mlp.fc2.weight", "temporal_evolution.enc.4.block.mlp.fc2.bias", "temporal_evolution.enc.5.block.gamma_1", "temporal_evolution.enc.5.block.gamma_2", "temporal_evolution.enc.5.block.pos_embed.weight", "temporal_evolution.enc.5.block.pos_embed.bias", "temporal_evolution.enc.5.block.norm1.weight", "temporal_evolution.enc.5.block.norm1.bias", "temporal_evolution.enc.5.block.attn.qkv.weight", "temporal_evolution.enc.5.block.attn.qkv.bias", "temporal_evolution.enc.5.block.attn.proj.weight", "temporal_evolution.enc.5.block.attn.proj.bias", "temporal_evolution.enc.5.block.norm2.weight", "temporal_evolution.enc.5.block.norm2.bias", "temporal_evolution.enc.5.block.mlp.fc1.weight", "temporal_evolution.enc.5.block.mlp.fc1.bias", "temporal_evolution.enc.5.block.mlp.fc2.weight", "temporal_evolution.enc.5.block.mlp.fc2.bias", "temporal_evolution.enc.6.block.gamma_1", "temporal_evolution.enc.6.block.gamma_2", "temporal_evolution.enc.6.block.pos_embed.weight", "temporal_evolution.enc.6.block.pos_embed.bias", "temporal_evolution.enc.6.block.norm1.weight", "temporal_evolution.enc.6.block.norm1.bias", "temporal_evolution.enc.6.block.attn.qkv.weight", "temporal_evolution.enc.6.block.attn.qkv.bias", "temporal_evolution.enc.6.block.attn.proj.weight", "temporal_evolution.enc.6.block.attn.proj.bias", "temporal_evolution.enc.6.block.norm2.weight", "temporal_evolution.enc.6.block.norm2.bias", "temporal_evolution.enc.6.block.mlp.fc1.weight", "temporal_evolution.enc.6.block.mlp.fc1.bias", "temporal_evolution.enc.6.block.mlp.fc2.weight", "temporal_evolution.enc.6.block.mlp.fc2.bias", "temporal_evolution.enc.7.block.pos_embed.weight", "temporal_evolution.enc.7.block.pos_embed.bias", "temporal_evolution.enc.7.block.norm1.weight", "temporal_evolution.enc.7.block.norm1.bias", "temporal_evolution.enc.7.block.norm1.running_mean", "temporal_evolution.enc.7.block.norm1.running_var", "temporal_evolution.enc.7.block.conv1.weight", "temporal_evolution.enc.7.block.conv1.bias", "temporal_evolution.enc.7.block.conv2.weight", "temporal_evolution.enc.7.block.conv2.bias", "temporal_evolution.enc.7.block.attn.weight", "temporal_evolution.enc.7.block.attn.bias", "temporal_evolution.enc.7.block.norm2.weight", "temporal_evolution.enc.7.block.norm2.bias", "temporal_evolution.enc.7.block.norm2.running_mean", "temporal_evolution.enc.7.block.norm2.running_var", "temporal_evolution.enc.7.block.mlp.fc1.weight", "temporal_evolution.enc.7.block.mlp.fc1.bias", "temporal_evolution.enc.7.block.mlp.fc2.weight", "temporal_evolution.enc.7.block.mlp.fc2.bias", "temporal_evolution.enc.7.reduction.weight", "temporal_evolution.enc.7.reduction.bias", "atmospheric_decoder.dec.0.conv.conv.weight", "atmospheric_decoder.dec.0.conv.conv.bias", "atmospheric_decoder.dec.0.conv.norm.weight", "atmospheric_decoder.dec.0.conv.norm.bias", "atmospheric_decoder.dec.1.conv.conv.weight", "atmospheric_decoder.dec.1.conv.conv.bias", "atmospheric_decoder.dec.1.conv.norm.weight", "atmospheric_decoder.dec.1.conv.norm.bias", "atmospheric_decoder.dec.2.conv.conv.weight", "atmospheric_decoder.dec.2.conv.conv.bias", "atmospheric_decoder.dec.2.conv.norm.weight", "atmospheric_decoder.dec.2.conv.norm.bias", "atmospheric_decoder.dec.3.conv.conv.weight", "atmospheric_decoder.dec.3.conv.conv.bias", "atmospheric_decoder.dec.3.conv.norm.weight", "atmospheric_decoder.dec.3.conv.norm.bias", "atmospheric_decoder.readout.weight", "atmospheric_decoder.readout.bias". 
	Unexpected key(s) in state_dict: "module.atmospheric_encoder.enc.0.conv.conv.weight", "module.atmospheric_encoder.enc.0.conv.conv.bias", "module.atmospheric_encoder.enc.0.conv.norm.weight", "module.atmospheric_encoder.enc.0.conv.norm.bias", "module.atmospheric_encoder.enc.1.conv.conv.weight", "module.atmospheric_encoder.enc.1.conv.conv.bias", "module.atmospheric_encoder.enc.1.conv.norm.weight", "module.atmospheric_encoder.enc.1.conv.norm.bias", "module.atmospheric_encoder.enc.2.conv.conv.weight", "module.atmospheric_encoder.enc.2.conv.conv.bias", "module.atmospheric_encoder.enc.2.conv.norm.weight", "module.atmospheric_encoder.enc.2.conv.norm.bias", "module.atmospheric_encoder.enc.3.conv.conv.weight", "module.atmospheric_encoder.enc.3.conv.conv.bias", "module.atmospheric_encoder.enc.3.conv.norm.weight", "module.atmospheric_encoder.enc.3.conv.norm.bias", "module.temporal_evolution.enc.0.block.pos_embed.weight", "module.temporal_evolution.enc.0.block.pos_embed.bias", "module.temporal_evolution.enc.0.block.norm1.weight", "module.temporal_evolution.enc.0.block.norm1.bias", "module.temporal_evolution.enc.0.block.norm1.running_mean", "module.temporal_evolution.enc.0.block.norm1.running_var", "module.temporal_evolution.enc.0.block.norm1.num_batches_tracked", "module.temporal_evolution.enc.0.block.conv1.weight", "module.temporal_evolution.enc.0.block.conv1.bias", "module.temporal_evolution.enc.0.block.conv2.weight", "module.temporal_evolution.enc.0.block.conv2.bias", "module.temporal_evolution.enc.0.block.attn.weight", "module.temporal_evolution.enc.0.block.attn.bias", "module.temporal_evolution.enc.0.block.norm2.weight", "module.temporal_evolution.enc.0.block.norm2.bias", "module.temporal_evolution.enc.0.block.norm2.running_mean", "module.temporal_evolution.enc.0.block.norm2.running_var", "module.temporal_evolution.enc.0.block.norm2.num_batches_tracked", "module.temporal_evolution.enc.0.block.mlp.fc1.weight", "module.temporal_evolution.enc.0.block.mlp.fc1.bias", "module.temporal_evolution.enc.0.block.mlp.fc2.weight", "module.temporal_evolution.enc.0.block.mlp.fc2.bias", "module.temporal_evolution.enc.0.reduction.weight", "module.temporal_evolution.enc.0.reduction.bias", "module.temporal_evolution.enc.1.block.gamma_1", "module.temporal_evolution.enc.1.block.gamma_2", "module.temporal_evolution.enc.1.block.pos_embed.weight", "module.temporal_evolution.enc.1.block.pos_embed.bias", "module.temporal_evolution.enc.1.block.norm1.weight", "module.temporal_evolution.enc.1.block.norm1.bias", "module.temporal_evolution.enc.1.block.attn.qkv.weight", "module.temporal_evolution.enc.1.block.attn.qkv.bias", "module.temporal_evolution.enc.1.block.attn.proj.weight", "module.temporal_evolution.enc.1.block.attn.proj.bias", "module.temporal_evolution.enc.1.block.norm2.weight", "module.temporal_evolution.enc.1.block.norm2.bias", "module.temporal_evolution.enc.1.block.mlp.fc1.weight", "module.temporal_evolution.enc.1.block.mlp.fc1.bias", "module.temporal_evolution.enc.1.block.mlp.fc2.weight", "module.temporal_evolution.enc.1.block.mlp.fc2.bias", "module.temporal_evolution.enc.2.block.gamma_1", "module.temporal_evolution.enc.2.block.gamma_2", "module.temporal_evolution.enc.2.block.pos_embed.weight", "module.temporal_evolution.enc.2.block.pos_embed.bias", "module.temporal_evolution.enc.2.block.norm1.weight", "module.temporal_evolution.enc.2.block.norm1.bias", "module.temporal_evolution.enc.2.block.attn.qkv.weight", "module.temporal_evolution.enc.2.block.attn.qkv.bias", "module.temporal_evolution.enc.2.block.attn.proj.weight", "module.temporal_evolution.enc.2.block.attn.proj.bias", "module.temporal_evolution.enc.2.block.norm2.weight", "module.temporal_evolution.enc.2.block.norm2.bias", "module.temporal_evolution.enc.2.block.mlp.fc1.weight", "module.temporal_evolution.enc.2.block.mlp.fc1.bias", "module.temporal_evolution.enc.2.block.mlp.fc2.weight", "module.temporal_evolution.enc.2.block.mlp.fc2.bias", "module.temporal_evolution.enc.3.block.gamma_1", "module.temporal_evolution.enc.3.block.gamma_2", "module.temporal_evolution.enc.3.block.pos_embed.weight", "module.temporal_evolution.enc.3.block.pos_embed.bias", "module.temporal_evolution.enc.3.block.norm1.weight", "module.temporal_evolution.enc.3.block.norm1.bias", "module.temporal_evolution.enc.3.block.attn.qkv.weight", "module.temporal_evolution.enc.3.block.attn.qkv.bias", "module.temporal_evolution.enc.3.block.attn.proj.weight", "module.temporal_evolution.enc.3.block.attn.proj.bias", "module.temporal_evolution.enc.3.block.norm2.weight", "module.temporal_evolution.enc.3.block.norm2.bias", "module.temporal_evolution.enc.3.block.mlp.fc1.weight", "module.temporal_evolution.enc.3.block.mlp.fc1.bias", "module.temporal_evolution.enc.3.block.mlp.fc2.weight", "module.temporal_evolution.enc.3.block.mlp.fc2.bias", "module.temporal_evolution.enc.4.block.gamma_1", "module.temporal_evolution.enc.4.block.gamma_2", "module.temporal_evolution.enc.4.block.pos_embed.weight", "module.temporal_evolution.enc.4.block.pos_embed.bias", "module.temporal_evolution.enc.4.block.norm1.weight", "module.temporal_evolution.enc.4.block.norm1.bias", "module.temporal_evolution.enc.4.block.attn.qkv.weight", "module.temporal_evolution.enc.4.block.attn.qkv.bias", "module.temporal_evolution.enc.4.block.attn.proj.weight", "module.temporal_evolution.enc.4.block.attn.proj.bias", "module.temporal_evolution.enc.4.block.norm2.weight", "module.temporal_evolution.enc.4.block.norm2.bias", "module.temporal_evolution.enc.4.block.mlp.fc1.weight", "module.temporal_evolution.enc.4.block.mlp.fc1.bias", "module.temporal_evolution.enc.4.block.mlp.fc2.weight", "module.temporal_evolution.enc.4.block.mlp.fc2.bias", "module.temporal_evolution.enc.5.block.gamma_1", "module.temporal_evolution.enc.5.block.gamma_2", "module.temporal_evolution.enc.5.block.pos_embed.weight", "module.temporal_evolution.enc.5.block.pos_embed.bias", "module.temporal_evolution.enc.5.block.norm1.weight", "module.temporal_evolution.enc.5.block.norm1.bias", "module.temporal_evolution.enc.5.block.attn.qkv.weight", "module.temporal_evolution.enc.5.block.attn.qkv.bias", "module.temporal_evolution.enc.5.block.attn.proj.weight", "module.temporal_evolution.enc.5.block.attn.proj.bias", "module.temporal_evolution.enc.5.block.norm2.weight", "module.temporal_evolution.enc.5.block.norm2.bias", "module.temporal_evolution.enc.5.block.mlp.fc1.weight", "module.temporal_evolution.enc.5.block.mlp.fc1.bias", "module.temporal_evolution.enc.5.block.mlp.fc2.weight", "module.temporal_evolution.enc.5.block.mlp.fc2.bias", "module.temporal_evolution.enc.6.block.gamma_1", "module.temporal_evolution.enc.6.block.gamma_2", "module.temporal_evolution.enc.6.block.pos_embed.weight", "module.temporal_evolution.enc.6.block.pos_embed.bias", "module.temporal_evolution.enc.6.block.norm1.weight", "module.temporal_evolution.enc.6.block.norm1.bias", "module.temporal_evolution.enc.6.block.attn.qkv.weight", "module.temporal_evolution.enc.6.block.attn.qkv.bias", "module.temporal_evolution.enc.6.block.attn.proj.weight", "module.temporal_evolution.enc.6.block.attn.proj.bias", "module.temporal_evolution.enc.6.block.norm2.weight", "module.temporal_evolution.enc.6.block.norm2.bias", "module.temporal_evolution.enc.6.block.mlp.fc1.weight", "module.temporal_evolution.enc.6.block.mlp.fc1.bias", "module.temporal_evolution.enc.6.block.mlp.fc2.weight", "module.temporal_evolution.enc.6.block.mlp.fc2.bias", "module.temporal_evolution.enc.7.block.pos_embed.weight", "module.temporal_evolution.enc.7.block.pos_embed.bias", "module.temporal_evolution.enc.7.block.norm1.weight", "module.temporal_evolution.enc.7.block.norm1.bias", "module.temporal_evolution.enc.7.block.norm1.running_mean", "module.temporal_evolution.enc.7.block.norm1.running_var", "module.temporal_evolution.enc.7.block.norm1.num_batches_tracked", "module.temporal_evolution.enc.7.block.conv1.weight", "module.temporal_evolution.enc.7.block.conv1.bias", "module.temporal_evolution.enc.7.block.conv2.weight", "module.temporal_evolution.enc.7.block.conv2.bias", "module.temporal_evolution.enc.7.block.attn.weight", "module.temporal_evolution.enc.7.block.attn.bias", "module.temporal_evolution.enc.7.block.norm2.weight", "module.temporal_evolution.enc.7.block.norm2.bias", "module.temporal_evolution.enc.7.block.norm2.running_mean", "module.temporal_evolution.enc.7.block.norm2.running_var", "module.temporal_evolution.enc.7.block.norm2.num_batches_tracked", "module.temporal_evolution.enc.7.block.mlp.fc1.weight", "module.temporal_evolution.enc.7.block.mlp.fc1.bias", "module.temporal_evolution.enc.7.block.mlp.fc2.weight", "module.temporal_evolution.enc.7.block.mlp.fc2.bias", "module.temporal_evolution.enc.7.reduction.weight", "module.temporal_evolution.enc.7.reduction.bias", "module.atmospheric_decoder.dec.0.conv.conv.weight", "module.atmospheric_decoder.dec.0.conv.conv.bias", "module.atmospheric_decoder.dec.0.conv.norm.weight", "module.atmospheric_decoder.dec.0.conv.norm.bias", "module.atmospheric_decoder.dec.1.conv.conv.weight", "module.atmospheric_decoder.dec.1.conv.conv.bias", "module.atmospheric_decoder.dec.1.conv.norm.weight", "module.atmospheric_decoder.dec.1.conv.norm.bias", "module.atmospheric_decoder.dec.2.conv.conv.weight", "module.atmospheric_decoder.dec.2.conv.conv.bias", "module.atmospheric_decoder.dec.2.conv.norm.weight", "module.atmospheric_decoder.dec.2.conv.norm.bias", "module.atmospheric_decoder.dec.3.conv.conv.weight", "module.atmospheric_decoder.dec.3.conv.conv.bias", "module.atmospheric_decoder.dec.3.conv.norm.weight", "module.atmospheric_decoder.dec.3.conv.norm.bias", "module.atmospheric_decoder.readout.weight", "module.atmospheric_decoder.readout.bias". 
2025-02-19 11:08:45,666 Attempting to fix the state_dict by removing "module." prefix.
2025-02-19 11:08:45,685 Model loaded successfully after fixing state_dict.
2025-02-19 11:09:18,082 Current Learning Rate: 0.0016349374
2025-02-19 11:09:19,211 Train Loss: 0.0001334, Val Loss: 0.0001779
2025-02-19 11:09:19,214 Epoch 1748/2000
2025-02-19 11:10:02,209 Current Learning Rate: 0.0015772645
2025-02-19 11:10:04,005 Train Loss: 0.0001303, Val Loss: 0.0001775
2025-02-19 11:10:04,030 Epoch 1749/2000
2025-02-19 11:10:46,588 Current Learning Rate: 0.0015204360
2025-02-19 11:10:46,590 Train Loss: 0.0001463, Val Loss: 0.0001778
2025-02-19 11:10:46,591 Epoch 1750/2000
2025-02-19 11:11:19,697 Loading best model from checkpoint.
2025-02-19 11:11:20,429 Error loading model checkpoint directly: Error(s) in loading state_dict for Triton:
	Missing key(s) in state_dict: "atmospheric_encoder.enc.0.conv.conv.weight", "atmospheric_encoder.enc.0.conv.conv.bias", "atmospheric_encoder.enc.0.conv.norm.weight", "atmospheric_encoder.enc.0.conv.norm.bias", "atmospheric_encoder.enc.1.conv.conv.weight", "atmospheric_encoder.enc.1.conv.conv.bias", "atmospheric_encoder.enc.1.conv.norm.weight", "atmospheric_encoder.enc.1.conv.norm.bias", "atmospheric_encoder.enc.2.conv.conv.weight", "atmospheric_encoder.enc.2.conv.conv.bias", "atmospheric_encoder.enc.2.conv.norm.weight", "atmospheric_encoder.enc.2.conv.norm.bias", "atmospheric_encoder.enc.3.conv.conv.weight", "atmospheric_encoder.enc.3.conv.conv.bias", "atmospheric_encoder.enc.3.conv.norm.weight", "atmospheric_encoder.enc.3.conv.norm.bias", "temporal_evolution.enc.0.block.pos_embed.weight", "temporal_evolution.enc.0.block.pos_embed.bias", "temporal_evolution.enc.0.block.norm1.weight", "temporal_evolution.enc.0.block.norm1.bias", "temporal_evolution.enc.0.block.norm1.running_mean", "temporal_evolution.enc.0.block.norm1.running_var", "temporal_evolution.enc.0.block.conv1.weight", "temporal_evolution.enc.0.block.conv1.bias", "temporal_evolution.enc.0.block.conv2.weight", "temporal_evolution.enc.0.block.conv2.bias", "temporal_evolution.enc.0.block.attn.weight", "temporal_evolution.enc.0.block.attn.bias", "temporal_evolution.enc.0.block.norm2.weight", "temporal_evolution.enc.0.block.norm2.bias", "temporal_evolution.enc.0.block.norm2.running_mean", "temporal_evolution.enc.0.block.norm2.running_var", "temporal_evolution.enc.0.block.mlp.fc1.weight", "temporal_evolution.enc.0.block.mlp.fc1.bias", "temporal_evolution.enc.0.block.mlp.fc2.weight", "temporal_evolution.enc.0.block.mlp.fc2.bias", "temporal_evolution.enc.0.reduction.weight", "temporal_evolution.enc.0.reduction.bias", "temporal_evolution.enc.1.block.gamma_1", "temporal_evolution.enc.1.block.gamma_2", "temporal_evolution.enc.1.block.pos_embed.weight", "temporal_evolution.enc.1.block.pos_embed.bias", "temporal_evolution.enc.1.block.norm1.weight", "temporal_evolution.enc.1.block.norm1.bias", "temporal_evolution.enc.1.block.attn.qkv.weight", "temporal_evolution.enc.1.block.attn.qkv.bias", "temporal_evolution.enc.1.block.attn.proj.weight", "temporal_evolution.enc.1.block.attn.proj.bias", "temporal_evolution.enc.1.block.norm2.weight", "temporal_evolution.enc.1.block.norm2.bias", "temporal_evolution.enc.1.block.mlp.fc1.weight", "temporal_evolution.enc.1.block.mlp.fc1.bias", "temporal_evolution.enc.1.block.mlp.fc2.weight", "temporal_evolution.enc.1.block.mlp.fc2.bias", "temporal_evolution.enc.2.block.gamma_1", "temporal_evolution.enc.2.block.gamma_2", "temporal_evolution.enc.2.block.pos_embed.weight", "temporal_evolution.enc.2.block.pos_embed.bias", "temporal_evolution.enc.2.block.norm1.weight", "temporal_evolution.enc.2.block.norm1.bias", "temporal_evolution.enc.2.block.attn.qkv.weight", "temporal_evolution.enc.2.block.attn.qkv.bias", "temporal_evolution.enc.2.block.attn.proj.weight", "temporal_evolution.enc.2.block.attn.proj.bias", "temporal_evolution.enc.2.block.norm2.weight", "temporal_evolution.enc.2.block.norm2.bias", "temporal_evolution.enc.2.block.mlp.fc1.weight", "temporal_evolution.enc.2.block.mlp.fc1.bias", "temporal_evolution.enc.2.block.mlp.fc2.weight", "temporal_evolution.enc.2.block.mlp.fc2.bias", "temporal_evolution.enc.3.block.gamma_1", "temporal_evolution.enc.3.block.gamma_2", "temporal_evolution.enc.3.block.pos_embed.weight", "temporal_evolution.enc.3.block.pos_embed.bias", "temporal_evolution.enc.3.block.norm1.weight", "temporal_evolution.enc.3.block.norm1.bias", "temporal_evolution.enc.3.block.attn.qkv.weight", "temporal_evolution.enc.3.block.attn.qkv.bias", "temporal_evolution.enc.3.block.attn.proj.weight", "temporal_evolution.enc.3.block.attn.proj.bias", "temporal_evolution.enc.3.block.norm2.weight", "temporal_evolution.enc.3.block.norm2.bias", "temporal_evolution.enc.3.block.mlp.fc1.weight", "temporal_evolution.enc.3.block.mlp.fc1.bias", "temporal_evolution.enc.3.block.mlp.fc2.weight", "temporal_evolution.enc.3.block.mlp.fc2.bias", "temporal_evolution.enc.4.block.gamma_1", "temporal_evolution.enc.4.block.gamma_2", "temporal_evolution.enc.4.block.pos_embed.weight", "temporal_evolution.enc.4.block.pos_embed.bias", "temporal_evolution.enc.4.block.norm1.weight", "temporal_evolution.enc.4.block.norm1.bias", "temporal_evolution.enc.4.block.attn.qkv.weight", "temporal_evolution.enc.4.block.attn.qkv.bias", "temporal_evolution.enc.4.block.attn.proj.weight", "temporal_evolution.enc.4.block.attn.proj.bias", "temporal_evolution.enc.4.block.norm2.weight", "temporal_evolution.enc.4.block.norm2.bias", "temporal_evolution.enc.4.block.mlp.fc1.weight", "temporal_evolution.enc.4.block.mlp.fc1.bias", "temporal_evolution.enc.4.block.mlp.fc2.weight", "temporal_evolution.enc.4.block.mlp.fc2.bias", "temporal_evolution.enc.5.block.gamma_1", "temporal_evolution.enc.5.block.gamma_2", "temporal_evolution.enc.5.block.pos_embed.weight", "temporal_evolution.enc.5.block.pos_embed.bias", "temporal_evolution.enc.5.block.norm1.weight", "temporal_evolution.enc.5.block.norm1.bias", "temporal_evolution.enc.5.block.attn.qkv.weight", "temporal_evolution.enc.5.block.attn.qkv.bias", "temporal_evolution.enc.5.block.attn.proj.weight", "temporal_evolution.enc.5.block.attn.proj.bias", "temporal_evolution.enc.5.block.norm2.weight", "temporal_evolution.enc.5.block.norm2.bias", "temporal_evolution.enc.5.block.mlp.fc1.weight", "temporal_evolution.enc.5.block.mlp.fc1.bias", "temporal_evolution.enc.5.block.mlp.fc2.weight", "temporal_evolution.enc.5.block.mlp.fc2.bias", "temporal_evolution.enc.6.block.gamma_1", "temporal_evolution.enc.6.block.gamma_2", "temporal_evolution.enc.6.block.pos_embed.weight", "temporal_evolution.enc.6.block.pos_embed.bias", "temporal_evolution.enc.6.block.norm1.weight", "temporal_evolution.enc.6.block.norm1.bias", "temporal_evolution.enc.6.block.attn.qkv.weight", "temporal_evolution.enc.6.block.attn.qkv.bias", "temporal_evolution.enc.6.block.attn.proj.weight", "temporal_evolution.enc.6.block.attn.proj.bias", "temporal_evolution.enc.6.block.norm2.weight", "temporal_evolution.enc.6.block.norm2.bias", "temporal_evolution.enc.6.block.mlp.fc1.weight", "temporal_evolution.enc.6.block.mlp.fc1.bias", "temporal_evolution.enc.6.block.mlp.fc2.weight", "temporal_evolution.enc.6.block.mlp.fc2.bias", "temporal_evolution.enc.7.block.pos_embed.weight", "temporal_evolution.enc.7.block.pos_embed.bias", "temporal_evolution.enc.7.block.norm1.weight", "temporal_evolution.enc.7.block.norm1.bias", "temporal_evolution.enc.7.block.norm1.running_mean", "temporal_evolution.enc.7.block.norm1.running_var", "temporal_evolution.enc.7.block.conv1.weight", "temporal_evolution.enc.7.block.conv1.bias", "temporal_evolution.enc.7.block.conv2.weight", "temporal_evolution.enc.7.block.conv2.bias", "temporal_evolution.enc.7.block.attn.weight", "temporal_evolution.enc.7.block.attn.bias", "temporal_evolution.enc.7.block.norm2.weight", "temporal_evolution.enc.7.block.norm2.bias", "temporal_evolution.enc.7.block.norm2.running_mean", "temporal_evolution.enc.7.block.norm2.running_var", "temporal_evolution.enc.7.block.mlp.fc1.weight", "temporal_evolution.enc.7.block.mlp.fc1.bias", "temporal_evolution.enc.7.block.mlp.fc2.weight", "temporal_evolution.enc.7.block.mlp.fc2.bias", "temporal_evolution.enc.7.reduction.weight", "temporal_evolution.enc.7.reduction.bias", "atmospheric_decoder.dec.0.conv.conv.weight", "atmospheric_decoder.dec.0.conv.conv.bias", "atmospheric_decoder.dec.0.conv.norm.weight", "atmospheric_decoder.dec.0.conv.norm.bias", "atmospheric_decoder.dec.1.conv.conv.weight", "atmospheric_decoder.dec.1.conv.conv.bias", "atmospheric_decoder.dec.1.conv.norm.weight", "atmospheric_decoder.dec.1.conv.norm.bias", "atmospheric_decoder.dec.2.conv.conv.weight", "atmospheric_decoder.dec.2.conv.conv.bias", "atmospheric_decoder.dec.2.conv.norm.weight", "atmospheric_decoder.dec.2.conv.norm.bias", "atmospheric_decoder.dec.3.conv.conv.weight", "atmospheric_decoder.dec.3.conv.conv.bias", "atmospheric_decoder.dec.3.conv.norm.weight", "atmospheric_decoder.dec.3.conv.norm.bias", "atmospheric_decoder.readout.weight", "atmospheric_decoder.readout.bias". 
	Unexpected key(s) in state_dict: "module.atmospheric_encoder.enc.0.conv.conv.weight", "module.atmospheric_encoder.enc.0.conv.conv.bias", "module.atmospheric_encoder.enc.0.conv.norm.weight", "module.atmospheric_encoder.enc.0.conv.norm.bias", "module.atmospheric_encoder.enc.1.conv.conv.weight", "module.atmospheric_encoder.enc.1.conv.conv.bias", "module.atmospheric_encoder.enc.1.conv.norm.weight", "module.atmospheric_encoder.enc.1.conv.norm.bias", "module.atmospheric_encoder.enc.2.conv.conv.weight", "module.atmospheric_encoder.enc.2.conv.conv.bias", "module.atmospheric_encoder.enc.2.conv.norm.weight", "module.atmospheric_encoder.enc.2.conv.norm.bias", "module.atmospheric_encoder.enc.3.conv.conv.weight", "module.atmospheric_encoder.enc.3.conv.conv.bias", "module.atmospheric_encoder.enc.3.conv.norm.weight", "module.atmospheric_encoder.enc.3.conv.norm.bias", "module.temporal_evolution.enc.0.block.pos_embed.weight", "module.temporal_evolution.enc.0.block.pos_embed.bias", "module.temporal_evolution.enc.0.block.norm1.weight", "module.temporal_evolution.enc.0.block.norm1.bias", "module.temporal_evolution.enc.0.block.norm1.running_mean", "module.temporal_evolution.enc.0.block.norm1.running_var", "module.temporal_evolution.enc.0.block.norm1.num_batches_tracked", "module.temporal_evolution.enc.0.block.conv1.weight", "module.temporal_evolution.enc.0.block.conv1.bias", "module.temporal_evolution.enc.0.block.conv2.weight", "module.temporal_evolution.enc.0.block.conv2.bias", "module.temporal_evolution.enc.0.block.attn.weight", "module.temporal_evolution.enc.0.block.attn.bias", "module.temporal_evolution.enc.0.block.norm2.weight", "module.temporal_evolution.enc.0.block.norm2.bias", "module.temporal_evolution.enc.0.block.norm2.running_mean", "module.temporal_evolution.enc.0.block.norm2.running_var", "module.temporal_evolution.enc.0.block.norm2.num_batches_tracked", "module.temporal_evolution.enc.0.block.mlp.fc1.weight", "module.temporal_evolution.enc.0.block.mlp.fc1.bias", "module.temporal_evolution.enc.0.block.mlp.fc2.weight", "module.temporal_evolution.enc.0.block.mlp.fc2.bias", "module.temporal_evolution.enc.0.reduction.weight", "module.temporal_evolution.enc.0.reduction.bias", "module.temporal_evolution.enc.1.block.gamma_1", "module.temporal_evolution.enc.1.block.gamma_2", "module.temporal_evolution.enc.1.block.pos_embed.weight", "module.temporal_evolution.enc.1.block.pos_embed.bias", "module.temporal_evolution.enc.1.block.norm1.weight", "module.temporal_evolution.enc.1.block.norm1.bias", "module.temporal_evolution.enc.1.block.attn.qkv.weight", "module.temporal_evolution.enc.1.block.attn.qkv.bias", "module.temporal_evolution.enc.1.block.attn.proj.weight", "module.temporal_evolution.enc.1.block.attn.proj.bias", "module.temporal_evolution.enc.1.block.norm2.weight", "module.temporal_evolution.enc.1.block.norm2.bias", "module.temporal_evolution.enc.1.block.mlp.fc1.weight", "module.temporal_evolution.enc.1.block.mlp.fc1.bias", "module.temporal_evolution.enc.1.block.mlp.fc2.weight", "module.temporal_evolution.enc.1.block.mlp.fc2.bias", "module.temporal_evolution.enc.2.block.gamma_1", "module.temporal_evolution.enc.2.block.gamma_2", "module.temporal_evolution.enc.2.block.pos_embed.weight", "module.temporal_evolution.enc.2.block.pos_embed.bias", "module.temporal_evolution.enc.2.block.norm1.weight", "module.temporal_evolution.enc.2.block.norm1.bias", "module.temporal_evolution.enc.2.block.attn.qkv.weight", "module.temporal_evolution.enc.2.block.attn.qkv.bias", "module.temporal_evolution.enc.2.block.attn.proj.weight", "module.temporal_evolution.enc.2.block.attn.proj.bias", "module.temporal_evolution.enc.2.block.norm2.weight", "module.temporal_evolution.enc.2.block.norm2.bias", "module.temporal_evolution.enc.2.block.mlp.fc1.weight", "module.temporal_evolution.enc.2.block.mlp.fc1.bias", "module.temporal_evolution.enc.2.block.mlp.fc2.weight", "module.temporal_evolution.enc.2.block.mlp.fc2.bias", "module.temporal_evolution.enc.3.block.gamma_1", "module.temporal_evolution.enc.3.block.gamma_2", "module.temporal_evolution.enc.3.block.pos_embed.weight", "module.temporal_evolution.enc.3.block.pos_embed.bias", "module.temporal_evolution.enc.3.block.norm1.weight", "module.temporal_evolution.enc.3.block.norm1.bias", "module.temporal_evolution.enc.3.block.attn.qkv.weight", "module.temporal_evolution.enc.3.block.attn.qkv.bias", "module.temporal_evolution.enc.3.block.attn.proj.weight", "module.temporal_evolution.enc.3.block.attn.proj.bias", "module.temporal_evolution.enc.3.block.norm2.weight", "module.temporal_evolution.enc.3.block.norm2.bias", "module.temporal_evolution.enc.3.block.mlp.fc1.weight", "module.temporal_evolution.enc.3.block.mlp.fc1.bias", "module.temporal_evolution.enc.3.block.mlp.fc2.weight", "module.temporal_evolution.enc.3.block.mlp.fc2.bias", "module.temporal_evolution.enc.4.block.gamma_1", "module.temporal_evolution.enc.4.block.gamma_2", "module.temporal_evolution.enc.4.block.pos_embed.weight", "module.temporal_evolution.enc.4.block.pos_embed.bias", "module.temporal_evolution.enc.4.block.norm1.weight", "module.temporal_evolution.enc.4.block.norm1.bias", "module.temporal_evolution.enc.4.block.attn.qkv.weight", "module.temporal_evolution.enc.4.block.attn.qkv.bias", "module.temporal_evolution.enc.4.block.attn.proj.weight", "module.temporal_evolution.enc.4.block.attn.proj.bias", "module.temporal_evolution.enc.4.block.norm2.weight", "module.temporal_evolution.enc.4.block.norm2.bias", "module.temporal_evolution.enc.4.block.mlp.fc1.weight", "module.temporal_evolution.enc.4.block.mlp.fc1.bias", "module.temporal_evolution.enc.4.block.mlp.fc2.weight", "module.temporal_evolution.enc.4.block.mlp.fc2.bias", "module.temporal_evolution.enc.5.block.gamma_1", "module.temporal_evolution.enc.5.block.gamma_2", "module.temporal_evolution.enc.5.block.pos_embed.weight", "module.temporal_evolution.enc.5.block.pos_embed.bias", "module.temporal_evolution.enc.5.block.norm1.weight", "module.temporal_evolution.enc.5.block.norm1.bias", "module.temporal_evolution.enc.5.block.attn.qkv.weight", "module.temporal_evolution.enc.5.block.attn.qkv.bias", "module.temporal_evolution.enc.5.block.attn.proj.weight", "module.temporal_evolution.enc.5.block.attn.proj.bias", "module.temporal_evolution.enc.5.block.norm2.weight", "module.temporal_evolution.enc.5.block.norm2.bias", "module.temporal_evolution.enc.5.block.mlp.fc1.weight", "module.temporal_evolution.enc.5.block.mlp.fc1.bias", "module.temporal_evolution.enc.5.block.mlp.fc2.weight", "module.temporal_evolution.enc.5.block.mlp.fc2.bias", "module.temporal_evolution.enc.6.block.gamma_1", "module.temporal_evolution.enc.6.block.gamma_2", "module.temporal_evolution.enc.6.block.pos_embed.weight", "module.temporal_evolution.enc.6.block.pos_embed.bias", "module.temporal_evolution.enc.6.block.norm1.weight", "module.temporal_evolution.enc.6.block.norm1.bias", "module.temporal_evolution.enc.6.block.attn.qkv.weight", "module.temporal_evolution.enc.6.block.attn.qkv.bias", "module.temporal_evolution.enc.6.block.attn.proj.weight", "module.temporal_evolution.enc.6.block.attn.proj.bias", "module.temporal_evolution.enc.6.block.norm2.weight", "module.temporal_evolution.enc.6.block.norm2.bias", "module.temporal_evolution.enc.6.block.mlp.fc1.weight", "module.temporal_evolution.enc.6.block.mlp.fc1.bias", "module.temporal_evolution.enc.6.block.mlp.fc2.weight", "module.temporal_evolution.enc.6.block.mlp.fc2.bias", "module.temporal_evolution.enc.7.block.pos_embed.weight", "module.temporal_evolution.enc.7.block.pos_embed.bias", "module.temporal_evolution.enc.7.block.norm1.weight", "module.temporal_evolution.enc.7.block.norm1.bias", "module.temporal_evolution.enc.7.block.norm1.running_mean", "module.temporal_evolution.enc.7.block.norm1.running_var", "module.temporal_evolution.enc.7.block.norm1.num_batches_tracked", "module.temporal_evolution.enc.7.block.conv1.weight", "module.temporal_evolution.enc.7.block.conv1.bias", "module.temporal_evolution.enc.7.block.conv2.weight", "module.temporal_evolution.enc.7.block.conv2.bias", "module.temporal_evolution.enc.7.block.attn.weight", "module.temporal_evolution.enc.7.block.attn.bias", "module.temporal_evolution.enc.7.block.norm2.weight", "module.temporal_evolution.enc.7.block.norm2.bias", "module.temporal_evolution.enc.7.block.norm2.running_mean", "module.temporal_evolution.enc.7.block.norm2.running_var", "module.temporal_evolution.enc.7.block.norm2.num_batches_tracked", "module.temporal_evolution.enc.7.block.mlp.fc1.weight", "module.temporal_evolution.enc.7.block.mlp.fc1.bias", "module.temporal_evolution.enc.7.block.mlp.fc2.weight", "module.temporal_evolution.enc.7.block.mlp.fc2.bias", "module.temporal_evolution.enc.7.reduction.weight", "module.temporal_evolution.enc.7.reduction.bias", "module.atmospheric_decoder.dec.0.conv.conv.weight", "module.atmospheric_decoder.dec.0.conv.conv.bias", "module.atmospheric_decoder.dec.0.conv.norm.weight", "module.atmospheric_decoder.dec.0.conv.norm.bias", "module.atmospheric_decoder.dec.1.conv.conv.weight", "module.atmospheric_decoder.dec.1.conv.conv.bias", "module.atmospheric_decoder.dec.1.conv.norm.weight", "module.atmospheric_decoder.dec.1.conv.norm.bias", "module.atmospheric_decoder.dec.2.conv.conv.weight", "module.atmospheric_decoder.dec.2.conv.conv.bias", "module.atmospheric_decoder.dec.2.conv.norm.weight", "module.atmospheric_decoder.dec.2.conv.norm.bias", "module.atmospheric_decoder.dec.3.conv.conv.weight", "module.atmospheric_decoder.dec.3.conv.conv.bias", "module.atmospheric_decoder.dec.3.conv.norm.weight", "module.atmospheric_decoder.dec.3.conv.norm.bias", "module.atmospheric_decoder.readout.weight", "module.atmospheric_decoder.readout.bias". 
2025-02-19 11:11:20,431 Attempting to fix the state_dict by removing "module." prefix.
2025-02-19 11:11:20,450 Model loaded successfully after fixing state_dict.
2025-02-19 11:11:29,596 Current Learning Rate: 0.0014644661
2025-02-19 11:11:29,597 Train Loss: 0.0001557, Val Loss: 0.0001785
2025-02-19 11:11:29,598 Epoch 1751/2000
2025-02-19 11:12:12,000 Current Learning Rate: 0.0014093685
2025-02-19 11:12:12,002 Train Loss: 0.0001411, Val Loss: 0.0001776
2025-02-19 11:12:12,003 Epoch 1752/2000
2025-02-19 11:12:54,734 Current Learning Rate: 0.0013551569
2025-02-19 11:12:56,388 Train Loss: 0.0001373, Val Loss: 0.0001771
2025-02-19 11:12:56,391 Epoch 1753/2000
2025-02-19 11:13:37,749 Current Learning Rate: 0.0013018445
2025-02-19 11:13:37,751 Train Loss: 0.0001384, Val Loss: 0.0001774
2025-02-19 11:13:37,752 Epoch 1754/2000
2025-02-19 11:14:20,731 Current Learning Rate: 0.0012494447
2025-02-19 11:14:22,637 Train Loss: 0.0001578, Val Loss: 0.0001769
2025-02-19 11:14:22,642 Epoch 1755/2000
2025-02-19 11:14:47,987 Animation.save using <class 'matplotlib.animation.PillowWriter'>
2025-02-19 11:15:05,149 Current Learning Rate: 0.0011979702
2025-02-19 11:15:07,072 Train Loss: 0.0001192, Val Loss: 0.0001768
2025-02-19 11:15:07,083 Epoch 1756/2000
2025-02-19 11:15:48,401 Current Learning Rate: 0.0011474338
2025-02-19 11:15:49,919 Train Loss: 0.0001372, Val Loss: 0.0001765
2025-02-19 11:15:49,937 Epoch 1757/2000
2025-02-19 11:16:31,266 Current Learning Rate: 0.0010978480
2025-02-19 11:16:33,116 Train Loss: 0.0001330, Val Loss: 0.0001763
2025-02-19 11:16:33,119 Epoch 1758/2000
2025-02-19 11:17:14,593 Current Learning Rate: 0.0010492249
2025-02-19 11:17:14,596 Train Loss: 0.0001402, Val Loss: 0.0001765
2025-02-19 11:17:14,597 Epoch 1759/2000
2025-02-19 11:17:57,568 Current Learning Rate: 0.0010015767
2025-02-19 11:17:59,466 Train Loss: 0.0001441, Val Loss: 0.0001760
2025-02-19 11:17:59,469 Epoch 1760/2000
2025-02-19 11:18:42,065 Current Learning Rate: 0.0009549150
2025-02-19 11:18:44,162 Train Loss: 0.0001377, Val Loss: 0.0001759
2025-02-19 11:18:44,165 Epoch 1761/2000
2025-02-19 11:19:27,020 Current Learning Rate: 0.0009092514
2025-02-19 11:19:27,022 Train Loss: 0.0002455, Val Loss: 0.0001764
2025-02-19 11:19:27,023 Epoch 1762/2000
2025-02-19 11:20:09,077 Current Learning Rate: 0.0008645971
2025-02-19 11:20:10,710 Train Loss: 0.0000958, Val Loss: 0.0001755
2025-02-19 11:20:10,731 Epoch 1763/2000
2025-02-19 11:20:52,362 Current Learning Rate: 0.0008209632
2025-02-19 11:20:52,364 Train Loss: 0.0001152, Val Loss: 0.0001756
2025-02-19 11:20:52,365 Epoch 1764/2000
2025-02-19 11:21:34,536 Current Learning Rate: 0.0007783604
2025-02-19 11:21:34,538 Train Loss: 0.0001213, Val Loss: 0.0001756
2025-02-19 11:21:34,539 Epoch 1765/2000
2025-02-19 11:22:16,821 Current Learning Rate: 0.0007367992
2025-02-19 11:22:18,466 Train Loss: 0.0001546, Val Loss: 0.0001754
2025-02-19 11:22:18,473 Epoch 1766/2000
2025-02-19 11:22:59,791 Current Learning Rate: 0.0006962899
2025-02-19 11:22:59,793 Train Loss: 0.0001509, Val Loss: 0.0001757
2025-02-19 11:22:59,795 Epoch 1767/2000
2025-02-19 11:23:42,999 Current Learning Rate: 0.0006568424
2025-02-19 11:23:44,929 Train Loss: 0.0001195, Val Loss: 0.0001753
2025-02-19 11:23:44,932 Epoch 1768/2000
2025-02-19 11:24:27,617 Current Learning Rate: 0.0006184666
2025-02-19 11:24:29,700 Train Loss: 0.0000939, Val Loss: 0.0001752
2025-02-19 11:24:29,704 Epoch 1769/2000
2025-02-19 11:25:12,818 Current Learning Rate: 0.0005811718
2025-02-19 11:25:14,711 Train Loss: 0.0001764, Val Loss: 0.0001752
2025-02-19 11:25:14,714 Epoch 1770/2000
2025-02-19 11:25:57,441 Current Learning Rate: 0.0005449674
2025-02-19 11:25:57,442 Train Loss: 0.0001636, Val Loss: 0.0001752
2025-02-19 11:25:57,443 Epoch 1771/2000
2025-02-19 11:26:40,233 Current Learning Rate: 0.0005098621
2025-02-19 11:26:42,090 Train Loss: 0.0001524, Val Loss: 0.0001751
2025-02-19 11:26:42,095 Epoch 1772/2000
2025-02-19 11:27:24,449 Current Learning Rate: 0.0004758647
2025-02-19 11:27:26,282 Train Loss: 0.0001196, Val Loss: 0.0001750
2025-02-19 11:27:26,285 Epoch 1773/2000
2025-02-19 11:28:07,767 Current Learning Rate: 0.0004429836
2025-02-19 11:28:09,145 Train Loss: 0.0001205, Val Loss: 0.0001750
2025-02-19 11:28:09,148 Epoch 1774/2000
2025-02-19 11:28:50,611 Current Learning Rate: 0.0004112269
2025-02-19 11:28:52,227 Train Loss: 0.0001419, Val Loss: 0.0001748
2025-02-19 11:28:52,230 Epoch 1775/2000
2025-02-19 11:29:35,014 Current Learning Rate: 0.0003806023
2025-02-19 11:29:37,108 Train Loss: 0.0001105, Val Loss: 0.0001748
2025-02-19 11:29:37,117 Epoch 1776/2000
2025-02-19 11:30:19,674 Current Learning Rate: 0.0003511176
2025-02-19 11:30:21,635 Train Loss: 0.0001147, Val Loss: 0.0001747
2025-02-19 11:30:21,639 Epoch 1777/2000
2025-02-19 11:31:04,174 Current Learning Rate: 0.0003227798
2025-02-19 11:31:05,900 Train Loss: 0.0001228, Val Loss: 0.0001745
2025-02-19 11:31:05,902 Epoch 1778/2000
2025-02-19 11:31:47,100 Current Learning Rate: 0.0002955962
2025-02-19 11:31:48,390 Train Loss: 0.0001214, Val Loss: 0.0001745
2025-02-19 11:31:48,392 Epoch 1779/2000
2025-02-19 11:32:30,885 Current Learning Rate: 0.0002695732
2025-02-19 11:32:32,828 Train Loss: 0.0000931, Val Loss: 0.0001744
2025-02-19 11:32:32,831 Epoch 1780/2000
2025-02-19 11:33:14,304 Current Learning Rate: 0.0002447174
2025-02-19 11:33:15,737 Train Loss: 0.0001198, Val Loss: 0.0001743
2025-02-19 11:33:15,746 Epoch 1781/2000
2025-02-19 11:33:58,237 Current Learning Rate: 0.0002210349
2025-02-19 11:33:58,239 Train Loss: 0.0001610, Val Loss: 0.0001744
2025-02-19 11:33:58,240 Epoch 1782/2000
2025-02-19 11:34:40,850 Current Learning Rate: 0.0001985316
2025-02-19 11:34:42,710 Train Loss: 0.0001984, Val Loss: 0.0001743
2025-02-19 11:34:42,713 Epoch 1783/2000
2025-02-19 11:35:24,907 Current Learning Rate: 0.0001772129
2025-02-19 11:35:24,939 Train Loss: 0.0001247, Val Loss: 0.0001743
2025-02-19 11:35:24,953 Epoch 1784/2000
2025-02-19 11:36:07,362 Current Learning Rate: 0.0001570842
2025-02-19 11:36:08,788 Train Loss: 0.0001221, Val Loss: 0.0001743
2025-02-19 11:36:08,801 Epoch 1785/2000
2025-02-19 11:36:51,782 Current Learning Rate: 0.0001381504
2025-02-19 11:36:51,784 Train Loss: 0.0001060, Val Loss: 0.0001743
2025-02-19 11:36:51,785 Epoch 1786/2000
2025-02-19 11:37:33,812 Current Learning Rate: 0.0001204162
2025-02-19 11:37:33,814 Train Loss: 0.0001111, Val Loss: 0.0001743
2025-02-19 11:37:33,815 Epoch 1787/2000
2025-02-19 11:38:15,886 Current Learning Rate: 0.0001038859
2025-02-19 11:38:15,888 Train Loss: 0.0001388, Val Loss: 0.0001743
2025-02-19 11:38:15,889 Epoch 1788/2000
2025-02-19 11:38:58,895 Current Learning Rate: 0.0000885637
2025-02-19 11:38:58,898 Train Loss: 0.0001245, Val Loss: 0.0001743
2025-02-19 11:38:58,899 Epoch 1789/2000
2025-02-19 11:39:41,920 Current Learning Rate: 0.0000744534
2025-02-19 11:39:43,671 Train Loss: 0.0001501, Val Loss: 0.0001742
2025-02-19 11:39:43,674 Epoch 1790/2000
2025-02-19 11:40:25,875 Current Learning Rate: 0.0000615583
2025-02-19 11:40:25,877 Train Loss: 0.0001453, Val Loss: 0.0001743
2025-02-19 11:40:25,878 Epoch 1791/2000
2025-02-19 11:41:09,006 Current Learning Rate: 0.0000498817
2025-02-19 11:41:09,008 Train Loss: 0.0001278, Val Loss: 0.0001742
2025-02-19 11:41:09,009 Epoch 1792/2000
2025-02-19 11:41:51,930 Current Learning Rate: 0.0000394265
2025-02-19 11:41:53,386 Train Loss: 0.0001380, Val Loss: 0.0001742
2025-02-19 11:41:53,392 Epoch 1793/2000
2025-02-19 11:42:34,808 Current Learning Rate: 0.0000301952
2025-02-19 11:42:34,810 Train Loss: 0.0000980, Val Loss: 0.0001742
2025-02-19 11:42:34,811 Epoch 1794/2000
2025-02-19 11:43:17,880 Current Learning Rate: 0.0000221902
2025-02-19 11:43:19,241 Train Loss: 0.0001129, Val Loss: 0.0001742
2025-02-19 11:43:19,244 Epoch 1795/2000
2025-02-19 11:44:02,098 Current Learning Rate: 0.0000154133
2025-02-19 11:44:03,559 Train Loss: 0.0001571, Val Loss: 0.0001741
2025-02-19 11:44:03,562 Epoch 1796/2000
2025-02-19 11:44:46,260 Current Learning Rate: 0.0000098664
2025-02-19 11:44:46,262 Train Loss: 0.0001403, Val Loss: 0.0001742
2025-02-19 11:44:46,263 Epoch 1797/2000
2025-02-19 11:45:29,552 Current Learning Rate: 0.0000055506
2025-02-19 11:45:29,554 Train Loss: 0.0001222, Val Loss: 0.0001742
2025-02-19 11:45:29,581 Epoch 1798/2000
2025-02-19 11:46:11,982 Current Learning Rate: 0.0000024672
2025-02-19 11:46:11,985 Train Loss: 0.0001442, Val Loss: 0.0001742
2025-02-19 11:46:11,986 Epoch 1799/2000
2025-02-19 11:46:54,882 Current Learning Rate: 0.0000006168
2025-02-19 11:46:56,639 Train Loss: 0.0001533, Val Loss: 0.0001741
2025-02-19 11:46:56,642 Epoch 1800/2000
2025-02-19 11:47:39,456 Current Learning Rate: 0.0000000000
2025-02-19 11:47:39,459 Train Loss: 0.0001512, Val Loss: 0.0001741
2025-02-19 11:47:39,460 Epoch 1801/2000
2025-02-19 11:48:22,567 Current Learning Rate: 0.0000006168
2025-02-19 11:48:22,586 Train Loss: 0.0001399, Val Loss: 0.0001742
2025-02-19 11:48:22,588 Epoch 1802/2000
2025-02-19 11:49:05,407 Current Learning Rate: 0.0000024672
2025-02-19 11:49:05,409 Train Loss: 0.0001749, Val Loss: 0.0001741
2025-02-19 11:49:05,410 Epoch 1803/2000
2025-02-19 11:49:47,644 Current Learning Rate: 0.0000055506
2025-02-19 11:49:47,646 Train Loss: 0.0001430, Val Loss: 0.0001741
2025-02-19 11:49:47,647 Epoch 1804/2000
2025-02-19 11:50:30,011 Current Learning Rate: 0.0000098664
2025-02-19 11:50:30,013 Train Loss: 0.0001170, Val Loss: 0.0001742
2025-02-19 11:50:30,014 Epoch 1805/2000
2025-02-19 11:51:11,955 Current Learning Rate: 0.0000154133
2025-02-19 11:51:11,957 Train Loss: 0.0001191, Val Loss: 0.0001742
2025-02-19 11:51:11,958 Epoch 1806/2000
2025-02-19 11:51:54,716 Current Learning Rate: 0.0000221902
2025-02-19 11:51:54,718 Train Loss: 0.0001110, Val Loss: 0.0001742
2025-02-19 11:51:54,719 Epoch 1807/2000
2025-02-19 11:52:36,481 Current Learning Rate: 0.0000301952
2025-02-19 11:52:36,483 Train Loss: 0.0001361, Val Loss: 0.0001741
2025-02-19 11:52:36,484 Epoch 1808/2000
2025-02-19 11:53:18,753 Current Learning Rate: 0.0000394265
2025-02-19 11:53:18,755 Train Loss: 0.0001192, Val Loss: 0.0001742
2025-02-19 11:53:18,756 Epoch 1809/2000
2025-02-19 11:54:01,167 Current Learning Rate: 0.0000498817
2025-02-19 11:54:01,169 Train Loss: 0.0001584, Val Loss: 0.0001741
2025-02-19 11:54:01,170 Epoch 1810/2000
2025-02-19 11:54:44,568 Current Learning Rate: 0.0000615583
2025-02-19 11:54:44,570 Train Loss: 0.0001216, Val Loss: 0.0001742
2025-02-19 11:54:44,571 Epoch 1811/2000
2025-02-19 11:55:27,446 Current Learning Rate: 0.0000744534
2025-02-19 11:55:27,449 Train Loss: 0.0001477, Val Loss: 0.0001742
2025-02-19 11:55:27,450 Epoch 1812/2000
2025-02-19 11:56:10,295 Current Learning Rate: 0.0000885637
2025-02-19 11:56:10,323 Train Loss: 0.0001707, Val Loss: 0.0001742
2025-02-19 11:56:10,335 Epoch 1813/2000
2025-02-19 11:56:53,208 Current Learning Rate: 0.0001038859
2025-02-19 11:56:53,210 Train Loss: 0.0001253, Val Loss: 0.0001742
2025-02-19 11:56:53,211 Epoch 1814/2000
2025-02-19 11:57:35,351 Current Learning Rate: 0.0001204162
2025-02-19 11:57:35,354 Train Loss: 0.0001129, Val Loss: 0.0001743
2025-02-19 11:57:35,355 Epoch 1815/2000
2025-02-19 11:58:17,273 Current Learning Rate: 0.0001381504
2025-02-19 11:58:17,276 Train Loss: 0.0001055, Val Loss: 0.0001742
2025-02-19 11:58:17,277 Epoch 1816/2000
2025-02-19 11:59:00,086 Current Learning Rate: 0.0001570842
2025-02-19 11:59:00,089 Train Loss: 0.0001858, Val Loss: 0.0001742
2025-02-19 11:59:00,090 Epoch 1817/2000
2025-02-19 11:59:42,882 Current Learning Rate: 0.0001772129
2025-02-19 11:59:42,918 Train Loss: 0.0000986, Val Loss: 0.0001742
2025-02-19 11:59:42,934 Epoch 1818/2000
2025-02-19 12:00:24,837 Current Learning Rate: 0.0001985316
2025-02-19 12:00:24,839 Train Loss: 0.0001297, Val Loss: 0.0001742
2025-02-19 12:00:24,841 Epoch 1819/2000
2025-02-19 12:01:08,031 Current Learning Rate: 0.0002210349
2025-02-19 12:01:08,045 Train Loss: 0.0000983, Val Loss: 0.0001743
2025-02-19 12:01:08,055 Epoch 1820/2000
2025-02-19 12:01:50,556 Current Learning Rate: 0.0002447174
2025-02-19 12:01:50,559 Train Loss: 0.0001394, Val Loss: 0.0001742
2025-02-19 12:01:50,560 Epoch 1821/2000
2025-02-19 12:02:33,642 Current Learning Rate: 0.0002695732
2025-02-19 12:02:33,644 Train Loss: 0.0001232, Val Loss: 0.0001745
2025-02-19 12:02:33,646 Epoch 1822/2000
2025-02-19 12:03:16,185 Current Learning Rate: 0.0002955962
2025-02-19 12:03:16,188 Train Loss: 0.0001277, Val Loss: 0.0001745
2025-02-19 12:03:16,189 Epoch 1823/2000
2025-02-19 12:03:59,199 Current Learning Rate: 0.0003227798
2025-02-19 12:03:59,201 Train Loss: 0.0001523, Val Loss: 0.0001745
2025-02-19 12:03:59,202 Epoch 1824/2000
2025-02-19 12:04:42,066 Current Learning Rate: 0.0003511176
2025-02-19 12:04:42,068 Train Loss: 0.0001470, Val Loss: 0.0001744
2025-02-19 12:04:42,069 Epoch 1825/2000
2025-02-19 12:05:23,947 Current Learning Rate: 0.0003806023
2025-02-19 12:05:23,949 Train Loss: 0.0001038, Val Loss: 0.0001745
2025-02-19 12:05:23,950 Epoch 1826/2000
2025-02-19 12:06:06,651 Current Learning Rate: 0.0004112269
2025-02-19 12:06:06,653 Train Loss: 0.0001119, Val Loss: 0.0001745
2025-02-19 12:06:06,654 Epoch 1827/2000
2025-02-19 12:06:50,039 Current Learning Rate: 0.0004429836
2025-02-19 12:06:50,041 Train Loss: 0.0001061, Val Loss: 0.0001744
2025-02-19 12:06:50,042 Epoch 1828/2000
2025-02-19 12:07:32,401 Current Learning Rate: 0.0004758647
2025-02-19 12:07:32,403 Train Loss: 0.0001283, Val Loss: 0.0001744
2025-02-19 12:07:32,404 Epoch 1829/2000
2025-02-19 12:08:15,451 Current Learning Rate: 0.0005098621
2025-02-19 12:08:15,453 Train Loss: 0.0001414, Val Loss: 0.0001744
2025-02-19 12:08:15,454 Epoch 1830/2000
2025-02-19 12:08:57,536 Current Learning Rate: 0.0005449674
2025-02-19 12:08:57,548 Train Loss: 0.0001372, Val Loss: 0.0001744
2025-02-19 12:08:57,549 Epoch 1831/2000
2025-02-19 12:09:41,181 Current Learning Rate: 0.0005811718
2025-02-19 12:09:41,183 Train Loss: 0.0001302, Val Loss: 0.0001746
2025-02-19 12:09:41,185 Epoch 1832/2000
2025-02-19 12:10:23,757 Current Learning Rate: 0.0006184666
2025-02-19 12:10:23,770 Train Loss: 0.0001197, Val Loss: 0.0001746
2025-02-19 12:10:23,771 Epoch 1833/2000
2025-02-19 12:11:05,801 Current Learning Rate: 0.0006568424
2025-02-19 12:11:05,803 Train Loss: 0.0001108, Val Loss: 0.0001746
2025-02-19 12:11:05,804 Epoch 1834/2000
2025-02-19 12:11:48,264 Current Learning Rate: 0.0006962899
2025-02-19 12:11:48,266 Train Loss: 0.0001037, Val Loss: 0.0001744
2025-02-19 12:11:48,267 Epoch 1835/2000
2025-02-19 12:12:30,671 Current Learning Rate: 0.0007367992
2025-02-19 12:12:30,673 Train Loss: 0.0001293, Val Loss: 0.0001746
2025-02-19 12:12:30,674 Epoch 1836/2000
2025-02-19 12:13:12,733 Current Learning Rate: 0.0007783604
2025-02-19 12:13:12,736 Train Loss: 0.0001777, Val Loss: 0.0001746
2025-02-19 12:13:12,737 Epoch 1837/2000
2025-02-19 12:13:55,874 Current Learning Rate: 0.0008209632
2025-02-19 12:13:55,876 Train Loss: 0.0000935, Val Loss: 0.0001746
2025-02-19 12:13:55,877 Epoch 1838/2000
2025-02-19 12:14:37,760 Current Learning Rate: 0.0008645971
2025-02-19 12:14:37,763 Train Loss: 0.0001468, Val Loss: 0.0001747
2025-02-19 12:14:37,765 Epoch 1839/2000
2025-02-19 12:15:20,912 Current Learning Rate: 0.0009092514
2025-02-19 12:15:20,924 Train Loss: 0.0001294, Val Loss: 0.0001750
2025-02-19 12:15:20,924 Epoch 1840/2000
2025-02-19 12:16:04,075 Current Learning Rate: 0.0009549150
2025-02-19 12:16:04,077 Train Loss: 0.0001095, Val Loss: 0.0001759
2025-02-19 12:16:04,078 Epoch 1841/2000
2025-02-19 12:16:47,103 Current Learning Rate: 0.0010015767
2025-02-19 12:16:47,105 Train Loss: 0.0001207, Val Loss: 0.0001748
2025-02-19 12:16:47,106 Epoch 1842/2000
2025-02-19 12:17:29,899 Current Learning Rate: 0.0010492249
2025-02-19 12:17:29,901 Train Loss: 0.0001532, Val Loss: 0.0001756
2025-02-19 12:17:29,902 Epoch 1843/2000
2025-02-19 12:18:12,923 Current Learning Rate: 0.0010978480
2025-02-19 12:18:12,925 Train Loss: 0.0001866, Val Loss: 0.0001762
2025-02-19 12:18:12,926 Epoch 1844/2000
2025-02-19 12:18:55,950 Current Learning Rate: 0.0011474338
2025-02-19 12:18:55,951 Train Loss: 0.0001799, Val Loss: 0.0001807
2025-02-19 12:18:55,952 Epoch 1845/2000
2025-02-19 12:19:38,629 Current Learning Rate: 0.0011979702
2025-02-19 12:19:38,634 Train Loss: 0.0001183, Val Loss: 0.0001773
2025-02-19 12:19:38,637 Epoch 1846/2000
2025-02-19 12:20:22,246 Current Learning Rate: 0.0012494447
2025-02-19 12:20:22,252 Train Loss: 0.0001512, Val Loss: 0.0001773
2025-02-19 12:20:22,253 Epoch 1847/2000
2025-02-19 12:21:05,662 Current Learning Rate: 0.0013018445
2025-02-19 12:21:05,664 Train Loss: 0.0001506, Val Loss: 0.0001775
2025-02-19 12:21:05,665 Epoch 1848/2000
2025-02-19 12:21:49,080 Current Learning Rate: 0.0013551569
2025-02-19 12:21:49,082 Train Loss: 0.0001220, Val Loss: 0.0001756
2025-02-19 12:21:49,083 Epoch 1849/2000
2025-02-19 12:22:32,706 Current Learning Rate: 0.0014093685
2025-02-19 12:22:32,708 Train Loss: 0.0001570, Val Loss: 0.0001761
2025-02-19 12:22:32,709 Epoch 1850/2000
2025-02-19 12:23:15,700 Current Learning Rate: 0.0014644661
2025-02-19 12:23:15,702 Train Loss: 0.0001315, Val Loss: 0.0001758
2025-02-19 12:23:15,704 Epoch 1851/2000
2025-02-19 12:23:59,036 Current Learning Rate: 0.0015204360
2025-02-19 12:23:59,039 Train Loss: 0.0001497, Val Loss: 0.0001762
2025-02-19 12:23:59,074 Epoch 1852/2000
2025-02-19 12:24:42,234 Current Learning Rate: 0.0015772645
2025-02-19 12:24:42,238 Train Loss: 0.0001273, Val Loss: 0.0001767
2025-02-19 12:24:42,246 Epoch 1853/2000
2025-02-19 12:25:24,558 Current Learning Rate: 0.0016349374
2025-02-19 12:25:24,560 Train Loss: 0.0001386, Val Loss: 0.0001770
2025-02-19 12:25:24,562 Epoch 1854/2000
2025-02-19 12:26:07,061 Current Learning Rate: 0.0016934407
2025-02-19 12:26:07,063 Train Loss: 0.0001244, Val Loss: 0.0001767
2025-02-19 12:26:07,064 Epoch 1855/2000
2025-02-19 12:26:50,560 Current Learning Rate: 0.0017527598
2025-02-19 12:26:50,562 Train Loss: 0.0001597, Val Loss: 0.0001763
2025-02-19 12:26:50,564 Epoch 1856/2000
2025-02-19 12:27:33,496 Current Learning Rate: 0.0018128801
2025-02-19 12:27:33,498 Train Loss: 0.0001338, Val Loss: 0.0001765
2025-02-19 12:27:33,499 Epoch 1857/2000
2025-02-19 12:28:16,591 Current Learning Rate: 0.0018737867
2025-02-19 12:28:16,593 Train Loss: 0.0001112, Val Loss: 0.0001756
2025-02-19 12:28:16,594 Epoch 1858/2000
2025-02-19 12:28:59,714 Current Learning Rate: 0.0019354647
2025-02-19 12:28:59,728 Train Loss: 0.0001042, Val Loss: 0.0001755
2025-02-19 12:28:59,729 Epoch 1859/2000
2025-02-19 12:29:42,375 Current Learning Rate: 0.0019978989
2025-02-19 12:29:42,378 Train Loss: 0.0001398, Val Loss: 0.0001781
2025-02-19 12:29:42,380 Epoch 1860/2000
2025-02-19 12:30:25,218 Current Learning Rate: 0.0020610737
2025-02-19 12:30:25,220 Train Loss: 0.0001001, Val Loss: 0.0001758
2025-02-19 12:30:25,221 Epoch 1861/2000
2025-02-19 12:31:07,200 Current Learning Rate: 0.0021249737
2025-02-19 12:31:07,202 Train Loss: 0.0001824, Val Loss: 0.0001930
2025-02-19 12:31:07,203 Epoch 1862/2000
2025-02-19 12:31:50,163 Current Learning Rate: 0.0021895831
2025-02-19 12:31:50,165 Train Loss: 0.0001672, Val Loss: 0.0001807
2025-02-19 12:31:50,166 Epoch 1863/2000
2025-02-19 12:32:33,415 Current Learning Rate: 0.0022548859
2025-02-19 12:32:33,452 Train Loss: 0.0001289, Val Loss: 0.0001816
2025-02-19 12:32:33,464 Epoch 1864/2000
2025-02-19 12:33:16,080 Current Learning Rate: 0.0023208660
2025-02-19 12:33:16,082 Train Loss: 0.0001369, Val Loss: 0.0001785
2025-02-19 12:33:16,083 Epoch 1865/2000
2025-02-19 12:33:58,243 Current Learning Rate: 0.0023875072
2025-02-19 12:33:58,244 Train Loss: 0.0001618, Val Loss: 0.0001838
2025-02-19 12:33:58,246 Epoch 1866/2000
2025-02-19 12:34:40,625 Current Learning Rate: 0.0024547929
2025-02-19 12:34:40,631 Train Loss: 0.0001429, Val Loss: 0.0001811
2025-02-19 12:34:40,635 Epoch 1867/2000
2025-02-19 12:35:23,548 Current Learning Rate: 0.0025227067
2025-02-19 12:35:23,550 Train Loss: 0.0001820, Val Loss: 0.0001815
2025-02-19 12:35:23,551 Epoch 1868/2000
2025-02-19 12:36:06,908 Current Learning Rate: 0.0025912316
2025-02-19 12:36:06,910 Train Loss: 0.0001412, Val Loss: 0.0001773
2025-02-19 12:36:06,911 Epoch 1869/2000
2025-02-19 12:36:49,766 Current Learning Rate: 0.0026603509
2025-02-19 12:36:49,768 Train Loss: 0.0001425, Val Loss: 0.0001778
2025-02-19 12:36:49,770 Epoch 1870/2000
2025-02-19 12:37:32,337 Current Learning Rate: 0.0027300475
2025-02-19 12:37:32,339 Train Loss: 0.0001261, Val Loss: 0.0001773
2025-02-19 12:37:32,340 Epoch 1871/2000
2025-02-19 12:38:15,409 Current Learning Rate: 0.0028003042
2025-02-19 12:38:15,411 Train Loss: 0.0001707, Val Loss: 0.0002012
2025-02-19 12:38:15,412 Epoch 1872/2000
2025-02-19 12:38:58,870 Current Learning Rate: 0.0028711035
2025-02-19 12:38:58,880 Train Loss: 0.0001108, Val Loss: 0.0001784
2025-02-19 12:38:58,883 Epoch 1873/2000
2025-02-19 12:39:42,503 Current Learning Rate: 0.0029424282
2025-02-19 12:39:42,505 Train Loss: 0.0001836, Val Loss: 0.0001955
2025-02-19 12:39:42,507 Epoch 1874/2000
2025-02-19 12:40:24,627 Current Learning Rate: 0.0030142605
2025-02-19 12:40:24,630 Train Loss: 0.0001284, Val Loss: 0.0001809
2025-02-19 12:40:24,632 Epoch 1875/2000
2025-02-19 12:41:07,310 Current Learning Rate: 0.0030865828
2025-02-19 12:41:07,317 Train Loss: 0.0001500, Val Loss: 0.0001807
2025-02-19 12:41:07,322 Epoch 1876/2000
2025-02-19 12:41:50,456 Current Learning Rate: 0.0031593772
2025-02-19 12:41:50,458 Train Loss: 0.0001474, Val Loss: 0.0001829
2025-02-19 12:41:50,459 Epoch 1877/2000
2025-02-19 12:42:32,299 Current Learning Rate: 0.0032326258
2025-02-19 12:42:32,301 Train Loss: 0.0001471, Val Loss: 0.0001927
2025-02-19 12:42:32,302 Epoch 1878/2000
2025-02-19 12:43:15,459 Current Learning Rate: 0.0033063104
2025-02-19 12:43:15,461 Train Loss: 0.0001239, Val Loss: 0.0001840
2025-02-19 12:43:15,462 Epoch 1879/2000
2025-02-19 12:43:57,982 Current Learning Rate: 0.0033804129
2025-02-19 12:43:57,985 Train Loss: 0.0001551, Val Loss: 0.0001843
2025-02-19 12:43:57,985 Epoch 1880/2000
2025-02-19 12:44:41,661 Current Learning Rate: 0.0034549150
2025-02-19 12:44:41,662 Train Loss: 0.0001069, Val Loss: 0.0001824
2025-02-19 12:44:41,663 Epoch 1881/2000
2025-02-19 12:45:24,891 Current Learning Rate: 0.0035297984
2025-02-19 12:45:24,892 Train Loss: 0.0001347, Val Loss: 0.0001799
2025-02-19 12:45:24,893 Epoch 1882/2000
2025-02-19 12:46:07,836 Current Learning Rate: 0.0036050445
2025-02-19 12:46:07,838 Train Loss: 0.0001391, Val Loss: 0.0001903
2025-02-19 12:46:07,839 Epoch 1883/2000
2025-02-19 12:46:50,953 Current Learning Rate: 0.0036806348
2025-02-19 12:46:50,955 Train Loss: 0.0001913, Val Loss: 0.0001860
2025-02-19 12:46:50,956 Epoch 1884/2000
2025-02-19 12:47:33,816 Current Learning Rate: 0.0037565506
2025-02-19 12:47:33,817 Train Loss: 0.0001617, Val Loss: 0.0001902
2025-02-19 12:47:33,818 Epoch 1885/2000
2025-02-19 12:48:16,277 Current Learning Rate: 0.0038327732
2025-02-19 12:48:16,296 Train Loss: 0.0001117, Val Loss: 0.0001784
2025-02-19 12:48:16,308 Epoch 1886/2000
2025-02-19 12:48:58,598 Current Learning Rate: 0.0039092838
2025-02-19 12:48:58,600 Train Loss: 0.0001097, Val Loss: 0.0001794
2025-02-19 12:48:58,601 Epoch 1887/2000
2025-02-19 12:49:41,327 Current Learning Rate: 0.0039860635
2025-02-19 12:49:41,329 Train Loss: 0.0001837, Val Loss: 0.0002079
2025-02-19 12:49:41,330 Epoch 1888/2000
2025-02-19 12:50:24,139 Current Learning Rate: 0.0040630934
2025-02-19 12:50:24,141 Train Loss: 0.0001462, Val Loss: 0.0002011
2025-02-19 12:50:24,142 Epoch 1889/2000
2025-02-19 12:51:07,131 Current Learning Rate: 0.0041403545
2025-02-19 12:51:07,133 Train Loss: 0.0001310, Val Loss: 0.0001901
2025-02-19 12:51:07,134 Epoch 1890/2000
2025-02-19 12:51:50,033 Current Learning Rate: 0.0042178277
2025-02-19 12:51:50,034 Train Loss: 0.0001309, Val Loss: 0.0001880
2025-02-19 12:51:50,035 Epoch 1891/2000
2025-02-19 12:52:33,061 Current Learning Rate: 0.0042954938
2025-02-19 12:52:33,063 Train Loss: 0.0001679, Val Loss: 0.0001867
2025-02-19 12:52:33,064 Epoch 1892/2000
2025-02-19 12:53:16,272 Current Learning Rate: 0.0043733338
2025-02-19 12:53:16,274 Train Loss: 0.0001340, Val Loss: 0.0001908
2025-02-19 12:53:16,275 Epoch 1893/2000
2025-02-19 12:53:58,604 Current Learning Rate: 0.0044513284
2025-02-19 12:53:58,606 Train Loss: 0.0001083, Val Loss: 0.0001788
2025-02-19 12:53:58,607 Epoch 1894/2000
2025-02-19 12:54:40,754 Current Learning Rate: 0.0045294584
2025-02-19 12:54:40,756 Train Loss: 0.0001780, Val Loss: 0.0002197
2025-02-19 12:54:40,757 Epoch 1895/2000
2025-02-19 12:55:23,753 Current Learning Rate: 0.0046077045
2025-02-19 12:55:23,755 Train Loss: 0.0001931, Val Loss: 0.0002177
2025-02-19 12:55:23,756 Epoch 1896/2000
2025-02-19 12:56:06,207 Current Learning Rate: 0.0046860474
2025-02-19 12:56:06,209 Train Loss: 0.0001484, Val Loss: 0.0001954
2025-02-19 12:56:06,210 Epoch 1897/2000
2025-02-19 12:56:48,579 Current Learning Rate: 0.0047644677
2025-02-19 12:56:48,581 Train Loss: 0.0002076, Val Loss: 0.0002016
2025-02-19 12:56:48,582 Epoch 1898/2000
2025-02-19 12:57:30,641 Current Learning Rate: 0.0048429462
2025-02-19 12:57:30,643 Train Loss: 0.0001683, Val Loss: 0.0001948
2025-02-19 12:57:30,644 Epoch 1899/2000
2025-02-19 12:58:13,226 Current Learning Rate: 0.0049214634
2025-02-19 12:58:13,227 Train Loss: 0.0001474, Val Loss: 0.0001895
2025-02-19 12:58:13,228 Epoch 1900/2000
2025-02-19 12:58:56,372 Current Learning Rate: 0.0050000000
2025-02-19 12:58:56,374 Train Loss: 0.0001495, Val Loss: 0.0001913
2025-02-19 12:58:56,375 Epoch 1901/2000
2025-02-19 12:59:39,317 Current Learning Rate: 0.0050785366
2025-02-19 12:59:39,319 Train Loss: 0.0001509, Val Loss: 0.0001909
2025-02-19 12:59:39,320 Epoch 1902/2000
2025-02-19 13:00:21,728 Current Learning Rate: 0.0051570538
2025-02-19 13:00:21,730 Train Loss: 0.0001277, Val Loss: 0.0001865
2025-02-19 13:00:21,731 Epoch 1903/2000
2025-02-19 13:01:03,791 Current Learning Rate: 0.0052355323
2025-02-19 13:01:03,793 Train Loss: 0.0001968, Val Loss: 0.0002157
2025-02-19 13:01:03,794 Epoch 1904/2000
2025-02-19 13:01:46,164 Current Learning Rate: 0.0053139526
2025-02-19 13:01:46,166 Train Loss: 0.0001786, Val Loss: 0.0002102
2025-02-19 13:01:46,167 Epoch 1905/2000
2025-02-19 13:02:28,463 Current Learning Rate: 0.0053922955
2025-02-19 13:02:28,467 Train Loss: 0.0002122, Val Loss: 0.0002331
2025-02-19 13:02:28,468 Epoch 1906/2000
2025-02-19 13:03:10,775 Current Learning Rate: 0.0054705416
2025-02-19 13:03:10,777 Train Loss: 0.0001955, Val Loss: 0.0002446
2025-02-19 13:03:10,780 Epoch 1907/2000
2025-02-19 13:03:53,641 Current Learning Rate: 0.0055486716
2025-02-19 13:03:53,643 Train Loss: 0.0001329, Val Loss: 0.0002061
2025-02-19 13:03:53,644 Epoch 1908/2000
2025-02-19 13:04:36,065 Current Learning Rate: 0.0056266662
2025-02-19 13:04:36,067 Train Loss: 0.0001447, Val Loss: 0.0002013
2025-02-19 13:04:36,068 Epoch 1909/2000
2025-02-19 13:05:18,580 Current Learning Rate: 0.0057045062
2025-02-19 13:05:18,582 Train Loss: 0.0001538, Val Loss: 0.0002521
2025-02-19 13:05:18,583 Epoch 1910/2000
2025-02-19 13:06:00,780 Current Learning Rate: 0.0057821723
2025-02-19 13:06:00,782 Train Loss: 0.0001372, Val Loss: 0.0002132
2025-02-19 13:06:00,784 Epoch 1911/2000
2025-02-19 13:06:42,989 Current Learning Rate: 0.0058596455
2025-02-19 13:06:42,991 Train Loss: 0.0002274, Val Loss: 0.0002715
2025-02-19 13:06:42,992 Epoch 1912/2000
2025-02-19 13:07:25,288 Current Learning Rate: 0.0059369066
2025-02-19 13:07:25,290 Train Loss: 0.0002275, Val Loss: 0.0002161
2025-02-19 13:07:25,291 Epoch 1913/2000
2025-02-19 13:08:08,528 Current Learning Rate: 0.0060139365
2025-02-19 13:08:08,530 Train Loss: 0.0001516, Val Loss: 0.0002050
2025-02-19 13:08:08,531 Epoch 1914/2000
2025-02-19 13:08:50,689 Current Learning Rate: 0.0060907162
2025-02-19 13:08:50,690 Train Loss: 0.0001514, Val Loss: 0.0002046
2025-02-19 13:08:50,691 Epoch 1915/2000
2025-02-19 13:09:33,697 Current Learning Rate: 0.0061672268
2025-02-19 13:09:33,698 Train Loss: 0.0001509, Val Loss: 0.0002016
2025-02-19 13:09:33,699 Epoch 1916/2000
2025-02-19 13:10:16,147 Current Learning Rate: 0.0062434494
2025-02-19 13:10:16,149 Train Loss: 0.0001351, Val Loss: 0.0002077
2025-02-19 13:10:16,150 Epoch 1917/2000
2025-02-19 13:10:59,057 Current Learning Rate: 0.0063193652
2025-02-19 13:10:59,059 Train Loss: 0.0001638, Val Loss: 0.0002379
2025-02-19 13:10:59,060 Epoch 1918/2000
2025-02-19 13:11:41,942 Current Learning Rate: 0.0063949555
2025-02-19 13:11:41,944 Train Loss: 0.0001867, Val Loss: 0.0002167
2025-02-19 13:11:41,981 Epoch 1919/2000
2025-02-19 13:12:24,970 Current Learning Rate: 0.0064702016
2025-02-19 13:12:24,972 Train Loss: 0.0001658, Val Loss: 0.0002154
2025-02-19 13:12:24,973 Epoch 1920/2000
2025-02-19 13:13:07,878 Current Learning Rate: 0.0065450850
2025-02-19 13:13:07,880 Train Loss: 0.0002318, Val Loss: 0.0002632
2025-02-19 13:13:07,881 Epoch 1921/2000
2025-02-19 13:13:50,872 Current Learning Rate: 0.0066195871
2025-02-19 13:13:50,874 Train Loss: 0.0001913, Val Loss: 0.0002284
2025-02-19 13:13:50,875 Epoch 1922/2000
2025-02-19 13:14:33,804 Current Learning Rate: 0.0066936896
2025-02-19 13:14:33,806 Train Loss: 0.0001459, Val Loss: 0.0002138
2025-02-19 13:14:33,807 Epoch 1923/2000
2025-02-19 13:15:16,813 Current Learning Rate: 0.0067673742
2025-02-19 13:15:16,815 Train Loss: 0.0002812, Val Loss: 0.0002483
2025-02-19 13:15:16,816 Epoch 1924/2000
2025-02-19 13:15:59,207 Current Learning Rate: 0.0068406228
2025-02-19 13:15:59,209 Train Loss: 0.0002145, Val Loss: 0.0002288
2025-02-19 13:15:59,210 Epoch 1925/2000
2025-02-19 13:16:41,938 Current Learning Rate: 0.0069134172
2025-02-19 13:16:41,940 Train Loss: 0.0001984, Val Loss: 0.0002528
2025-02-19 13:16:41,941 Epoch 1926/2000
2025-02-19 13:17:25,177 Current Learning Rate: 0.0069857395
2025-02-19 13:17:25,198 Train Loss: 0.0002265, Val Loss: 0.0002222
2025-02-19 13:17:25,199 Epoch 1927/2000
2025-02-19 13:18:07,944 Current Learning Rate: 0.0070575718
2025-02-19 13:18:07,945 Train Loss: 0.0001428, Val Loss: 0.0002000
2025-02-19 13:18:07,947 Epoch 1928/2000
2025-02-19 13:18:50,744 Current Learning Rate: 0.0071288965
2025-02-19 13:18:50,746 Train Loss: 0.0001800, Val Loss: 0.0002026
2025-02-19 13:18:50,747 Epoch 1929/2000
2025-02-19 13:19:33,919 Current Learning Rate: 0.0071996958
2025-02-19 13:19:33,921 Train Loss: 0.0001496, Val Loss: 0.0002037
2025-02-19 13:19:33,921 Epoch 1930/2000
2025-02-19 13:20:16,809 Current Learning Rate: 0.0072699525
2025-02-19 13:20:16,810 Train Loss: 0.0001270, Val Loss: 0.0001976
2025-02-19 13:20:16,811 Epoch 1931/2000
2025-02-19 13:20:59,522 Current Learning Rate: 0.0073396491
2025-02-19 13:20:59,524 Train Loss: 0.0001876, Val Loss: 0.0002109
2025-02-19 13:20:59,525 Epoch 1932/2000
2025-02-19 13:21:41,327 Current Learning Rate: 0.0074087684
2025-02-19 13:21:41,329 Train Loss: 0.0002204, Val Loss: 0.0002758
2025-02-19 13:21:41,330 Epoch 1933/2000
2025-02-19 13:22:24,108 Current Learning Rate: 0.0074772933
2025-02-19 13:22:24,110 Train Loss: 0.0002512, Val Loss: 0.0003013
2025-02-19 13:22:24,111 Epoch 1934/2000
2025-02-19 13:23:06,154 Current Learning Rate: 0.0075452071
2025-02-19 13:23:06,156 Train Loss: 0.0001801, Val Loss: 0.0002345
2025-02-19 13:23:06,157 Epoch 1935/2000
2025-02-19 13:23:49,081 Current Learning Rate: 0.0076124928
2025-02-19 13:23:49,083 Train Loss: 0.0001786, Val Loss: 0.0002157
2025-02-19 13:23:49,084 Epoch 1936/2000
2025-02-19 13:24:32,073 Current Learning Rate: 0.0076791340
2025-02-19 13:24:32,076 Train Loss: 0.0001962, Val Loss: 0.0002676
2025-02-19 13:24:32,079 Epoch 1937/2000
2025-02-19 13:25:14,555 Current Learning Rate: 0.0077451141
2025-02-19 13:25:14,556 Train Loss: 0.0001862, Val Loss: 0.0003078
2025-02-19 13:25:14,557 Epoch 1938/2000
2025-02-19 13:25:57,598 Current Learning Rate: 0.0078104169
2025-02-19 13:25:57,600 Train Loss: 0.0002606, Val Loss: 0.0002930
2025-02-19 13:25:57,624 Epoch 1939/2000
2025-02-19 13:26:40,458 Current Learning Rate: 0.0078750263
2025-02-19 13:26:40,459 Train Loss: 0.0002308, Val Loss: 0.0002649
2025-02-19 13:26:40,460 Epoch 1940/2000
2025-02-19 13:27:23,032 Current Learning Rate: 0.0079389263
2025-02-19 13:27:23,034 Train Loss: 0.0002622, Val Loss: 0.0003057
2025-02-19 13:27:23,034 Epoch 1941/2000
2025-02-19 13:28:05,654 Current Learning Rate: 0.0080021011
2025-02-19 13:28:05,674 Train Loss: 0.0001882, Val Loss: 0.0002389
2025-02-19 13:28:05,684 Epoch 1942/2000
2025-02-19 13:28:48,651 Current Learning Rate: 0.0080645353
2025-02-19 13:28:48,653 Train Loss: 0.0002612, Val Loss: 0.0002628
2025-02-19 13:28:48,654 Epoch 1943/2000
2025-02-19 13:29:31,359 Current Learning Rate: 0.0081262133
2025-02-19 13:29:31,365 Train Loss: 0.0002431, Val Loss: 0.0002704
2025-02-19 13:29:31,380 Epoch 1944/2000
2025-02-19 13:30:13,373 Current Learning Rate: 0.0081871199
2025-02-19 13:30:13,375 Train Loss: 0.0002086, Val Loss: 0.0002460
2025-02-19 13:30:13,376 Epoch 1945/2000
2025-02-19 13:30:55,763 Current Learning Rate: 0.0082472402
2025-02-19 13:30:55,764 Train Loss: 0.0001597, Val Loss: 0.0002605
2025-02-19 13:30:55,766 Epoch 1946/2000
2025-02-19 13:31:38,097 Current Learning Rate: 0.0083065593
2025-02-19 13:31:38,100 Train Loss: 0.0002475, Val Loss: 0.0002503
2025-02-19 13:31:38,101 Epoch 1947/2000
2025-02-19 13:32:19,906 Current Learning Rate: 0.0083650626
2025-02-19 13:32:19,908 Train Loss: 0.0001475, Val Loss: 0.0002258
2025-02-19 13:32:19,909 Epoch 1948/2000
2025-02-19 13:33:03,173 Current Learning Rate: 0.0084227355
2025-02-19 13:33:03,175 Train Loss: 0.0002425, Val Loss: 0.0002687
2025-02-19 13:33:03,176 Epoch 1949/2000
2025-02-19 13:33:44,897 Current Learning Rate: 0.0084795640
2025-02-19 13:33:44,899 Train Loss: 0.0004316, Val Loss: 0.0004006
2025-02-19 13:33:44,900 Epoch 1950/2000
2025-02-19 13:34:27,879 Current Learning Rate: 0.0085355339
2025-02-19 13:34:27,918 Train Loss: 0.0002529, Val Loss: 0.0002580
2025-02-19 13:34:27,953 Epoch 1951/2000
2025-02-19 13:35:10,671 Current Learning Rate: 0.0085906315
2025-02-19 13:35:10,673 Train Loss: 0.0002903, Val Loss: 0.0002955
2025-02-19 13:35:10,674 Epoch 1952/2000
2025-02-19 13:35:53,550 Current Learning Rate: 0.0086448431
2025-02-19 13:35:53,553 Train Loss: 0.0003255, Val Loss: 0.0003264
2025-02-19 13:35:53,554 Epoch 1953/2000
2025-02-19 13:36:35,914 Current Learning Rate: 0.0086981555
2025-02-19 13:36:35,916 Train Loss: 0.0002436, Val Loss: 0.0002938
2025-02-19 13:36:35,917 Epoch 1954/2000
2025-02-19 13:37:18,312 Current Learning Rate: 0.0087505553
2025-02-19 13:37:18,314 Train Loss: 0.0002444, Val Loss: 0.0002661
2025-02-19 13:37:18,315 Epoch 1955/2000
2025-02-19 13:38:00,641 Current Learning Rate: 0.0088020298
2025-02-19 13:38:00,643 Train Loss: 0.0001847, Val Loss: 0.0002517
2025-02-19 13:38:00,644 Epoch 1956/2000
2025-02-19 13:38:42,456 Current Learning Rate: 0.0088525662
2025-02-19 13:38:42,469 Train Loss: 0.0003018, Val Loss: 0.0002881
2025-02-19 13:38:42,475 Epoch 1957/2000
2025-02-19 13:39:24,647 Current Learning Rate: 0.0089021520
2025-02-19 13:39:24,650 Train Loss: 0.0002253, Val Loss: 0.0002416
2025-02-19 13:39:24,651 Epoch 1958/2000
2025-02-19 13:40:08,015 Current Learning Rate: 0.0089507751
2025-02-19 13:40:08,061 Train Loss: 0.0001915, Val Loss: 0.0002403
2025-02-19 13:40:08,063 Epoch 1959/2000
2025-02-19 13:40:50,904 Current Learning Rate: 0.0089984233
2025-02-19 13:40:50,906 Train Loss: 0.0001649, Val Loss: 0.0002827
2025-02-19 13:40:50,907 Epoch 1960/2000
2025-02-19 13:41:33,015 Current Learning Rate: 0.0090450850
2025-02-19 13:41:33,017 Train Loss: 0.0002614, Val Loss: 0.0002810
2025-02-19 13:41:33,019 Epoch 1961/2000
2025-02-19 13:42:15,236 Current Learning Rate: 0.0090907486
2025-02-19 13:42:15,238 Train Loss: 0.0001902, Val Loss: 0.0002588
2025-02-19 13:42:15,239 Epoch 1962/2000
2025-02-19 13:42:58,812 Current Learning Rate: 0.0091354029
2025-02-19 13:42:58,814 Train Loss: 0.0002041, Val Loss: 0.0002960
2025-02-19 13:42:58,815 Epoch 1963/2000
2025-02-19 13:43:42,064 Current Learning Rate: 0.0091790368
2025-02-19 13:43:42,066 Train Loss: 0.0002398, Val Loss: 0.0002979
2025-02-19 13:43:42,067 Epoch 1964/2000
2025-02-19 13:44:25,348 Current Learning Rate: 0.0092216396
2025-02-19 13:44:25,350 Train Loss: 0.0002669, Val Loss: 0.0003629
2025-02-19 13:44:25,351 Epoch 1965/2000
2025-02-19 13:45:08,370 Current Learning Rate: 0.0092632008
2025-02-19 13:45:08,372 Train Loss: 0.0002395, Val Loss: 0.0003153
2025-02-19 13:45:08,373 Epoch 1966/2000
2025-02-19 13:45:51,845 Current Learning Rate: 0.0093037101
2025-02-19 13:45:51,846 Train Loss: 0.0002947, Val Loss: 0.0002661
2025-02-19 13:45:51,847 Epoch 1967/2000
2025-02-19 13:46:34,606 Current Learning Rate: 0.0093431576
2025-02-19 13:46:34,608 Train Loss: 0.0002339, Val Loss: 0.0002777
2025-02-19 13:46:34,610 Epoch 1968/2000
2025-02-19 13:47:17,360 Current Learning Rate: 0.0093815334
2025-02-19 13:47:17,363 Train Loss: 0.0002310, Val Loss: 0.0002872
2025-02-19 13:47:17,363 Epoch 1969/2000
2025-02-19 13:48:00,319 Current Learning Rate: 0.0094188282
2025-02-19 13:48:00,322 Train Loss: 0.0003090, Val Loss: 0.0003310
2025-02-19 13:48:00,323 Epoch 1970/2000
2025-02-19 13:48:44,101 Current Learning Rate: 0.0094550326
2025-02-19 13:48:44,103 Train Loss: 0.0002036, Val Loss: 0.0002684
2025-02-19 13:48:44,104 Epoch 1971/2000
2025-02-19 13:49:27,175 Current Learning Rate: 0.0094901379
2025-02-19 13:49:27,176 Train Loss: 0.0001900, Val Loss: 0.0002480
2025-02-19 13:49:27,178 Epoch 1972/2000
2025-02-19 13:50:10,158 Current Learning Rate: 0.0095241353
2025-02-19 13:50:10,160 Train Loss: 0.0002441, Val Loss: 0.0002496
2025-02-19 13:50:10,161 Epoch 1973/2000
2025-02-19 13:50:53,102 Current Learning Rate: 0.0095570164
2025-02-19 13:50:53,106 Train Loss: 0.0002433, Val Loss: 0.0002842
2025-02-19 13:50:53,107 Epoch 1974/2000
2025-02-19 13:51:35,785 Current Learning Rate: 0.0095887731
2025-02-19 13:51:35,786 Train Loss: 0.0002307, Val Loss: 0.0002594
2025-02-19 13:51:35,788 Epoch 1975/2000
2025-02-19 13:52:19,247 Current Learning Rate: 0.0096193977
2025-02-19 13:52:19,249 Train Loss: 0.0025567, Val Loss: 0.0024394
2025-02-19 13:52:19,250 Epoch 1976/2000
2025-02-19 13:53:02,547 Current Learning Rate: 0.0096488824
2025-02-19 13:53:02,550 Train Loss: 0.0015209, Val Loss: 0.0006062
2025-02-19 13:53:02,552 Epoch 1977/2000
2025-02-19 13:53:46,008 Current Learning Rate: 0.0096772202
2025-02-19 13:53:46,019 Train Loss: 0.0006244, Val Loss: 0.0005558
2025-02-19 13:53:46,032 Epoch 1978/2000
2025-02-19 13:54:28,691 Current Learning Rate: 0.0097044038
2025-02-19 13:54:28,693 Train Loss: 0.0006278, Val Loss: 0.0008046
2025-02-19 13:54:28,694 Epoch 1979/2000
2025-02-19 13:55:11,953 Current Learning Rate: 0.0097304268
2025-02-19 13:55:11,955 Train Loss: 0.0006101, Val Loss: 0.0028847
2025-02-19 13:55:11,956 Epoch 1980/2000
2025-02-19 13:55:55,610 Current Learning Rate: 0.0097552826
2025-02-19 13:55:55,612 Train Loss: 0.0006145, Val Loss: 0.0009004
2025-02-19 13:55:55,613 Epoch 1981/2000
2025-02-19 13:56:39,183 Current Learning Rate: 0.0097789651
2025-02-19 13:56:39,185 Train Loss: 0.0006718, Val Loss: 0.0005532
2025-02-19 13:56:39,186 Epoch 1982/2000
2025-02-19 13:57:22,287 Current Learning Rate: 0.0098014684
2025-02-19 13:57:22,289 Train Loss: 0.0004988, Val Loss: 0.0005209
2025-02-19 13:57:22,291 Epoch 1983/2000
2025-02-19 13:58:05,719 Current Learning Rate: 0.0098227871
2025-02-19 13:58:05,721 Train Loss: 0.0005861, Val Loss: 0.0004734
2025-02-19 13:58:05,722 Epoch 1984/2000
2025-02-19 13:58:48,271 Current Learning Rate: 0.0098429158
2025-02-19 13:58:48,274 Train Loss: 0.0002894, Val Loss: 0.0003020
2025-02-19 13:58:48,275 Epoch 1985/2000
2025-02-19 13:59:31,616 Current Learning Rate: 0.0098618496
2025-02-19 13:59:31,618 Train Loss: 0.0003156, Val Loss: 0.0002799
2025-02-19 13:59:31,619 Epoch 1986/2000
2025-02-19 14:00:14,060 Current Learning Rate: 0.0098795838
2025-02-19 14:00:14,062 Train Loss: 0.0002834, Val Loss: 0.0002853
2025-02-19 14:00:14,063 Epoch 1987/2000
2025-02-19 14:00:57,253 Current Learning Rate: 0.0098961141
2025-02-19 14:00:57,257 Train Loss: 0.0002277, Val Loss: 0.0002562
2025-02-19 14:00:57,258 Epoch 1988/2000
2025-02-19 14:01:39,942 Current Learning Rate: 0.0099114363
2025-02-19 14:01:39,943 Train Loss: 0.0003088, Val Loss: 0.0002971
2025-02-19 14:01:39,944 Epoch 1989/2000
2025-02-19 14:02:22,476 Current Learning Rate: 0.0099255466
2025-02-19 14:02:22,478 Train Loss: 0.0002795, Val Loss: 0.0003608
2025-02-19 14:02:22,479 Epoch 1990/2000
2025-02-19 14:03:05,339 Current Learning Rate: 0.0099384417
2025-02-19 14:03:05,341 Train Loss: 0.0003420, Val Loss: 0.0002915
2025-02-19 14:03:05,342 Epoch 1991/2000
2025-02-19 14:03:49,211 Current Learning Rate: 0.0099501183
2025-02-19 14:03:49,233 Train Loss: 0.0002168, Val Loss: 0.0002731
2025-02-19 14:03:49,245 Epoch 1992/2000
2025-02-19 14:04:31,933 Current Learning Rate: 0.0099605735
2025-02-19 14:04:31,935 Train Loss: 0.0002011, Val Loss: 0.0002687
2025-02-19 14:04:31,936 Epoch 1993/2000
2025-02-19 14:05:15,740 Current Learning Rate: 0.0099698048
2025-02-19 14:05:15,742 Train Loss: 0.0002759, Val Loss: 0.0002570
2025-02-19 14:05:15,743 Epoch 1994/2000
2025-02-19 14:05:58,944 Current Learning Rate: 0.0099778098
2025-02-19 14:05:58,945 Train Loss: 0.0001932, Val Loss: 0.0002441
2025-02-19 14:05:58,947 Epoch 1995/2000
2025-02-19 14:06:41,994 Current Learning Rate: 0.0099845867
2025-02-19 14:06:41,996 Train Loss: 0.0002042, Val Loss: 0.0002350
2025-02-19 14:06:41,997 Epoch 1996/2000
2025-02-19 14:07:25,018 Current Learning Rate: 0.0099901336
2025-02-19 14:07:25,020 Train Loss: 0.0001661, Val Loss: 0.0002245
2025-02-19 14:07:25,021 Epoch 1997/2000
2025-02-19 14:08:08,176 Current Learning Rate: 0.0099944494
2025-02-19 14:08:08,193 Train Loss: 0.0002242, Val Loss: 0.0002363
2025-02-19 14:08:08,198 Epoch 1998/2000
2025-02-19 14:08:50,579 Current Learning Rate: 0.0099975328
2025-02-19 14:08:50,580 Train Loss: 0.0001969, Val Loss: 0.0002482
2025-02-19 14:08:50,581 Epoch 1999/2000
2025-02-19 14:09:32,908 Current Learning Rate: 0.0099993832
2025-02-19 14:09:32,910 Train Loss: 0.0002183, Val Loss: 0.0002514
2025-02-19 14:09:32,911 Epoch 2000/2000
2025-02-19 14:10:15,485 Current Learning Rate: 0.0100000000
2025-02-19 14:10:15,487 Train Loss: 0.0002445, Val Loss: 0.0002415
2025-02-19 14:10:20,008 Testing completed and best model saved.
